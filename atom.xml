<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>MrBird</title>
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://mrbird.cc/"/>
  <updated>2019-12-12T07:22:30.157Z</updated>
  <id>http://mrbird.cc/</id>
  
  <author>
    <name>MrBird</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>IDEA中使用Docker插件</title>
    <link href="http://mrbird.cc/IDEA-Docker-Plugin.html"/>
    <id>http://mrbird.cc/IDEA-Docker-Plugin.html</id>
    <published>2019-12-03T09:19:29.000Z</published>
    <updated>2019-12-12T07:22:30.157Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Tue Dec 17 2019 19:26:13 GMT+0800 (GMT+08:00) --><p>在Windows上如果没有安装docker for windows的话，是没办法构建Docker镜像的。这种情况下，如果要通过fat jar构建docker镜像的话，只能将fat jar上传到安装了docker服务的Linux服务器上，然后编写Dockerfile构建。这种方式比较麻烦，这里记录下如何通过IDEA的Docker插件远程构建Docker镜像。<a id="more"></a></p><h2 id="Docker开启远程访问"><a href="#Docker开启远程访问" class="headerlink" title="Docker开启远程访问"></a>Docker开启远程访问</h2><p>假如我在CentOS虚拟机上安装好了Docker，IP地址为192.168.33.11，我们可以修改Docker的配置，开启远程访问权限：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 修改Docker配置</span></span><br><span class="line">vi /lib/systemd/system/docker.service</span><br></pre></td></tr></table></figure><p></p><p>修改的地方如下图所示：</p><p><img src="img/QQ截图20191203190038.png" alt="QQ截图20191203190038.png"></p><p>修改保存后，重启Docker服务：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">systemctl daemon-reload </span><br><span class="line">systemctl restart docker.service</span><br></pre></td></tr></table></figure><p></p><p>重启后，验证下2375端口是否是通的：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl 192.168.33.11:2375/info</span><br></pre></td></tr></table></figure><p>如果返回了一坨JSON数据，说明🆗。</p><h2 id="IDEA使用Docker插件"><a href="#IDEA使用Docker插件" class="headerlink" title="IDEA使用Docker插件"></a>IDEA使用Docker插件</h2><p>IDEA Ultimate版本已经默认安装了Docker插件（没有的话去插件市场下载安装下就可以了）。点击IDEA -&gt; File -&gt; Settings… -&gt; Build,Execution,Deployment -&gt; Docker：</p><p><img src="img/QQ截图20191203190538.png" alt="QQ截图20191203190538.png"></p><p>填写远程Docker地址，如果显示Connection Successfully说明连接远程Docker服务成功。</p><p>新建一个简单的Spring Boot项目，pom如下所示：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">project</span> <span class="attr">xmlns</span>=<span class="string">"http://maven.apache.org/POM/4.0.0"</span> <span class="attr">xmlns:xsi</span>=<span class="string">"http://www.w3.org/2001/XMLSchema-instance"</span></span></span><br><span class="line"><span class="tag">         <span class="attr">xsi:schemaLocation</span>=<span class="string">"http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">modelVersion</span>&gt;</span>4.0.0<span class="tag">&lt;/<span class="name">modelVersion</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">parent</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-parent<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.2.1.RELEASE<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">relativePath</span>/&gt;</span> <span class="comment">&lt;!-- lookup parent from repository --&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">parent</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>cc.mrbird<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>demo<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>0.0.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>demo<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>Demo project for Spring Boot<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">properties</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">java.version</span>&gt;</span>1.8<span class="tag">&lt;/<span class="name">java.version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">properties</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-web<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-test<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">scope</span>&gt;</span>test<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">build</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">plugins</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-maven-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">plugins</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">build</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">project</span>&gt;</span></span><br></pre></td></tr></table></figure><p></p><p>然后用maven打包，打包后项目根目录的target下会有如下fat jar：</p><p><img src="img/QQ截图20191203191101.png" alt="QQ截图20191203191101.png"></p><p>在项目根目录下新建Dockerfile，内容如下所示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">FROM openjdk:8u212-jre</span><br><span class="line">MAINTAINER MrBird 852252810@qq.com</span><br><span class="line"></span><br><span class="line">COPY target/demo-0.0.1.jar /demo-0.0.1.jar</span><br><span class="line">ENTRYPOINT [&quot;java&quot;, &quot;-jar&quot;, &quot;/demo-0.0.1.jar&quot;]</span><br></pre></td></tr></table></figure><p></p><p>然后点击IDEA -&gt; Run -&gt; Edit Configrations…</p><p><img src="img/QQ截图20191203191341.png" alt="QQ截图20191203191341.png"></p><p>选择远程的Docker服务，填写镜像标签内容，点击保存后，运行：</p><p><img src="img/QQ截图20191203191547.png" alt="QQ截图20191203191547.png"></p><p>通过日志来看，镜像构建是成功的：</p><p><img src="img/QQ截图20191203191734.png" alt="QQ截图20191203191734.png"></p><p>可以看到远程服务器上已经包含了该Docker镜像：</p><p><img src="img/QQ截图20191203191809.png" alt="QQ截图20191203191809.png"></p><p>可以到服务器上验证下：</p><p><img src="img/QQ截图20191203191934.png" alt="QQ截图20191203191934.png"></p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Tue Dec 17 2019 19:26:13 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;在Windows上如果没有安装docker for windows的话，是没办法构建Docker镜像的。这种情况下，如果要通过fat jar构建docker镜像的话，只能将fat jar上传到安装了docker服务的Linux服务器上，然后编写Dockerfile构建。这种方式比较麻烦，这里记录下如何通过IDEA的Docker插件远程构建Docker镜像。
    
    </summary>
    
    
      <category term="Docker" scheme="http://mrbird.cc/tags/Docker/"/>
    
  </entry>
  
  <entry>
    <title>Kubernetes服务发现总结</title>
    <link href="http://mrbird.cc/Kubernetes-Service-Discovery-Summary.html"/>
    <id>http://mrbird.cc/Kubernetes-Service-Discovery-Summary.html</id>
    <published>2019-12-02T06:23:17.000Z</published>
    <updated>2019-12-12T07:22:30.158Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Tue Dec 17 2019 19:26:13 GMT+0800 (GMT+08:00) --><p>Kubernetes服务发现主要可以归为三种情形：1.Kubernetes集群内部间服务如何互相通信；2.Kuberntes集群外部如何访问集群内部服务；3.Kubernetes集群内部如何访问集群外部服务。这节针对这三种情况做个总结。</p><a id="more"></a><h2 id="集群间服务通信"><a href="#集群间服务通信" class="headerlink" title="集群间服务通信"></a>集群间服务通信</h2><p><strong>1.通过Pod IP相互通信，但是Pod具有不确定性，Pod IP会发生改变，所以这种方式并不推荐。</strong></p><p><strong>2.部署Pod对应的Service，访问Service IP，请求负载均衡转发服务到各个对应的Pod实例。</strong></p><p>比如有如下配置文件demo.yml：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">nginx-d</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  selector:</span></span><br><span class="line"><span class="attr">    matchLabels:</span></span><br><span class="line"><span class="attr">      name:</span> <span class="string">web-app</span></span><br><span class="line"><span class="attr">  replicas:</span> <span class="number">3</span></span><br><span class="line"><span class="attr">  template:</span></span><br><span class="line"><span class="attr">    metadata:</span></span><br><span class="line"><span class="attr">      labels:</span></span><br><span class="line"><span class="attr">        name:</span> <span class="string">web-app</span></span><br><span class="line"><span class="attr">    spec:</span></span><br><span class="line"><span class="attr">      containers:</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">          image:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">          ports:</span></span><br><span class="line"><span class="attr">            - containerPort:</span> <span class="number">80</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">nginx-s</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  ports:</span></span><br><span class="line"><span class="attr">    - port:</span> <span class="number">8080</span></span><br><span class="line"><span class="attr">      targetPort:</span> <span class="number">80</span></span><br><span class="line"><span class="attr">      protocol:</span> <span class="string">TCP</span></span><br><span class="line"><span class="attr">  selector:</span></span><br><span class="line"><span class="attr">    name:</span> <span class="string">web-app</span></span><br></pre></td></tr></table></figure><p></p><p>运行该配置，查看Service对应的IP：</p><p><img src="img/QQ截图20191203143956.png" alt="QQ截图20191203143956.png"></p><p>通过Service IP和端口就能访问对应的Pod服务:</p><p><img src="img/QQ截图20191203144119.png" alt="QQ截图20191203144119.png"></p><p>但是我们事先并不知道Service的IP是多少，如果我们在启动服务后再去配置这个IP的话，这个过程也是非常麻烦的，所幸我们可以通过DNS解决这个问题，也就是下面这种方式：</p><p><strong>3.部署Pod对应的Service，通过ServiceName，请求负载均衡转发服务到各个对应的Pod实例。</strong></p><p>通过下面这段配置部署一个新的Pod服务：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">centos-pod</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  containers:</span></span><br><span class="line"><span class="attr">    - name:</span> <span class="string">centos</span></span><br><span class="line"><span class="attr">      image:</span> <span class="string">centos</span></span><br><span class="line"><span class="attr">      command:</span></span><br><span class="line"><span class="bullet">        -</span> <span class="string">sh</span></span><br><span class="line"><span class="bullet">        -</span> <span class="bullet">-c</span></span><br><span class="line"><span class="bullet">        -</span> <span class="string">'while true; do sleep 360000000; done'</span></span><br></pre></td></tr></table></figure><p></p><p>进入到该容器内部，测试下是否可以访问上面创建的Service：</p><p><img src="img/QQ截图20191203145657.png" alt="QQ截图20191203145657.png"></p><p>试着通过ServiceName访问Nginx服务：</p><p><img src="img/QQ截图20191203145744.png" alt="QQ截图20191203145744.png"></p><p>可以看到效果是一样的。这得益于Kube-dns，具体的格式为：<strong><code>&lt;service_name&gt;.&lt;namespace&gt;.svc.&lt;cluster_domain&gt;</code></strong>其中，<code>&lt;cluster_domain&gt;</code>默认值为<code>cluster.local</code>，可以通过kubelet的<code>--cluster-domain=SomeDomain</code>参数进行设置。为了在Pod中调用其他Service，kubelet会自动在容器中创建域名解析配置：</p><p><img src="img/QQ截图20191203150831.png" alt="QQ截图20191203150831.png"></p><p>所以除了使用<code>curl nginx-s:8080</code>访问外，以下这些也是等效的：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">curl nginx-s.default:8080</span><br><span class="line"></span><br><span class="line">curl nginx-s.default.svc:8080</span><br><span class="line"></span><br><span class="line">curl nginx-s.default.svc.cluster.local:8080</span><br></pre></td></tr></table></figure><p></p><p>所以我们现在可以不用事先知道Service的IP了，只要事先知道ServiceName即可（ServiceName是我们自己定义的）。</p><p><strong>4.通过Headless Service，返回Pod的所有实例。</strong></p><p>有时候我们并不需要Service的负载均衡功能，而是手动获取Service对应的Pod实例，自己决定如何访问。创建一个Headless Service配置：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">nginx-headless-s</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  ports:</span></span><br><span class="line"><span class="attr">    - port:</span> <span class="number">8080</span></span><br><span class="line"><span class="attr">  clusterIP:</span> <span class="string">None</span></span><br><span class="line"><span class="attr">  selector:</span></span><br><span class="line"><span class="attr">    name:</span> <span class="string">web-app</span></span><br></pre></td></tr></table></figure><p></p><p>创建该Headless Service，然后到centos-pod容器内部查询DNS记录：</p><p><img src="img/QQ截图20191203153848.png" alt="QQ截图20191203153848.png"></p><blockquote><p>如果没有nslookup命令，可以使用<code>yum -y install bind-utils</code>命令安装。</p></blockquote><p>可以看到，通过解析nginx-headless-s DNS，返回了三个Nginx Pod实例地址。</p><h2 id="集群外部访问内部"><a href="#集群外部访问内部" class="headerlink" title="集群外部访问内部"></a>集群外部访问内部</h2><p>1.Pod指定hostPort，或者开启hostNetwork，这样外部就可以通过Pod宿主机IP+Pod端口访问了，但Pod调度的不确定性，这种方式不推荐；</p><p>2.通过Service的NodePort暴露服务，如果服务较多的话不推荐，因为这种方式会在集群中的所有节点上都暴露该端口，所以当服务多的时候很容易造成端口冲突，并且端口维护不便；</p><p>3.通过Ingress集中暴露服务，要暴露的服务较多的时候推荐。</p><p>这三种方式是前面博客中都有介绍到，所以就不赘述了。</p><h2 id="集群内部访问外部"><a href="#集群内部访问外部" class="headerlink" title="集群内部访问外部"></a>集群内部访问外部</h2><p>1.直接通过外部服务的IP和端口进行访问；</p><p>2.通过Service和Endpoint绑定，集群内的服务通过DNS访问集群外部服务（推荐）。</p><p>创建如下配置（test-remote.yml）：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">remote-s</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  ports:</span></span><br><span class="line"><span class="attr">    - protocol:</span> <span class="string">TCP</span></span><br><span class="line"><span class="attr">      port:</span> <span class="number">8081</span></span><br><span class="line"><span class="attr">      targetPort:</span> <span class="number">8080</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Endpoints</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">remote-s</span></span><br><span class="line"><span class="attr">subsets:</span></span><br><span class="line"><span class="attr">  - addresses:</span></span><br><span class="line"><span class="attr">      - ip:</span> <span class="number">192.168</span><span class="number">.73</span><span class="number">.42</span></span><br><span class="line"><span class="attr">    ports:</span></span><br><span class="line"><span class="attr">      - port:</span> <span class="number">8080</span></span><br></pre></td></tr></table></figure><p></p><p>Service和Endpoints名称一样，所以他们会绑定上，通过访问remote-s Service便可以访问到对应的Endpoint地址192.168.73.42:8080服务（这是个我在集群外部，通过Spring Boot搭建的简单web服务）。</p><p>运行该配置后，在master节点上，测试是否可以访问：</p><p><img src="img/QQ截图20191203165019.png" alt="QQ截图20191203165019.png"></p><p>我们进到centos-pod容器内部，通过服务名称看看是否可以访问到：</p><p><img src="img/QQ截图20191203165144.png" alt="QQ截图20191203165144.png"></p><p>可以看到这种方式也是没问题的，推荐使用这种方式，可以降低耦合度。</p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Tue Dec 17 2019 19:26:13 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;Kubernetes服务发现主要可以归为三种情形：1.Kubernetes集群内部间服务如何互相通信；2.Kuberntes集群外部如何访问集群内部服务；3.Kubernetes集群内部如何访问集群外部服务。这节针对这三种情况做个总结。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Kubernetes" scheme="http://mrbird.cc/tags/Kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>Kubernetes Ingress</title>
    <link href="http://mrbird.cc/Kubernetes-Ingress.html"/>
    <id>http://mrbird.cc/Kubernetes-Ingress.html</id>
    <published>2019-11-28T02:59:56.000Z</published>
    <updated>2019-11-29T12:30:24.280Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Tue Dec 17 2019 19:26:13 GMT+0800 (GMT+08:00) --><p>在<a href="/Kubernetes-Service-Basic.html">Kubernetes Service基础</a>一节中，我们了解到可以通过设置Service NodePort向Kubernetes集群外部暴露端口，外部服务可以通过Kubernetes集群节点IP+NodePort访问集群内部资源。当集群内部服务众多时，需要暴露的端口也会越来越多。这样不仅端口维护困难，集群边界也变得“千疮百孔”。针对这个问题，Kubernetes提供了Ingress来解决，Ingress对象用于配置外部请求转发到集群内部服务的具体规则，而实际的转发操作由Ingress Controller来完成。</p><a id="more"></a><p>假设我们的Kubernetes集群中分别存在2个实例的tomcat和nginx Deployment，并且有对应的Service。加入Ingress后，我们可以实现如下图所示的服务暴露方式：</p><p><img src="img/QQ截图20191128181259.png" alt="QQ截图20191128181259.png"></p><h2 id="Ingress-Controller"><a href="#Ingress-Controller" class="headerlink" title="Ingress Controller"></a>Ingress Controller</h2><p>Ingress Controller并不是Kubernetes对象，而是根据Ingress对象配置，实现具体转发功能的组件统称。除了Kubernetes官方维护的GCE和Ingress Nginx外，还有许多第三方维护的实现。这里以用的较多的Ingress Nginx为例，实现Ingress Controller的部署。</p><p>因为Ingress Controller是用于处理集群外部请求访问集群内部服务的组件，所以我们需要思考，如何将Ingress Controller暴露出去。最为常见的方式主要有以下两种：</p><ol><li><p>创建和Intress Controller对应的Service服务，Service通过NodePort将服务端口暴露出去；</p></li><li><p>将Ingress Controller部署到几个<strong>固定</strong>的节点上，然后通过HostPort将端口映射出去，最外层通过LVS+keepalive实现负载均衡。</p></li></ol><p>因为第1种方式需要在请求链路中再加一层Service服务，性能可能会有耗损，所以我们选择第2种方式。</p><p>为了简化过程，这里只在一个节点上部署Ingress Controller，比如我们可以选择在Node1节点上部署。给Node1节点打个标签：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl label node node1 <span class="built_in">type</span>=<span class="string">"ingress"</span></span><br></pre></td></tr></table></figure><p>下载Ingress Nginx配置文件：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/static/mandatory.yaml</span><br></pre></td></tr></table></figure><p></p><p>修改该配置文件：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi mandatory.yaml</span><br></pre></td></tr></table></figure><p></p><p>修改部分如下所示:</p><p><img src="img/QQ截图20191128184352.png" alt="QQ截图20191128184352.png"></p><p>创建该配置文件：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl create -f mandatory.yaml</span><br></pre></td></tr></table></figure><p></p><p><img src="img/QQ截图20191128184513.png" alt="QQ截图20191128184513.png"></p><p>查看是否创建成功：</p><p><img src="img/QQ截图20191128184723.png" alt="QQ截图20191128184723.png"></p><p>使用浏览器访问<a href="http://192.168.33.12/" target="_blank" rel="noopener">http://192.168.33.12/</a>：</p><p><img src="img/QQ截图20191129091742.png" alt="QQ截图20191128190016.png"></p><p>因为还没有创建Ingress，所以页面响应暂时为404。</p><h2 id="Ingress"><a href="#Ingress" class="headerlink" title="Ingress"></a>Ingress</h2><p>在创建Ingress对象前，我们需要准备好tomcat和nginx服务，供待会演示，创建demo.yml：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">tomcat-app</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  selector:</span></span><br><span class="line"><span class="attr">    matchLabels:</span></span><br><span class="line"><span class="attr">      name:</span> <span class="string">tomcat</span></span><br><span class="line"><span class="attr">  replicas:</span> <span class="number">2</span></span><br><span class="line"><span class="attr">  template:</span></span><br><span class="line"><span class="attr">    metadata:</span></span><br><span class="line"><span class="attr">      labels:</span></span><br><span class="line"><span class="attr">        name:</span> <span class="string">tomcat</span></span><br><span class="line"><span class="attr">    spec:</span></span><br><span class="line"><span class="attr">      containers:</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">tomcat</span></span><br><span class="line"><span class="attr">          image:</span> <span class="attr">tomcat:8.0.51-alpine</span></span><br><span class="line"><span class="attr">          ports:</span></span><br><span class="line"><span class="attr">            - containerPort:</span> <span class="number">8080</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">nginx-app</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  selector:</span></span><br><span class="line"><span class="attr">    matchLabels:</span></span><br><span class="line"><span class="attr">      name:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">  replicas:</span> <span class="number">2</span></span><br><span class="line"><span class="attr">  template:</span></span><br><span class="line"><span class="attr">    metadata:</span></span><br><span class="line"><span class="attr">      labels:</span></span><br><span class="line"><span class="attr">        name:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">    spec:</span></span><br><span class="line"><span class="attr">      containers:</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">          image:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">          ports:</span></span><br><span class="line"><span class="attr">            - containerPort:</span> <span class="number">80</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">tomcat-service</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  ports:</span></span><br><span class="line"><span class="attr">    - port:</span> <span class="number">8080</span></span><br><span class="line"><span class="attr">      targetPort:</span> <span class="number">8080</span></span><br><span class="line"><span class="attr">  selector:</span></span><br><span class="line"><span class="attr">    name:</span> <span class="string">tomcat</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">nginx-service</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  ports:</span></span><br><span class="line"><span class="attr">    - port:</span> <span class="number">8081</span></span><br><span class="line"><span class="attr">      targetPort:</span> <span class="number">80</span></span><br><span class="line"><span class="attr">  selector:</span></span><br><span class="line"><span class="attr">    name:</span> <span class="string">nginx</span></span><br></pre></td></tr></table></figure><p></p><p>创建：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl create -f demo.yml</span><br></pre></td></tr></table></figure><p></p><p><img src="img/QQ截图20191128191135.png" alt="QQ截图20191128191135.png"></p><p>查看是否创建成功：</p><p><img src="img/QQ截图20191128191253.png" alt="QQ截图20191128191253.png"></p><p>接着创建Ingress配置文件（ingress.yml）:</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.k8s.io/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Ingress</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">ingress</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  rules:</span></span><br><span class="line"><span class="attr">    - host:</span> <span class="string">tomcat.mrbird.cc</span></span><br><span class="line"><span class="attr">      http:</span></span><br><span class="line"><span class="attr">        paths:</span></span><br><span class="line"><span class="attr">          - path:</span> <span class="string">/</span></span><br><span class="line"><span class="attr">            backend:</span></span><br><span class="line"><span class="attr">              serviceName:</span> <span class="string">tomcat-service</span></span><br><span class="line"><span class="attr">              servicePort:</span> <span class="number">8080</span></span><br><span class="line"><span class="attr">    - host:</span> <span class="string">nginx.mrbird.cc</span></span><br><span class="line"><span class="attr">      http:</span></span><br><span class="line"><span class="attr">        paths:</span></span><br><span class="line"><span class="attr">          - path:</span> <span class="string">/</span></span><br><span class="line"><span class="attr">            backend:</span></span><br><span class="line"><span class="attr">              serviceName:</span> <span class="string">nginx-service</span></span><br><span class="line"><span class="attr">              servicePort:</span> <span class="number">8081</span></span><br></pre></td></tr></table></figure><p></p><p>根据上述配置，当我们访问tomcat.mrbird.cc根路径的时候，请求将转发到名称为tomcat-service，端口为8080的service上，根据上面demo.yml的配置，该service对应两个tomcat pod；访问nginx.mrbird.cc根路径的时候，请求将转发到nginx-service。</p><p>创建该Ingress：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl create -f ingress.yml</span><br></pre></td></tr></table></figure><p></p><p><img src="img/QQ截图20191129094819.png" alt="QQ截图20191129094819.png"></p><p>从图中可以看出，当我们访问tomcat.mrbird.cc/的时候，请求会均衡地转发到10.244.1.10:8080/和10.244.2.15:8080/。</p><p>在Windows上配置hosts域名解析：</p><p><img src="img/QQ截图20191129095034.png" alt="QQ截图20191129095034.png"></p><p>浏览器访问<a href="http://tomcat.mrbird.cc/" target="_blank" rel="noopener">http://tomcat.mrbird.cc/</a>：</p><p><img src="img/QQ截图20191129095222.png" alt="QQ截图20191129095222.png"></p><p>访问<a href="http://nginx.mrbird.cc/" target="_blank" rel="noopener">http://nginx.mrbird.cc/</a>：</p><p><img src="img/QQ截图20191129095333.png" alt="QQ截图20191129095333.png"></p><p>结果符合我们的预期。</p><p>Ingress Nginx实质上就是一个nginx服务，它可以自动通过我们的Ingress配置，生成相应的nginx配置文件，我们可以进入到Ingress Nginx容器内部证实这一点:</p><p><img src="img/QQ截图20191129100835.png" alt="QQ截图20191129100835.png"></p><p>在配置文件中，可以看到下面这些配置（仅截取tomcat.mrbird.cc配置）：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">## start server tomcat.mrbird.cc</span><br><span class="line">server &#123;</span><br><span class="line">        server_name tomcat.mrbird.cc ;</span><br><span class="line"></span><br><span class="line">        listen 80  ;</span><br><span class="line">        listen [::]:80  ;</span><br><span class="line">        listen 443  ssl http2 ;</span><br><span class="line">        listen [::]:443  ssl http2 ;</span><br><span class="line"></span><br><span class="line">        set $proxy_upstream_name &quot;-&quot;;</span><br><span class="line"></span><br><span class="line">        ssl_certificate_by_lua_block &#123;</span><br><span class="line">                certificate.call()</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        location / &#123;</span><br><span class="line"></span><br><span class="line">                set $namespace      &quot;default&quot;;</span><br><span class="line">                set $ingress_name   &quot;ingress&quot;;</span><br><span class="line">                set $service_name   &quot;tomcat-service&quot;;</span><br><span class="line">                set $service_port   &quot;8080&quot;;</span><br><span class="line">                set $location_path  &quot;/&quot;;</span><br><span class="line"></span><br><span class="line">                rewrite_by_lua_block &#123;</span><br><span class="line">                        lua_ingress.rewrite(&#123;</span><br><span class="line">                                force_ssl_redirect = false,</span><br><span class="line">                                ssl_redirect = true,</span><br><span class="line">                                force_no_ssl_redirect = false,</span><br><span class="line">                                use_port_in_redirects = false,</span><br><span class="line">                        &#125;)</span><br><span class="line">                        balancer.rewrite()</span><br><span class="line">                        plugins.run()</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                header_filter_by_lua_block &#123;</span><br><span class="line"></span><br><span class="line">                        plugins.run()</span><br><span class="line">                &#125;</span><br><span class="line">                body_filter_by_lua_block &#123;</span><br><span class="line"></span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                log_by_lua_block &#123;</span><br><span class="line"></span><br><span class="line">                        balancer.log()</span><br><span class="line"></span><br><span class="line">                        monitor.call()</span><br><span class="line"></span><br><span class="line">                        plugins.run()</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                port_in_redirect off;</span><br><span class="line"></span><br><span class="line">                set $balancer_ewma_score -1;</span><br><span class="line">                set $proxy_upstream_name &quot;default-tomcat-service-8080&quot;;</span><br><span class="line">                set $proxy_host          $proxy_upstream_name;</span><br><span class="line">                set $pass_access_scheme  $scheme;</span><br><span class="line">                set $pass_server_port    $server_port;</span><br><span class="line">                set $best_http_host      $http_host;</span><br><span class="line">                set $pass_port           $pass_server_port;</span><br><span class="line"></span><br><span class="line">                set $proxy_alternative_upstream_name &quot;&quot;;</span><br><span class="line"></span><br><span class="line">                client_max_body_size                    1m;</span><br><span class="line"></span><br><span class="line">                proxy_set_header Host                   $best_http_host;</span><br><span class="line"></span><br><span class="line">                # Pass the extracted client certificate to the backend</span><br><span class="line"></span><br><span class="line">                # Allow websocket connections</span><br><span class="line">                proxy_set_header                        Upgrade           $http_upgrade;</span><br><span class="line"></span><br><span class="line">                proxy_set_header                        Connection        $connection_upgrade;</span><br><span class="line"></span><br><span class="line">                proxy_set_header X-Request-ID           $req_id;</span><br><span class="line">                proxy_set_header X-Real-IP              $remote_addr;</span><br><span class="line"></span><br><span class="line">                proxy_set_header X-Forwarded-For        $remote_addr;</span><br><span class="line"></span><br><span class="line">                proxy_set_header X-Forwarded-Host       $best_http_host;</span><br><span class="line">                proxy_set_header X-Forwarded-Port       $pass_port;</span><br><span class="line">                proxy_set_header X-Forwarded-Proto      $pass_access_scheme;</span><br><span class="line"></span><br><span class="line">                proxy_set_header X-Scheme               $pass_access_scheme;</span><br><span class="line"></span><br><span class="line">                # Pass the original X-Forwarded-For</span><br><span class="line">                proxy_set_header X-Original-Forwarded-For $http_x_forwarded_for;</span><br><span class="line"></span><br><span class="line">                # mitigate HTTPoxy Vulnerability</span><br><span class="line">                # https://www.nginx.com/blog/mitigating-the-httpoxy-vulnerability-with-nginx/</span><br><span class="line">                proxy_set_header Proxy                  &quot;&quot;;</span><br><span class="line"></span><br><span class="line">                # Custom headers to proxied server</span><br><span class="line"></span><br><span class="line">                proxy_connect_timeout                   5s;</span><br><span class="line">                proxy_send_timeout                      60s;</span><br><span class="line">                proxy_read_timeout                      60s;</span><br><span class="line"></span><br><span class="line">                proxy_buffering                         off;</span><br><span class="line">                proxy_buffer_size                       4k;</span><br><span class="line">                proxy_buffers                           4 4k;</span><br><span class="line"></span><br><span class="line">                proxy_max_temp_file_size                1024m;</span><br><span class="line"></span><br><span class="line">                proxy_request_buffering                 on;</span><br><span class="line">                proxy_http_version                      1.1;</span><br><span class="line"></span><br><span class="line">                proxy_cookie_domain                     off;</span><br><span class="line">                proxy_cookie_path                       off;</span><br><span class="line"></span><br><span class="line">                # In case of errors try the next upstream server before returning an error</span><br><span class="line">                proxy_next_upstream                     error timeout;</span><br><span class="line">                proxy_next_upstream_timeout             0;</span><br><span class="line">                proxy_next_upstream_tries               3;</span><br><span class="line"></span><br><span class="line">                proxy_pass http://upstream_balancer;</span><br><span class="line"></span><br><span class="line">                proxy_redirect                          off;</span><br><span class="line"></span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line">## end server tomcat.mrbird.cc</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p></p><p>更多Ingress配置可以参考官方文档：<a href="https://v1-12.docs.kubernetes.io/zh/docs/concepts/services-networking/ingress/" target="_blank" rel="noopener">https://v1-12.docs.kubernetes.io/zh/docs/concepts/services-networking/ingress/</a>。</p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Tue Dec 17 2019 19:26:13 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;在&lt;a href=&quot;/Kubernetes-Service-Basic.html&quot;&gt;Kubernetes Service基础&lt;/a&gt;一节中，我们了解到可以通过设置Service NodePort向Kubernetes集群外部暴露端口，外部服务可以通过Kubernetes集群节点IP+NodePort访问集群内部资源。当集群内部服务众多时，需要暴露的端口也会越来越多。这样不仅端口维护困难，集群边界也变得“千疮百孔”。针对这个问题，Kubernetes提供了Ingress来解决，Ingress对象用于配置外部请求转发到集群内部服务的具体规则，而实际的转发操作由Ingress Controller来完成。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Kubernetes" scheme="http://mrbird.cc/tags/Kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>Kubernetes StatefulSet</title>
    <link href="http://mrbird.cc/Kubernetes-StatefulSet.html"/>
    <id>http://mrbird.cc/Kubernetes-StatefulSet.html</id>
    <published>2019-11-27T01:17:47.000Z</published>
    <updated>2019-11-29T12:30:24.281Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Tue Dec 17 2019 19:26:13 GMT+0800 (GMT+08:00) --><p>前面介绍的Pod管理对象，如RC/RS、Deployment、DaemonSet等都是面向无状态服务的，而对于有状态的应用，比如MySQL集群，MongoDB集群等，则可以使用StatefulSet来完成。有状态的应用集群通常有以下这些特点：</p><ol><li><p>每个节点都有固定的身份ID，通过这个ID，集群中的成员可以相互发现并通信；</p></li><li><p>集群的规模是比较固定的，集群规模不能随意变动；</p></li><li><p>集群中的每个节点都是有状态的，通常会持久化数据到永久存储中。</p></li></ol><a id="more"></a><h2 id="StatefulSet特性"><a href="#StatefulSet特性" class="headerlink" title="StatefulSet特性"></a>StatefulSet特性</h2><p>通过StatefulSet搭建的集群通常有以下这些特性：</p><ol><li><p>StatefulSet里的每个Pod都有稳定、唯一的网络标识，可以用来发现集群内的其他成员。假设StatefulSet的名称为nginx，那么第1个Pod叫nginx-0，第2个叫nginx-1，以此类推；</p></li><li><p>StatefulSet控制的Pod副本的启停顺序是受控的，操作第n个Pod时，前n-1个Pod已经是运行且准备好的状态。</p></li><li><p>StatefulSet里的Pod采用稳定的持久化存储卷，通过PV或PVC来实现，删除Pod时默认不会删除与StatefulSet相关的存储卷（为了保证数据的安全）；</p></li><li><p>配合Headless Service使用，用于发现和控制Pod实例数量。</p></li></ol><h2 id="StatefulSet实践"><a href="#StatefulSet实践" class="headerlink" title="StatefulSet实践"></a>StatefulSet实践</h2><p>下面使用StatefulSet搭建个Nginx集群，持久化存储使用上一节搭建的名称为<strong>managed-nfs-storage</strong>的StorageClass。</p><p>创建nginx-headless-service.yml配置文件：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">  labels:</span></span><br><span class="line"><span class="attr">    name:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  ports:</span></span><br><span class="line"><span class="attr">    - port:</span> <span class="number">80</span></span><br><span class="line"><span class="attr">      targetPort:</span> <span class="number">80</span></span><br><span class="line"><span class="attr">  clusterIP:</span> <span class="string">None</span> <span class="comment"># 表明为Headleass Service</span></span><br><span class="line"><span class="attr">  selector:</span></span><br><span class="line"><span class="attr">    role:</span> <span class="string">web-app</span></span><br></pre></td></tr></table></figure><p></p><p>创建该Headless Service：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl create -f nginx-headless-service.yml</span><br></pre></td></tr></table></figure><p></p><p>接着创建nginx-statefulset.yml配置文件：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">StatefulSet</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">nginx-sc</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  serviceName:</span> <span class="string">"nginx"</span> <span class="comment"># 对应刚刚创建的Headless Service名称</span></span><br><span class="line"><span class="attr">  replicas:</span> <span class="number">3</span></span><br><span class="line"><span class="attr">  selector:</span></span><br><span class="line"><span class="attr">    matchLabels:</span></span><br><span class="line"><span class="attr">      role:</span> <span class="string">web-app</span></span><br><span class="line"><span class="attr">  template:</span></span><br><span class="line"><span class="attr">    metadata:</span></span><br><span class="line"><span class="attr">      labels:</span></span><br><span class="line"><span class="attr">        role:</span> <span class="string">web-app</span></span><br><span class="line"><span class="attr">    spec:</span></span><br><span class="line"><span class="attr">      terminationGracePeriodSeconds:</span> <span class="number">10</span></span><br><span class="line"><span class="attr">      containers:</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">          image:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">          ports:</span></span><br><span class="line"><span class="attr">            - containerPort:</span> <span class="number">80</span></span><br><span class="line"><span class="attr">          volumeMounts:</span></span><br><span class="line"><span class="attr">            - mountPath:</span> <span class="string">/usr/share/nginx/html</span></span><br><span class="line"><span class="attr">              name:</span> <span class="string">nginx-persistent-storage</span> <span class="comment"># 和下面的pvc名称对应</span></span><br><span class="line"><span class="attr">  volumeClaimTemplates:</span> <span class="comment"># pvc模板</span></span><br><span class="line"><span class="attr">    - metadata:</span></span><br><span class="line"><span class="attr">        name:</span> <span class="string">nginx-persistent-storage</span> <span class="comment"># pvc名称</span></span><br><span class="line"><span class="attr">      spec:</span></span><br><span class="line"><span class="attr">        storageClassName:</span> <span class="string">managed-nfs-storage</span> <span class="comment"># 指定StorageClass名称</span></span><br><span class="line"><span class="attr">        accessModes:</span> <span class="string">["ReadWriteMany"]</span></span><br><span class="line"><span class="attr">        resources:</span></span><br><span class="line"><span class="attr">          requests:</span></span><br><span class="line"><span class="attr">            storage:</span> <span class="number">100</span><span class="string">Mi</span></span><br></pre></td></tr></table></figure><p></p><p>创建该StatefulSet，观察pod的创建过程：</p><p><img src="img/QQ截图20191127163115.png" alt="QQ截图20191127163115.png"></p><p>可以看到，pod的创建是严格one by one的，因为我们定义的StatefulSet的名称位nginx-sc，所以Pod的名称分别位nginx-sc-0、nginx-sc-1和nginx-sc-2。</p><p>查看对应的PVC和PV：</p><p><img src="img/QQ截图20191127163428.png" alt="QQ截图20191127163428.png"></p><p>状态为Bound。</p><p>删除Pod，再次观察Pod的创建过程：</p><p><img src="img/QQ截图20191127172411.png" alt="QQ截图20191127172411.png"></p><p>可以看到顺序性是严格保证的。</p><p>进入到Pod内部，查看其hostname：</p><p><img src="img/QQ截图20191127172632.png" alt="QQ截图20191127172632.png"></p><p>hostname和pod名称一致。</p><p>到192.168.33.13的/nfs目录下可以看到挂载了三个nginx目录：</p><p><img src="img/QQ截图20191127172826.png" alt="QQ截图20191127172826.png"></p><blockquote><p>《Kubernetes权威指南(第4版)》读书笔记</p></blockquote><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Tue Dec 17 2019 19:26:13 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;前面介绍的Pod管理对象，如RC/RS、Deployment、DaemonSet等都是面向无状态服务的，而对于有状态的应用，比如MySQL集群，MongoDB集群等，则可以使用StatefulSet来完成。有状态的应用集群通常有以下这些特点：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;每个节点都有固定的身份ID，通过这个ID，集群中的成员可以相互发现并通信；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;集群的规模是比较固定的，集群规模不能随意变动；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;集群中的每个节点都是有状态的，通常会持久化数据到永久存储中。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;
    
    </summary>
    
    
      <category term="Kubernetes" scheme="http://mrbird.cc/tags/Kubernetes/"/>
    
      <category term="MongoDB" scheme="http://mrbird.cc/tags/MongoDB/"/>
    
  </entry>
  
  <entry>
    <title>Kubernetes StorageClass实践</title>
    <link href="http://mrbird.cc/Kubernetes-StorageClass-Practice.html"/>
    <id>http://mrbird.cc/Kubernetes-StorageClass-Practice.html</id>
    <published>2019-11-26T06:51:06.000Z</published>
    <updated>2019-11-29T12:30:24.281Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Tue Dec 17 2019 19:26:13 GMT+0800 (GMT+08:00) --><p>手动创建PV不仅繁琐，还可能造成资源浪费。比如某个PV定义的存储空间为10Gi，该PV被某个声明需要8Gi内存的PVC绑定上了，这时候该PV处于Bound状态，无法再和别的PVC进行绑定，PV上剩下的2Gi内存实际上浪费的。StorageClass可以根据PVC的声明，动态创建对应的PV，这样不仅省去了创建PV的过程，还实现了存储资源的动态供应。</p><a id="more"></a><h2 id="StorageClass构成"><a href="#StorageClass构成" class="headerlink" title="StorageClass构成"></a>StorageClass构成</h2><p>StorageClass的定义主要包括名称、后端存储的提供者（provisioner）和后端存储的相关参数配置。StorageClass一旦被创建出来，则将无法修改。如需更改，则只能删除原StorageClass的定义重建。</p><p>举个简单的StorageClass配置：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">storage.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">StorageClass</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">managed-nfs-storage</span> <span class="comment"># StorageClass名称</span></span><br><span class="line"><span class="attr">provisioner:</span> <span class="string">fuseim.pri/ifs</span>  <span class="comment"># 指定具体存储的提供者</span></span><br><span class="line"><span class="attr">parameters:</span> <span class="comment"># 后端存储相关参数配置</span></span><br><span class="line"><span class="attr">  archiveOnDelete:</span> <span class="string">"false"</span></span><br></pre></td></tr></table></figure><p></p><p>不同的StorageClass主要区别在于：不同的存储提供者需要填写不同的参数配置，下面实现个NFS作为动态StorageClass存储的例子。</p><h2 id="基于NFS存储类型的实践"><a href="#基于NFS存储类型的实践" class="headerlink" title="基于NFS存储类型的实践"></a>基于NFS存储类型的实践</h2><p>NFS环境在上一节已经搭建好了，IP为192.168.33.13，路径为/nfs。</p><p>在master节点上克隆相关代码：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/kubernetes-incubator/external-storage.git</span><br></pre></td></tr></table></figure><p></p><p>切换到<code>external-storage/nfs-client/deploy目录</code>：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> external-storage/nfs-client/deploy</span><br></pre></td></tr></table></figure><p></p><p>创建RBAC：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl create -f rbac.yml</span><br></pre></td></tr></table></figure><p></p><p><img src="img/QQ截图20191126155024.png" alt="QQ截图20191126155024.png"></p><p>接着部署NFS Client Provisioner，部署前修改deployment.yml：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">nfs-client-provisioner</span></span><br><span class="line"><span class="attr">  labels:</span></span><br><span class="line"><span class="attr">    app:</span> <span class="string">nfs-client-provisioner</span></span><br><span class="line">  <span class="comment"># replace with namespace where provisioner is deployed</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">default</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  replicas:</span> <span class="number">1</span></span><br><span class="line"><span class="attr">  selector:</span></span><br><span class="line"><span class="attr">    matchLabels:</span></span><br><span class="line"><span class="attr">      app:</span> <span class="string">nfs-client-provisioner</span></span><br><span class="line"><span class="attr">  strategy:</span></span><br><span class="line"><span class="attr">    type:</span> <span class="string">Recreate</span></span><br><span class="line"><span class="attr">  selector:</span></span><br><span class="line"><span class="attr">    matchLabels:</span></span><br><span class="line"><span class="attr">      app:</span> <span class="string">nfs-client-provisioner</span></span><br><span class="line"><span class="attr">  template:</span></span><br><span class="line"><span class="attr">    metadata:</span></span><br><span class="line"><span class="attr">      labels:</span></span><br><span class="line"><span class="attr">        app:</span> <span class="string">nfs-client-provisioner</span></span><br><span class="line"><span class="attr">    spec:</span></span><br><span class="line"><span class="attr">      serviceAccountName:</span> <span class="string">nfs-client-provisioner</span></span><br><span class="line"><span class="attr">      containers:</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">nfs-client-provisioner</span></span><br><span class="line"><span class="attr">          image:</span> <span class="string">quay.io/external_storage/nfs-client-provisioner:latest</span></span><br><span class="line"><span class="attr">          volumeMounts:</span></span><br><span class="line"><span class="attr">            - name:</span> <span class="string">nfs-client-root</span></span><br><span class="line"><span class="attr">              mountPath:</span> <span class="string">/persistentvolumes</span></span><br><span class="line"><span class="attr">          env:</span></span><br><span class="line"><span class="attr">            - name:</span> <span class="string">PROVISIONER_NAME</span></span><br><span class="line"><span class="attr">              value:</span> <span class="string">mrbird.cc/nfs</span> <span class="comment"># 名称随你定义</span></span><br><span class="line"><span class="attr">            - name:</span> <span class="string">NFS_SERVER</span></span><br><span class="line"><span class="attr">              value:</span> <span class="number">192.168</span><span class="number">.33</span><span class="number">.13</span> <span class="comment"># NFS 服务IP</span></span><br><span class="line"><span class="attr">            - name:</span> <span class="string">NFS_PATH</span></span><br><span class="line"><span class="attr">              value:</span> <span class="string">/nfs</span> <span class="comment"># NFS 目录</span></span><br><span class="line"><span class="attr">      volumes:</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">nfs-client-root</span></span><br><span class="line"><span class="attr">          nfs:</span></span><br><span class="line"><span class="attr">            server:</span> <span class="number">192.168</span><span class="number">.33</span><span class="number">.13</span> <span class="comment"># NFS 服务IP</span></span><br><span class="line"><span class="attr">            path:</span> <span class="string">/nfs</span> <span class="comment"># NFS 目录</span></span><br></pre></td></tr></table></figure><p></p><p>然后创建该deployment：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl create -f deployment.yml</span><br></pre></td></tr></table></figure><p></p><p>修改class.yaml配置：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">storage.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">StorageClass</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">managed-nfs-storage</span> <span class="comment"># StorageClass名称，随你定义</span></span><br><span class="line"><span class="attr">provisioner:</span> <span class="string">mrbird.cc/nfs</span> <span class="comment"># 和上面deployment里定义的一致</span></span><br><span class="line"><span class="attr">parameters:</span></span><br><span class="line"><span class="attr">  archiveOnDelete:</span> <span class="string">"false"</span></span><br></pre></td></tr></table></figure><p></p><p>创建这个StorageClass：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl create -f class.yml</span><br></pre></td></tr></table></figure><p></p><p><img src="img/QQ截图20191126160143.png" alt="QQ截图20191126160143.png"></p><p>创建PVC，PVC的定义对应test-claim.yml：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">kind:</span> <span class="string">PersistentVolumeClaim</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">test-claim</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  storageClassName:</span> <span class="string">managed-nfs-storage</span> <span class="comment"># 指定StorageClass名称，即我们上面定义的StorageClass</span></span><br><span class="line"><span class="attr">  accessModes:</span></span><br><span class="line"><span class="bullet">    -</span> <span class="string">ReadWriteMany</span></span><br><span class="line"><span class="attr">  resources:</span> </span><br><span class="line"><span class="attr">    requests:</span></span><br><span class="line"><span class="attr">      storage:</span> <span class="number">1</span><span class="string">Mi</span></span><br></pre></td></tr></table></figure><p></p><p>创建这个PVC:</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl create -f <span class="built_in">test</span>-claim.yml</span><br></pre></td></tr></table></figure><p></p><p><img src="img/QQ截图20191126160628.png" alt="QQ截图20191126160628.png"></p><p>状态为Bound，说明已经成功绑定上了存储。</p><p>查看PV，会看到系统自动创建了PV： <img src="img/QQ截图20191126161957.png" alt="QQ截图20191126161957.png"></p><p>自动创建的PV名称为pvc-3b8c5364-aadb-4b07-a3b5-fddad280fc98。</p><p>最后，修改test-pod.yml配置：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">test-pod</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  containers:</span></span><br><span class="line"><span class="attr">  - name:</span> <span class="string">test-pod</span></span><br><span class="line"><span class="attr">    image:</span> <span class="string">busybox</span> <span class="comment"># 修改为这个，原先的镜像地址需要科学上网</span></span><br><span class="line"><span class="attr">    command:</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">"/bin/sh"</span></span><br><span class="line"><span class="attr">    args:</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">"-c"</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">"touch /mnt/SUCCESS &amp;&amp; exit 0 || exit 1"</span></span><br><span class="line"><span class="attr">    volumeMounts:</span></span><br><span class="line"><span class="attr">      - name:</span> <span class="string">nfs-pvc</span></span><br><span class="line"><span class="attr">        mountPath:</span> <span class="string">"/mnt"</span></span><br><span class="line"><span class="attr">  restartPolicy:</span> <span class="string">"Never"</span></span><br><span class="line"><span class="attr">  volumes:</span></span><br><span class="line"><span class="attr">    - name:</span> <span class="string">nfs-pvc</span></span><br><span class="line"><span class="attr">      persistentVolumeClaim:</span></span><br><span class="line"><span class="attr">        claimName:</span> <span class="string">test-claim</span> <span class="comment"># 指定PVC名称，对应上面创建的PVC</span></span><br></pre></td></tr></table></figure><p></p><p>该Pod主要就是通过busybox在/mnt目录下创建了个SUCCESS文件。</p><p>创建该Pod：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl create -f <span class="built_in">test</span>-pod.yml</span><br></pre></td></tr></table></figure><p></p><p><img src="img/QQ截图20191126160933.png" alt="QQ截图20191126160933.png"></p><p>状态为Completed，说明busybox成功执行完了命令并结束了。如果一切顺利的话，在192.168.33.13的/nfs目录下会看到busybox pod创建的SUCCESS文件:</p><p><img src="img/QQ截图20191126161215.png" alt="QQ截图20191126161215.png"></p><p>可以看到/nfs目录下新增了一个目录，目录名称格式为：[namespace]-[pvc名称]-[pv名称]。</p><p>我们还可以玩一下另一个测试，新建一个test-pod-rc.yml文件：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ReplicationController</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">busybox</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  replicas:</span> <span class="number">2</span> <span class="comment"># 副本数为2，为了测试共享存储</span></span><br><span class="line"><span class="attr">  selector:</span></span><br><span class="line"><span class="attr">    name:</span> <span class="string">busybox</span></span><br><span class="line"><span class="attr">  template:</span></span><br><span class="line"><span class="attr">    metadata:</span></span><br><span class="line"><span class="attr">      labels:</span></span><br><span class="line"><span class="attr">        name:</span> <span class="string">busybox</span></span><br><span class="line"><span class="attr">    spec:</span></span><br><span class="line"><span class="attr">      containers:</span></span><br><span class="line"><span class="attr">        - image:</span> <span class="string">busybox</span></span><br><span class="line"><span class="attr">          command:</span></span><br><span class="line"><span class="bullet">            -</span> <span class="string">sh</span></span><br><span class="line"><span class="bullet">            -</span> <span class="bullet">-c</span></span><br><span class="line"><span class="bullet">            -</span> <span class="string">'while true; do sleep $(($RANDOM % 5 + 5)); done'</span></span><br><span class="line"><span class="attr">          imagePullPolicy:</span> <span class="string">IfNotPresent</span></span><br><span class="line"><span class="attr">          name:</span> <span class="string">busybox</span></span><br><span class="line"><span class="attr">          volumeMounts:</span></span><br><span class="line"><span class="attr">            - name:</span> <span class="string">nfs</span></span><br><span class="line"><span class="attr">              mountPath:</span> <span class="string">"/mnt"</span></span><br><span class="line"><span class="attr">      volumes:</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">nfs</span></span><br><span class="line"><span class="attr">          persistentVolumeClaim:</span></span><br><span class="line"><span class="attr">            claimName:</span> <span class="string">test-claim</span> <span class="comment"># 指定PVC名称，对应上面创建的PVC</span></span><br></pre></td></tr></table></figure><p></p><p>上面busybox做的事情很简单，就是无限期休眠。创建该rc：</p><p><img src="img/QQ截图20191126164355.png" alt="QQ截图20191126164355.png"></p><p>可以看到，pod分别部署到了node1和node2上。到node1节点上，进入busybox容器内部的/mnt目录，在该目录下创建一个hello文件：</p><p><img src="img/QQ截图20191126164821.png" alt="QQ截图20191126164821.png"></p><p>然后到node2节点上，进入busybox容器内部/mnt目录，观察刚刚在node1节点busybox容器内部创建的hello文件是否已经同步过来了：</p><p><img src="img/QQ截图20191126165107.png" alt="QQ截图20191126165107.png"></p><p>可以看到，文件同步成功。并且前面例子创建SUCCESS也同步过来了，这是因为它们指定了同一个PVC。</p><p>回到NFS服务器的/nfs目录下，可以看到刚刚创建的hello文件：</p><p><img src="img/QQ截图20191126165229.png" alt="QQ截图20191126165229.png"></p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Tue Dec 17 2019 19:26:13 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;手动创建PV不仅繁琐，还可能造成资源浪费。比如某个PV定义的存储空间为10Gi，该PV被某个声明需要8Gi内存的PVC绑定上了，这时候该PV处于Bound状态，无法再和别的PVC进行绑定，PV上剩下的2Gi内存实际上浪费的。StorageClass可以根据PVC的声明，动态创建对应的PV，这样不仅省去了创建PV的过程，还实现了存储资源的动态供应。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Kubernetes" scheme="http://mrbird.cc/tags/Kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>Kubernetes PV/PVC</title>
    <link href="http://mrbird.cc/Kubernetes-PV-PVC.html"/>
    <id>http://mrbird.cc/Kubernetes-PV-PVC.html</id>
    <published>2019-11-25T01:02:49.000Z</published>
    <updated>2019-11-29T12:30:24.280Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Tue Dec 17 2019 19:26:13 GMT+0800 (GMT+08:00) --><p>在Kubernetes中，我们虽然可以使用volume将容器内目录挂载到宿主机目录上，但由于Pod调度的不确定性，这种数据存储方式是不牢靠的。对于有状态的应用，我们希望无论Pod被调度到哪个节点上，它们的数据总能够完整地恢复，这时候我们就不能用volume挂载了，而应该使用“网络共享存储”。PV/PVC就是用于解决问题而存在的，它们屏蔽了底层存储实现的细节，使得我们很容易上手使用。</p><a id="more"></a><h2 id="PV"><a href="#PV" class="headerlink" title="PV"></a>PV</h2><p>PersistentVolume（PV）是对底层网络共享存储的抽象，将共享存储定义为一种“资源”，Kubernetes支持的PV类型如下：</p><table><tr><th>类型</th><th>描述</th></tr><tr><td>AWSElasticBlockStore</td><td>AWS公有云提供的ElasticBlockStore</td></tr><tr><td>AzureFile</td><td>Azure公有云提供的File</td></tr><tr><td>AzureDisk</td><td>Azure公有云提供的Disk</td></tr><tr><td>CephFS</td><td>一种开源共享存储系统</td></tr><tr><td>FC（Fibre Channel）</td><td>光纤存储设备</td></tr><tr><td>FlexVolume</td><td>一种插件式的存储机制</td></tr><tr><td>Flocker</td><td>一种开源共享存储系统</td></tr><tr><td>GCEPersistentDisk</td><td>GCE公有云提供的PersistentDisk</td></tr><tr><td>Glusterfs</td><td>一种开源共享存储系统</td></tr><tr><td>HostPath</td><td>宿主机目录，仅用于单机测试</td></tr><tr><td>iSCSI</td><td>iSCSI存储设备</td></tr><tr><td>Local</td><td>本地存储设备，从Kubernetes 1.7版本引入，到1.14版本时更新为稳定版，目前可以通过指定块（Block）设备提供Local PV，或通过社区开发的sig-storage-local-static-provisioner插件<a href="https://github.com/kubernetes-sigs/sigstorage-local-static-provisioner" target="_blank" rel="noopener">https://github.com/kubernetes-sigs/sigstorage-local-static-provisioner</a>来管理Local PV的生命周期</td></tr><tr><td>NFS</td><td>网络文件系统</td></tr><tr><td>Portworx Volumes</td><td>Portworx提供的存储服务</td></tr><tr><td>Quobyte Volumes</td><td>Quobyte提供的存储服务</td></tr><tr><td>RBD（Ceph Block Device）</td><td>Ceph块存储</td></tr><tr><td>ScaleIO Volumes</td><td>DellEMC的存储设备</td></tr><tr><td>StorageOS</td><td>StorageOS提供的存储服务</td></tr><tr><td>VsphereVolume</td><td>VMWare提供的存储系统</td></tr></table><p>举个PV配置文件例子：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">PersistentVolume</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">nfs</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  capacity:</span></span><br><span class="line"><span class="attr">    storage:</span> <span class="number">1</span><span class="string">Gi</span> <span class="comment"># 具有1Gi内存</span></span><br><span class="line"><span class="attr">  accessModes:</span></span><br><span class="line"><span class="bullet">    -</span> <span class="string">ReadWriteMany</span> <span class="comment"># 具有读写权限，允许被多个Node挂载</span></span><br><span class="line"><span class="attr">  persistentVolumeReclaimPolicy:</span> <span class="string">Retain</span> <span class="comment"># 回收策略，这里为保留</span></span><br><span class="line"><span class="attr">  nfs:</span> <span class="comment"># pv类型为NFS类型</span></span><br><span class="line"><span class="attr">    server:</span> <span class="number">192.168</span><span class="number">.33</span><span class="number">.13</span></span><br><span class="line"><span class="attr">    path:</span> <span class="string">"/nfs"</span></span><br></pre></td></tr></table></figure><p></p><p>PV支持的accessModes有：</p><ul><li>ReadWriteOnce（RWO）：读写权限，并且只能被单个Node挂载。</li><li>ReadOnlyMany（ROX）：只读权限，允许被多个Node挂载。</li><li>ReadWriteMany（RWX）：读写权限，允许被多个Node挂载。</li></ul><p>不同的存储提供者支持的accessModes：</p><table><thead><tr><th align="left">Volume Plugin</th><th align="center">ReadWriteOnce</th><th align="center">ReadOnlyMany</th><th align="center">ReadWriteMany</th></tr></thead><tbody><tr><td align="left">AWSElasticBlockStore</td><td align="center">✓</td><td align="center">-</td><td align="center">-</td></tr><tr><td align="left">AzureFile</td><td align="center">✓</td><td align="center">✓</td><td align="center">✓</td></tr><tr><td align="left">AzureDisk</td><td align="center">✓</td><td align="center">-</td><td align="center">-</td></tr><tr><td align="left">CephFS</td><td align="center">✓</td><td align="center">✓</td><td align="center">✓</td></tr><tr><td align="left">Cinder</td><td align="center">✓</td><td align="center">-</td><td align="center">-</td></tr><tr><td align="left">CSI</td><td align="center">depends on the driver</td><td align="center">depends on the driver</td><td align="center">depends on the driver</td></tr><tr><td align="left">FC</td><td align="center">✓</td><td align="center">✓</td><td align="center">-</td></tr><tr><td align="left">FlexVolume</td><td align="center">✓</td><td align="center">✓</td><td align="center">depends on the driver</td></tr><tr><td align="left">Flocker</td><td align="center">✓</td><td align="center">-</td><td align="center">-</td></tr><tr><td align="left">GCEPersistentDisk</td><td align="center">✓</td><td align="center">✓</td><td align="center">-</td></tr><tr><td align="left">Glusterfs</td><td align="center">✓</td><td align="center">✓</td><td align="center">✓</td></tr><tr><td align="left">HostPath</td><td align="center">✓</td><td align="center">-</td><td align="center">-</td></tr><tr><td align="left">iSCSI</td><td align="center">✓</td><td align="center">✓</td><td align="center">-</td></tr><tr><td align="left">Quobyte</td><td align="center">✓</td><td align="center">✓</td><td align="center">✓</td></tr><tr><td align="left">NFS</td><td align="center">✓</td><td align="center">✓</td><td align="center">✓</td></tr><tr><td align="left">RBD</td><td align="center">✓</td><td align="center">✓</td><td align="center">-</td></tr><tr><td align="left">VsphereVolume</td><td align="center">✓</td><td align="center">-</td><td align="center">- (works when Pods are collocated)</td></tr><tr><td align="left">PortworxVolume</td><td align="center">✓</td><td align="center">-</td><td align="center">✓</td></tr><tr><td align="left">ScaleIO</td><td align="center">✓</td><td align="center">✓</td><td align="center">-</td></tr><tr><td align="left">StorageOS</td><td align="center">✓</td><td align="center">-</td><td align="center">-</td></tr></tbody></table><p>PV支持的persistentVolumeReclaimPolicy有：</p><ul><li>Retain，不清理, 保留 Volume（需要手动清理）</li><li>Recycle，删除数据，（只有 NFS 和 HostPath 支持）</li><li>Delete，删除存储资源，比如删除 AWS EBS 卷（只有 AWS EBS, GCE PD, Azure Disk 和 Cinder 支持）</li></ul><p>PV声明周期：</p><ul><li>Available：空闲状态；</li><li>Bound：已经绑定到某个PVC上；</li><li>Released：对应的PVC已经被删除，但资源还没有被集群收回；</li><li>Failed：PV自动回收失败。</li></ul><h2 id="PVC"><a href="#PVC" class="headerlink" title="PVC"></a>PVC</h2><p>PersistentVolumeClaim（PVC），对存储资源的需求申请，主要包括存储空间请求、访问模式、PV选择条件和存储类别等信息的设置。只有PVC和PV相匹配，才能绑定上。</p><p>定义一个PVC配置：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">kind: PersistentVolumeClaim</span><br><span class="line">apiVersion: v1</span><br><span class="line">metadata:</span><br><span class="line">  name: nfs</span><br><span class="line">spec:</span><br><span class="line">  accessModes:</span><br><span class="line">    - ReadWriteMany</span><br><span class="line">  resources:</span><br><span class="line">    requests:</span><br><span class="line">      storage: 1Gi</span><br></pre></td></tr></table></figure><p></p><p>该PVC声明了需要1Gi存储空间，访问模式为ReadWriteMany，刚刚定义的PV符合这个要求，所以会被绑定上。</p><h2 id="实践"><a href="#实践" class="headerlink" title="实践"></a>实践</h2><p>因为NFS类型存储演示起来方便，所以这里选择使用NFS作为存储提供者。</p><p>在<a href="https://mrbird.cc/Kubeadm-install-Kubernetes1-16-2-cluster.html">Kubeadm安装Kubernetes1.16.2集群</a>一节中，我们曾在以下虚拟机上搭建了Kubernetes集群:</p><table><thead><tr><th style="text-align:center">操作系统</th><th style="text-align:center">IP</th><th style="text-align:center">角色</th><th style="text-align:center">CPU核心数</th><th style="text-align:center">内存</th><th style="text-align:center">Hostname</th></tr></thead><tbody><tr><td style="text-align:center">centos7</td><td style="text-align:center">192.168.33.11</td><td style="text-align:center">master</td><td style="text-align:center">2</td><td style="text-align:center">4096M</td><td style="text-align:center">master</td></tr><tr><td style="text-align:center">centos7</td><td style="text-align:center">192.168.33.12</td><td style="text-align:center">worker</td><td style="text-align:center">2</td><td style="text-align:center">4096M</td><td style="text-align:center">node1</td></tr><tr><td style="text-align:center">centos7</td><td style="text-align:center">192.168.33.13</td><td style="text-align:center">worker</td><td style="text-align:center">2</td><td style="text-align:center">4096M</td><td style="text-align:center">node2</td></tr></tbody></table><p>为了方便，这里就不再创建新的虚拟机安装NFS，直接在192.168.33.13节点上准备好NFS环境。</p><p>在192.168.33.13节点上执行以下bash命令：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建目录</span></span><br><span class="line">mkdir /nfs</span><br><span class="line"></span><br><span class="line"><span class="comment"># 修改权限</span></span><br><span class="line">chmod 777 /nfs</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建exports文件</span></span><br><span class="line">vim /etc/exports</span><br></pre></td></tr></table></figure><p></p><p>exports内容如下所示：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/nfs *(rw,insecure,sync,no_subtree_check,no_root_squash)</span><br></pre></td></tr></table></figure><p></p><p>让配置生效：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">exportfs -r</span><br></pre></td></tr></table></figure><p></p><p>启动NFS：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">systemctl <span class="built_in">enable</span> nfs</span><br><span class="line">systemctl <span class="built_in">enable</span> rpcbind</span><br><span class="line">systemctl restart nfs</span><br><span class="line">systemctl restart rpcbind</span><br></pre></td></tr></table></figure><p></p><p>接着在master节点上，创建test-pv-pvc.yml配置文件：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">PersistentVolume</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">nfs-pv</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  capacity:</span></span><br><span class="line"><span class="attr">    storage:</span> <span class="number">1</span><span class="string">Gi</span></span><br><span class="line"><span class="attr">  accessModes:</span></span><br><span class="line"><span class="bullet">    -</span> <span class="string">ReadWriteMany</span></span><br><span class="line"><span class="attr">  nfs:</span></span><br><span class="line"><span class="attr">    server:</span> <span class="number">192.168</span><span class="number">.33</span><span class="number">.13</span></span><br><span class="line"><span class="attr">    path:</span> <span class="string">"/nfs"</span></span><br><span class="line"></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">PersistentVolumeClaim</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">nfs-pvc</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  accessModes:</span></span><br><span class="line"><span class="bullet">    -</span> <span class="string">ReadWriteMany</span></span><br><span class="line"><span class="attr">  resources:</span></span><br><span class="line"><span class="attr">    requests:</span></span><br><span class="line"><span class="attr">      storage:</span> <span class="number">1</span><span class="string">Gi</span></span><br><span class="line"></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ReplicationController</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">busybox</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  replicas:</span> <span class="number">1</span></span><br><span class="line"><span class="attr">  selector:</span></span><br><span class="line"><span class="attr">    name:</span> <span class="string">busybox</span></span><br><span class="line"><span class="attr">  template:</span></span><br><span class="line"><span class="attr">    metadata:</span></span><br><span class="line"><span class="attr">      labels:</span></span><br><span class="line"><span class="attr">        name:</span> <span class="string">busybox</span></span><br><span class="line"><span class="attr">    spec:</span></span><br><span class="line"><span class="attr">      containers:</span></span><br><span class="line"><span class="attr">        - image:</span> <span class="string">busybox</span></span><br><span class="line"><span class="attr">          command:</span></span><br><span class="line"><span class="bullet">            -</span> <span class="string">sh</span></span><br><span class="line"><span class="bullet">            -</span> <span class="bullet">-c</span></span><br><span class="line"><span class="bullet">            -</span> <span class="string">'while true; do echo hello world &gt; /mnt/index.html; sleep $(($RANDOM % 5 + 5)); done'</span></span><br><span class="line"><span class="attr">          imagePullPolicy:</span> <span class="string">IfNotPresent</span></span><br><span class="line"><span class="attr">          name:</span> <span class="string">busybox</span></span><br><span class="line"><span class="attr">          volumeMounts:</span></span><br><span class="line"><span class="attr">            - name:</span> <span class="string">nfs</span></span><br><span class="line"><span class="attr">              mountPath:</span> <span class="string">"/mnt"</span></span><br><span class="line"><span class="attr">      volumes:</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">nfs</span></span><br><span class="line"><span class="attr">          persistentVolumeClaim:</span></span><br><span class="line"><span class="attr">            claimName:</span> <span class="string">nfs-pvc</span></span><br><span class="line"></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ReplicationController</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  replicas:</span> <span class="number">1</span></span><br><span class="line"><span class="attr">  selector:</span></span><br><span class="line"><span class="attr">    name:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">  template:</span></span><br><span class="line"><span class="attr">    metadata:</span></span><br><span class="line"><span class="attr">      labels:</span></span><br><span class="line"><span class="attr">        name:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">    spec:</span></span><br><span class="line"><span class="attr">      containers:</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">          image:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">          ports:</span></span><br><span class="line"><span class="attr">            - name:</span> <span class="string">web</span></span><br><span class="line"><span class="attr">              containerPort:</span> <span class="number">80</span></span><br><span class="line"><span class="attr">          volumeMounts:</span></span><br><span class="line"><span class="attr">            - name:</span> <span class="string">nfs</span></span><br><span class="line"><span class="attr">              mountPath:</span> <span class="string">"/usr/share/nginx/html"</span></span><br><span class="line"><span class="attr">      volumes:</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">nfs</span></span><br><span class="line"><span class="attr">          persistentVolumeClaim:</span></span><br><span class="line"><span class="attr">            claimName:</span> <span class="string">nfs-pvc</span></span><br><span class="line"></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">nginx-service</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  ports:</span></span><br><span class="line"><span class="attr">    - port:</span> <span class="number">80</span></span><br><span class="line"><span class="attr">      nodePort:</span> <span class="number">30000</span></span><br><span class="line"><span class="attr">  type:</span> <span class="string">NodePort</span></span><br><span class="line"><span class="attr">  selector:</span></span><br><span class="line"><span class="attr">    name:</span> <span class="string">nginx</span></span><br></pre></td></tr></table></figure><p></p><p>上面的配置文件效果可以用下面这张图表示：</p><p><img src="img/QQ截图20191125142753.png" alt="QQ截图20191125142753.png"></p><p>主要过程就是busybox通过nfs-pvc绑定了nfs-pv，然后定时将hello world写到容器内部/mnt/index.html文件中，而容器内部/mnt和PV的/nfs目录挂载；nginx也通过nfs-pvc绑定了nfs-pv，将/nfs目录和容器内部/usr/share/nginx/html目录挂载；我们后续可以通过访问浏览器<a href="http://192.168.33.11:30000/" target="_blank" rel="noopener">http://192.168.33.11:30000/</a>地址查看效果。</p><p>创建该配置文件:</p><p><img src="img/QQ截图20191125143031.png" alt="QQ截图20191125143031.png"></p><p>查看192.168.33.13虚拟机/nfs目录下是否已经存在index.html文件，并查看内容：</p><p><img src="img/QQ截图20191125143126.png" alt="QQ截图20191125143126.png"></p><p>浏览器访问<a href="http://192.168.33.11:30000/" target="_blank" rel="noopener">http://192.168.33.11:30000/</a>：</p><p><img src="img/QQ截图20191125143416.png" alt="QQ截图20191125143416.png"></p><p>说明整个流程没问题。</p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Tue Dec 17 2019 19:26:13 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;在Kubernetes中，我们虽然可以使用volume将容器内目录挂载到宿主机目录上，但由于Pod调度的不确定性，这种数据存储方式是不牢靠的。对于有状态的应用，我们希望无论Pod被调度到哪个节点上，它们的数据总能够完整地恢复，这时候我们就不能用volume挂载了，而应该使用“网络共享存储”。PV/PVC就是用于解决问题而存在的，它们屏蔽了底层存储实现的细节，使得我们很容易上手使用。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Kubernetes" scheme="http://mrbird.cc/tags/Kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>CI/CD实践笔记</title>
    <link href="http://mrbird.cc/CI-CD-Practice-Note.html"/>
    <id>http://mrbird.cc/CI-CD-Practice-Note.html</id>
    <published>2019-11-18T05:52:58.000Z</published>
    <updated>2019-11-23T06:13:43.424Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Tue Dec 17 2019 19:26:13 GMT+0800 (GMT+08:00) --><p>CICD（<strong>C</strong>ontinuous <strong>I</strong>ntegration/<strong>C</strong>ontinuous <strong>D</strong>eployment），持续集成持续部署的意思。完成CICD实践需要Kubernetes集群，Harbor，GitLab和Jenkins等软件配合完成，在前面几篇博客中，我已经搭建好了Kubernetes集群，并且在master节点（192.168.33.11,CentOS）上安装好了Harbor、GitLab和Jenkins，有需要可以参考下。<a id="more"></a></p><h2 id="实践准备"><a href="#实践准备" class="headerlink" title="实践准备"></a>实践准备</h2><h3 id="CICD流程图"><a href="#CICD流程图" class="headerlink" title="CICD流程图"></a>CICD流程图</h3><p>CICD的大致流程如下图所示：</p><p><img src="img/QQ截图20191118145712.png" alt="QQ截图20191118145712.png"></p><ol><li><p>开发者将最新代码提交到GitLab仓库；</p></li><li><p>GitLab WebHook触发Jenkins构建流水线：</p><p>2.1 拉取最新代码；</p><p>2.2 Maven打包，打包过程中会先进行单元测试；</p><p>2.3 单元测试通过，构建Docker镜像；</p><p>2.4 将最新镜像推送到Harbor；</p><p>2.5 更新Kubernetes相关配置镜像版本。</p></li><li><p>Kubernetes感知到镜像更新，从Harbor拉取最新镜像，滚动升级；</p></li><li><p>开发者看到最新的代码效果。</p></li></ol><h3 id="项目准备"><a href="#项目准备" class="headerlink" title="项目准备"></a>项目准备</h3><p>这里我们在Windows上使用IDEA、Spring Boot构建一个简单的Java Web项目，项目名为demo，项目pom如下所示：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">project</span> <span class="attr">xmlns</span>=<span class="string">"http://maven.apache.org/POM/4.0.0"</span> <span class="attr">xmlns:xsi</span>=<span class="string">"http://www.w3.org/2001/XMLSchema-instance"</span></span></span><br><span class="line"><span class="tag">         <span class="attr">xsi:schemaLocation</span>=<span class="string">"http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">modelVersion</span>&gt;</span>4.0.0<span class="tag">&lt;/<span class="name">modelVersion</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">parent</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-parent<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.2.1.RELEASE<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">relativePath</span>/&gt;</span> <span class="comment">&lt;!-- lookup parent from repository --&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">parent</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>cc.mrbird<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>demo<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>0.0.1-SNAPSHOT<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>demo<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>Demo project for Spring Boot<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">properties</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">java.version</span>&gt;</span>1.8<span class="tag">&lt;/<span class="name">java.version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">properties</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-web<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-test<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">scope</span>&gt;</span>test<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">build</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">plugins</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-maven-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">plugins</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">build</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">project</span>&gt;</span></span><br></pre></td></tr></table></figure><p></p><p>在Boot入口类中添加一个简单的Controller方法：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@RestController</span></span><br><span class="line"><span class="meta">@SpringBootApplication</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DemoApplication</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        SpringApplication.run(DemoApplication.class, args);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@GetMapping</span>(<span class="string">"hello"</span>)</span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">index</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="string">"hello world"</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><p>上面方法提供了一个<code>/hello</code>接口，简单返回<code>hello world</code>信息。</p><p>接着编写一个简单的单元测试：</p><p><img src="img/QQ截图20191118151519.png" alt="QQ截图20191118151519.png"></p><p>代码如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@RunWith</span>(SpringRunner.class)</span><br><span class="line"><span class="meta">@SpringBootTest</span></span><br><span class="line"><span class="meta">@AutoConfigureMockMvc</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DemoApplicationTests</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> MockMvc mockMvc;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">testIndex</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        mockMvc.perform(MockMvcRequestBuilders.get(<span class="string">"/hello"</span>))</span><br><span class="line">                .andExpect(MockMvcResultMatchers.content().string(<span class="string">"hello world"</span>));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><p>最后在项目的根目录下新建一个Dockerfile：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">FROM openjdk:8u212-jre</span><br><span class="line">MAINTAINER MrBird 852252810@qq.com</span><br><span class="line"></span><br><span class="line">COPY target/demo-0.0.1-SNAPSHOT.jar /demo-0.0.1-SNAPSHOT.jar</span><br><span class="line">ENTRYPOINT [&quot;java&quot;, &quot;-jar&quot;, &quot;/demo-0.0.1-SNAPSHOT.jar&quot;]</span><br></pre></td></tr></table></figure><p></p><p>至此简单的Java Web项目就准备好了。</p><h3 id="GitLab准备"><a href="#GitLab准备" class="headerlink" title="GitLab准备"></a>GitLab准备</h3><p>注册一个新的GitLab账号，比如mrbird，然后在GitLab新建一个项目，名称为Demo：</p><p><img src="img/QQ截图20191118153441.png" alt="QQ截图20191118153441.png"></p><p>因为我们后续需要在Windows下将项目提交到GitLab，并在192.168.33.11上拉取该项目，所以我们需要在Windows和192.168.33.11服务器上生成SSH Key，并添加到GitLab中。</p><p>在Windows及192.168.33.11虚拟机通过下面的命令生成SSH Key：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen -t rsa -C <span class="string">"852252810@qq.com"</span></span><br><span class="line"></span><br><span class="line">cat ~/.ssh/id_rsa.pub</span><br></pre></td></tr></table></figure><p></p><p>将SSH Key添加到GitLab：</p><p><img src="img/QQ截图20191118153948.png" alt="QQ截图20191118153948.png"></p><p>这样我们后续的push和pull操作就不需要输入用户名了。</p><p>接着我们将上面创建的Demo项目推送到GitLab中（在IDEA的Terminal窗口中操作，个人习惯用命令行）：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"># 配置Git</span><br><span class="line">git config --global user.name &quot;mrbird&quot;</span><br><span class="line">git config --global user.email &quot;852252810@qq.com&quot;</span><br><span class="line"></span><br><span class="line"># 初始化Git仓库</span><br><span class="line">git init</span><br><span class="line"></span><br><span class="line"># commit</span><br><span class="line">git commit -am init</span><br><span class="line"></span><br><span class="line"># 添加远程仓库</span><br><span class="line">git remote add origin ssh://git@gitlab.mrbird.cc:2223/mrbird/demo.git</span><br><span class="line"></span><br><span class="line"># 推送到远程仓库</span><br><span class="line">git push origin master</span><br></pre></td></tr></table></figure><p></p><p>推送成功后，回到GitLab页面可以看到项目已经推送OK了：</p><p><img src="img/QQ截图20191120162821.png" alt="QQ截图20191118154957.png"></p><h3 id="Kubernetes部署SpringBoot项目"><a href="#Kubernetes部署SpringBoot项目" class="headerlink" title="Kubernetes部署SpringBoot项目"></a>Kubernetes部署SpringBoot项目</h3><p>在192.168.33.11服务器上将刚刚的项目从GitLab中克隆下来:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git clone ssh://git@gitlab.mrbird.cc:2223/mrbird/demo.git</span><br></pre></td></tr></table></figure><p>因为打包需要Maven环境，所以接着配置Maven：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 下载Maven安装包</span><br><span class="line">wget http://mirrors.tuna.tsinghua.edu.cn/apache/maven/maven-3/3.6.2/binaries/apache-maven-3.6.2-bin.tar.gz</span><br><span class="line"></span><br><span class="line"># 解压</span><br><span class="line">tar -xzvf apache-maven-3.6.2-bin.tar.gz</span><br><span class="line"></span><br><span class="line"># 修改环境变量</span><br><span class="line">vim /etc/profile</span><br></pre></td></tr></table></figure><p></p><p>添加如下内容：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">M2_HOME=/home/vagrant/apache-maven-3.6.2</span><br><span class="line">export PATH=$PATH:$JAVA_HOME/bin:$M2_HOME/bin</span><br></pre></td></tr></table></figure><p></p><p>让修改生效：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure><p></p><p>验证下是否安装成功：</p><p><img src="img/QQ截图20191118164351.png" alt="QQ截图20191118164351.png"></p><p>环境准备好后，将目录切换到刚刚<code>git clone</code>的demo目录下，执行<code>mvn clean package</code>命令，完成后可以看到fat jar：</p><p><img src="img/QQ截图20191120162943.png" alt="QQ截图20191118171428.png"></p><p>接着执行<code>docker build -t docker.mrbird.cc/febs/demo .</code>命令构建docker镜像：</p><p><img src="img/QQ截图20191119184432.png" alt="QQ截图20191119184432.png"></p><p>构建成功后执行<code>docker push docker.mrbird.cc/febs/demo</code>命令推送到Harbor：</p><p><img src="img/QQ截图20191119184535.png" alt="QQ截图20191119184535.png"></p><p>访问Harbor管理页面，可以看到镜像已经推送上来了：</p><p><img src="img/QQ截图20191119184638.png" alt="QQ截图20191119184638.png"></p><p>接着编写个简单的Kubernetes配置文件（demo.yml）：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">demo-service</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  type:</span> <span class="string">NodePort</span></span><br><span class="line"><span class="attr">  ports:</span></span><br><span class="line"><span class="attr">    - port:</span> <span class="number">8080</span></span><br><span class="line"><span class="attr">      targetPort:</span> <span class="number">8080</span></span><br><span class="line"><span class="attr">      nodePort:</span> <span class="number">30000</span></span><br><span class="line"><span class="attr">  selector:</span></span><br><span class="line"><span class="attr">    name:</span> <span class="string">demo-app</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">demo-deployment</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  selector:</span></span><br><span class="line"><span class="attr">    matchLabels:</span></span><br><span class="line"><span class="attr">      name:</span> <span class="string">demo-app</span></span><br><span class="line"><span class="attr">  replicas:</span> <span class="number">2</span></span><br><span class="line"><span class="attr">  template:</span></span><br><span class="line"><span class="attr">    metadata:</span></span><br><span class="line"><span class="attr">      labels:</span></span><br><span class="line"><span class="attr">        name:</span> <span class="string">demo-app</span></span><br><span class="line"><span class="attr">    spec:</span></span><br><span class="line"><span class="attr">      containers:</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">demo</span></span><br><span class="line"><span class="attr">          image:</span> <span class="string">docker.mrbird.cc/febs/demo</span></span><br><span class="line"><span class="attr">          ports:</span></span><br><span class="line"><span class="attr">            - containerPort:</span> <span class="number">8080</span></span><br><span class="line"><span class="attr">          resources:</span></span><br><span class="line"><span class="attr">            limits:</span></span><br><span class="line"><span class="attr">              cpu:</span> <span class="number">500</span><span class="string">m</span></span><br><span class="line"><span class="attr">              memory:</span> <span class="number">500</span><span class="string">Mi</span></span><br><span class="line"><span class="attr">            requests:</span></span><br><span class="line"><span class="attr">              cpu:</span> <span class="number">200</span><span class="string">m</span></span><br><span class="line"><span class="attr">              memory:</span> <span class="number">200</span><span class="string">Mi</span></span><br></pre></td></tr></table></figure><p>运行该配置:</p><p><img src="img/QQ截图20191119191043.png" alt="QQ截图20191119191043.png"></p><p>使用浏览器访问<a href="http://192.168.33.11:30000/hello" target="_blank" rel="noopener">http://192.168.33.11:30000/hello</a>:</p><p><img src="img/QQ截图20191119192134.png" alt="QQ截图20191119192134.png"></p><p>至此Spring Boot项目已经成功运行在Kubernetes集群中了，接下来开始演示如何进行CICD。</p><h2 id="CICD实践"><a href="#CICD实践" class="headerlink" title="CICD实践"></a>CICD实践</h2><p>就如上面CICD流程图所示，第一步将本地开发代码push到GitLab已经实现了，接下来开始配置GitLab WebHook。</p><h3 id="GitLab-WebHook"><a href="#GitLab-WebHook" class="headerlink" title="GitLab WebHook"></a>GitLab WebHook</h3><p>在Jenkins中创建流水线前，先修改两处Jenkins配置。点击Jenkins管理页面的<strong>系统管理</strong>菜单 -&gt; <strong>全局安全配置</strong>：</p><p><img src="img/QQ截图20191120091638.png" alt="QQ截图20191120091638.png"></p><p>关闭CSRF保护和开启匿名用户具有可读权限。</p><p>然后点击<strong>新建任务</strong>菜单，新增一个名称为demo的流水线，勾选<strong>触发远程构建</strong>：</p><p><img src="img/QQ截图20191120091910.png" alt="QQ截图20191120091910.png"></p><p>令牌设置为666666，触发地址为<code>JENKINS_URL/job/demo/build?token=TOKEN_NAME</code>，我们需要将这个地址配置为GitLab的WebHook中。</p><p>打开GitLab的Demo项目页面，点击左侧的设置菜单：</p><p><img src="img/QQ截图20191120092313.png" alt="QQ截图20191120092313.png"></p><p>选择integrations：</p><p><img src="img/QQ截图20191120092425.png" alt="QQ截图20191120092425.png"></p><p>其中<code>http://192.168.33.11:8081</code>为我的Jenkins地址，对应JENKINS_URL；666666是我们设置的令牌，对应TOKEN_NAME。触发事件选择push event就行。</p><p>保存WebHook的时候如果提示<span style="color:red;font-weight:600">Url is blocked: Requests to the local network are not allowed</span>的话，可以使用<a href="mailto:admin@example.com" target="_blank" rel="noopener">admin@example.com</a>账号登录GitLab（密码就是你第一次登录修改的密码），然后点击<strong>Admin Area</strong>-&gt;<strong>Settings</strong>-&gt;<strong>Network</strong>：</p><p><img src="img/QQ截图20191120093459.png" alt="QQ截图20191120093459.png"></p><p>勾选Allow requests to the local network from web hooks and services即可。保存后，重新使用mrbird账号登录重新配置WebHook即可。</p><p>配置好后，测试一下：</p><p><img src="img/QQ截图20191120094028.png" alt="QQ截图20191120094028.png"></p><p>页面弹出如下提示说明配置🆗：</p><p><img src="img/QQ截图20191120094121.png" alt="QQ截图20191120094121.png"></p><h3 id="代码拉取"><a href="#代码拉取" class="headerlink" title="代码拉取"></a>代码拉取</h3><p>Maven打包前需要先用git命令将代码拉取下来。编辑刚刚创建的流水线，在Pipeline script中添加如下代码：</p><p><img src="img/QQ截图20191120141218.png" alt="QQ截图20191120141218.png"></p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!groovy</span></span><br><span class="line">pipeline &#123;</span><br><span class="line">  agent any</span><br><span class="line">  environment &#123;</span><br><span class="line">    REPOSITORY=<span class="string">"ssh://git@gitlab.mrbird.cc:2223/mrbird/demo.git"</span></span><br><span class="line">  &#125;</span><br><span class="line">  stages &#123;</span><br><span class="line">    stage(<span class="string">'拉取代码'</span>) &#123;</span><br><span class="line">      steps &#123;</span><br><span class="line">        <span class="built_in">echo</span> <span class="string">"从GitLab地址<span class="variable">$&#123;REPOSITORY&#125;</span>拉取代码"</span></span><br><span class="line">        deleteDir()</span><br><span class="line">        git <span class="string">"<span class="variable">$&#123;REPOSITORY&#125;</span>"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><p>Pipeline script的基本模板为：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!groovy</span></span><br><span class="line">pipeline &#123;</span><br><span class="line">  agent any</span><br><span class="line">  environment &#123;</span><br><span class="line">    // 定义全局变量</span><br><span class="line">  &#125;</span><br><span class="line">  stages &#123;</span><br><span class="line">  	// 可以定义多个阶段</span><br><span class="line">    stage(<span class="string">'阶段名称'</span>) &#123;</span><br><span class="line">      steps &#123;</span><br><span class="line">        // 具体步骤</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><p>回到上面的Pipeline script代码，我们主要做了下面几件事：</p><ol><li><p>在environment中定义GitLab项目仓库地址变量，方便下面直接引用；</p></li><li><p>通过<code>echo</code>命令输出，方便后续从日志中观察跟踪；</p></li><li><p>通过<code>deleteDir()</code>清空工作区；</p></li><li><p>通过<code>git &quot;${REPOSITORY}&quot;</code>从指定Git仓库拉取代码。</p></li></ol><p>其中，使用environment中的变量时候，一定要用<code>&quot;${xx}&quot;</code>的方式引用；第3第4步的命令可以通过流水线语法来生成，比如生成清空当前目录的命令：</p><p><img src="img/QQ截图20191120141809.png" alt="QQ截图20191120141809.png"></p><p>生成通过Git拉取代码的命令：</p><p><img src="img/QQ截图20191120141908.png" alt="QQ截图20191120141908.png"></p><p>修改好流水线后，点击<strong>立即构建</strong>，看看我们的配置是否🆗：</p><p><img src="img/20191120142110.png" alt="20191120142110.png"></p><p>从日志来看，代码拉取是成功的。</p><h3 id="Maven打包和单元测试"><a href="#Maven打包和单元测试" class="headerlink" title="Maven打包和单元测试"></a>Maven打包和单元测试</h3><p>Jenkins 通过shell脚本调用mvn 命令的时候，是从/usr/bin 文件夹中找命令的，这个时候需要做个软链接：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ln -s /home/vagrant/apache-maven-3.6.2/bin/mvn /usr/bin/mvn</span><br></pre></td></tr></table></figure><p></p><p>更新流水线的Pipeline script，添加maven打包阶段命令：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!groovy</span></span><br><span class="line">pipeline &#123;</span><br><span class="line">  agent any</span><br><span class="line">  environment &#123;</span><br><span class="line">    REPOSITORY=<span class="string">"ssh://git@gitlab.mrbird.cc:2223/mrbird/demo.git"</span></span><br><span class="line">  &#125;</span><br><span class="line">  stages &#123;</span><br><span class="line">    stage(<span class="string">'拉取代码'</span>) &#123;</span><br><span class="line">      steps &#123;</span><br><span class="line">        <span class="built_in">echo</span> <span class="string">"从GitLab地址<span class="variable">$&#123;REPOSITORY&#125;</span>拉取代码"</span></span><br><span class="line">        deleteDir()</span><br><span class="line">        git <span class="string">"<span class="variable">$&#123;REPOSITORY&#125;</span>"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    stage(<span class="string">'代码编译及单元测试'</span>) &#123;</span><br><span class="line">      steps &#123;</span><br><span class="line">        <span class="built_in">echo</span> <span class="string">"开始编译代码和单元测试"</span></span><br><span class="line">        sh <span class="string">"mvn -U -am clean package"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><p>maven打包前会自动运行我们在项目里写好的单元测试，修改后，点击<strong>立即构建</strong>，查看日志（截取关键部分）：</p><p><img src="img/QQ截图20191121170401.png" alt="QQ截图20191120154051.png"></p><p><img src="img/QQ截图20191121170425.png" alt="QQ截图20191120154144.png"></p><p><img src="img/QQ截图20191121170512.png" alt="QQ截图20191120154249.png"></p><p>可以看到单元测试及打包成功。</p><h3 id="构建镜像及推送"><a href="#构建镜像及推送" class="headerlink" title="构建镜像及推送"></a>构建镜像及推送</h3><p>镜像构建和推送涉及命令较多，所以可以定义一个脚本：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim build_push.sh</span><br></pre></td></tr></table></figure><p></p><p>脚本内容如下所示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line"></span><br><span class="line">MODULE=$1</span><br><span class="line">TIME=`date &quot;+%Y%m%d%H%M&quot;`</span><br><span class="line">GIT_REVISION=`git log -1 --pretty=format:&quot;%h&quot;`</span><br><span class="line">IMAGE_NAME=docker.mrbird.cc/febs/$&#123;MODULE&#125;:$&#123;TIME&#125;_$&#123;GIT_REVISION&#125;</span><br><span class="line"></span><br><span class="line">docker build -t $&#123;IMAGE_NAME&#125; .</span><br><span class="line"></span><br><span class="line">docker push $&#123;IMAGE_NAME&#125;</span><br><span class="line"></span><br><span class="line">echo &quot;$&#123;IMAGE_NAME&#125;&quot; &gt; image_name</span><br></pre></td></tr></table></figure><p></p><p>上面脚本定义了三个变量：</p><ol><li><p>MODULE，模块名称，由脚本执行的时候传入；</p></li><li><p>TIME，时间字符串；</p></li><li><p>GIT_REVISION，git 提交历史哈希码的前7位；</p></li><li><p>IMAGE_NAME，镜像名称。</p></li></ol><p>脚本做的事情很简单，根据当前目录的Dockerfile构建Docker镜像，然后将镜像推送到Harbor仓库，推送后，将镜像名称写到当前目录下的image_name文件中（供后续使用）。</p><p>给脚本添加可执行权限：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chmod +x build_push.sh</span><br></pre></td></tr></table></figure><p></p><p>修改Pipeline script，新增构建镜像及推送阶段命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">#!groovy</span><br><span class="line">pipeline &#123;</span><br><span class="line">  agent any</span><br><span class="line">  environment &#123;</span><br><span class="line">    REPOSITORY=&quot;ssh://git@gitlab.mrbird.cc:2223/mrbird/demo.git&quot;</span><br><span class="line">    SCRIPT_PATH=&quot;/home/vagrant/bash&quot;</span><br><span class="line">  &#125;</span><br><span class="line">  stages &#123;</span><br><span class="line">    stage(&apos;拉取代码&apos;) &#123;</span><br><span class="line">      steps &#123;</span><br><span class="line">        echo &quot;从GitLab地址$&#123;REPOSITORY&#125;拉取代码&quot;</span><br><span class="line">        deleteDir()</span><br><span class="line">        git &quot;$&#123;REPOSITORY&#125;&quot;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    stage(&apos;代码编译及单元测试&apos;) &#123;</span><br><span class="line">      steps &#123;</span><br><span class="line">        echo &quot;开始编译代码和单元测试&quot;</span><br><span class="line">        sh &quot;mvn -U -am clean package&quot;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    stage(&apos;Docker镜像构建及推送&apos;) &#123;</span><br><span class="line">      steps &#123;</span><br><span class="line">        echo &quot;开始构建Docker镜像并推送到Harbor&quot;</span><br><span class="line">        sh &quot;$&#123;SCRIPT_PATH&#125;/build_push.sh demo&quot;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><p>其中<code>SCRIPT_PATH</code>是上面定义的脚本的路径。</p><p>修改好Pipeline script，重新点击<strong>立即构建</strong>，截取和这部分相关的日志：</p><p><img src="img/20191121184651.png" alt="20191121184651.png"></p><p>查看镜像列表：</p><p><img src="img/QQ截图20191121184855.png" alt="QQ截图20191121184855.png"></p><p><img src="img/QQ截图20191121184943.png" alt="QQ截图20191121184943.png"></p><h3 id="Kubernetes-Deployment升级"><a href="#Kubernetes-Deployment升级" class="headerlink" title="Kubernetes Deployment升级"></a>Kubernetes Deployment升级</h3><p>在<code>/home/vagrant/bash</code>目录下新建deploy.sh脚本：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line"></span><br><span class="line">IMAGE=`cat image_name`</span><br><span class="line"></span><br><span class="line">kubectl set image deployment/demo-deployment demo=$&#123;IMAGE&#125;</span><br></pre></td></tr></table></figure><p></p><p>脚本内容很简单，就是通过kubectl命令升级相关Pod的镜像，镜像名称从image_name文件中读取。</p><p>修改Pipeline script，添加Kubernetes Deployment升级阶段命令：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!groovy</span></span><br><span class="line">pipeline &#123;</span><br><span class="line">  agent any</span><br><span class="line">  environment &#123;</span><br><span class="line">    REPOSITORY=<span class="string">"ssh://git@gitlab.mrbird.cc:2223/mrbird/demo.git"</span></span><br><span class="line">    SCRIPT_PATH=<span class="string">"/home/vagrant/bash"</span></span><br><span class="line">  &#125;</span><br><span class="line">  stages &#123;</span><br><span class="line">    stage(<span class="string">'拉取代码'</span>) &#123;</span><br><span class="line">      steps &#123;</span><br><span class="line">        <span class="built_in">echo</span> <span class="string">"从GitLab地址<span class="variable">$&#123;REPOSITORY&#125;</span>拉取代码"</span></span><br><span class="line">        deleteDir()</span><br><span class="line">        git <span class="string">"<span class="variable">$&#123;REPOSITORY&#125;</span>"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    stage(<span class="string">'代码编译及单元测试'</span>) &#123;</span><br><span class="line">      steps &#123;</span><br><span class="line">        <span class="built_in">echo</span> <span class="string">"开始编译代码和单元测试"</span></span><br><span class="line">        sh <span class="string">"mvn -U -am clean package"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    stage(<span class="string">'Docker镜像构建及推送'</span>) &#123;</span><br><span class="line">      steps &#123;</span><br><span class="line">        <span class="built_in">echo</span> <span class="string">"开始构建Docker镜像并推送到Harbor"</span></span><br><span class="line">        sh <span class="string">"<span class="variable">$&#123;SCRIPT_PATH&#125;</span>/build_push.sh demo"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    stage(<span class="string">'更新Kubernetes Deployment'</span>) &#123;</span><br><span class="line">      steps &#123;</span><br><span class="line">        <span class="built_in">echo</span> <span class="string">"开始更新Kubernetes Deployment"</span></span><br><span class="line">        sh <span class="string">"<span class="variable">$&#123;SCRIPT_PATH&#125;</span>/deploy.sh"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><p>修改后，点击<strong>立即构建</strong>：</p><p><img src="img/QQ截图20191121192052.png" alt="QQ截图20191121192052.png"></p><p>至此我们整条CICD流程就已经都通了，下面测试下CICD。</p><h2 id="效果测试"><a href="#效果测试" class="headerlink" title="效果测试"></a>效果测试</h2><p>如上面所示，我们访问<a href="http://192.168.33.11:30000/hello" target="_blank" rel="noopener">http://192.168.33.11:30000/hello</a>，页面返回hello world，我们在IDEA中修改Controller方法：</p><p><img src="img/QQ截图20191121190234.png" alt="QQ截图20191121190234.png"></p><p>同时修改单元测试方法：</p><p><img src="img/QQ截图20191121190318.png" alt="QQ截图20191121190318.png"></p><p>修改后在IDEA的命令窗口输入：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git commit -am update</span><br><span class="line"></span><br><span class="line">git push origin master</span><br></pre></td></tr></table></figure><p></p><p>将最新的代码提交到GitLab后，过一小会刷新<a href="http://192.168.33.11:30000/hello" target="_blank" rel="noopener">http://192.168.33.11:30000/hello</a>，可以看到，我们修改的内容已经生效了：</p><p><img src="img/QQ截图20191121191654.png" alt="QQ截图20191121191654.png"></p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Tue Dec 17 2019 19:26:13 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;CICD（&lt;strong&gt;C&lt;/strong&gt;ontinuous &lt;strong&gt;I&lt;/strong&gt;ntegration/&lt;strong&gt;C&lt;/strong&gt;ontinuous &lt;strong&gt;D&lt;/strong&gt;eployment），持续集成持续部署的意思。完成CICD实践需要Kubernetes集群，Harbor，GitLab和Jenkins等软件配合完成，在前面几篇博客中，我已经搭建好了Kubernetes集群，并且在master节点（192.168.33.11,CentOS）上安装好了Harbor、GitLab和Jenkins，有需要可以参考下。
    
    </summary>
    
    
      <category term="GitLab" scheme="http://mrbird.cc/tags/GitLab/"/>
    
      <category term="CI/CD" scheme="http://mrbird.cc/tags/CI-CD/"/>
    
      <category term="DevOps" scheme="http://mrbird.cc/tags/DevOps/"/>
    
      <category term="Harbor" scheme="http://mrbird.cc/tags/Harbor/"/>
    
      <category term="Kubernetes" scheme="http://mrbird.cc/tags/Kubernetes/"/>
    
      <category term="Jenkins" scheme="http://mrbird.cc/tags/Jenkins/"/>
    
  </entry>
  
  <entry>
    <title>GitLab &amp; Jenkins安装小记</title>
    <link href="http://mrbird.cc/GitLab-Jenkins-Install-Note.html"/>
    <id>http://mrbird.cc/GitLab-Jenkins-Install-Note.html</id>
    <published>2019-11-15T02:07:01.000Z</published>
    <updated>2019-11-29T12:30:24.279Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Tue Dec 17 2019 19:26:13 GMT+0800 (GMT+08:00) --><p>在CentOS下安装GitLab和Jenkins。<a id="more"></a></p><h2 id="安装GitLab"><a href="#安装GitLab" class="headerlink" title="安装GitLab"></a>安装GitLab</h2><p>传统方式安装GitLab比较麻烦，所以这里我们使用Docker安装GitLab，拉取官方镜像：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker pull gitlab/gitlab-ce:latest</span><br></pre></td></tr></table></figure><p></p><p>镜像有点大，耐心等待。拉取好后，编写一个启动脚本：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">cat &lt;&lt;EOF &gt; run_gitlab.sh</span><br><span class="line">#!/bin/bash</span><br><span class="line">docker stop gitlab</span><br><span class="line">docker rm gitlab</span><br><span class="line">docker run -d \</span><br><span class="line">    --hostname gitlab.mrbird.cc \</span><br><span class="line">    -p 8443:443 -p 8080:80 -p 2223:22 \</span><br><span class="line">    --name gitlab \</span><br><span class="line">    -v /gitlab/config:/etc/gitlab \</span><br><span class="line">    -v /gitlab/logs:/var/log/gitlab \</span><br><span class="line">    -v /gitlab/data:/var/opt/gitlab \</span><br><span class="line">    gitlab/gitlab-ce:latest</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p></p><p><code>--hostname gitlab.mrbird.cc</code>绑定域名，端口映射了下，防止和宿主机冲突。</p><p>执行<code>chmod u+x run_gitlab.sh</code>添加可执行权限，然后运行<code>sh run_gitlab.sh</code>启动GitLab。</p><p>执行启动脚本后，使用<code>docker logs -f gitlab</code>查看启动日志，第一次启动比较慢，当日志定时输出<code>/metrics</code>内容时说明GitLab已启动完毕：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">==&gt; /var/log/gitlab/gitlab-rails/sidekiq_exporter.log &lt;==</span><br><span class="line">[2019-11-03T03:35:18.170+0000] 127.0.0.1 - - [03/Nov/2019:03:35:18 UTC] &quot;GET /metrics HTTP/1.1&quot; 200 6162 &quot;-&quot; &quot;Prometheus/2.12.0&quot;</span><br></pre></td></tr></table></figure><p></p><p>启动后，修改gitlab.rb文件：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /gitlab/config/gitlab.rb</span><br></pre></td></tr></table></figure><p></p><p>开启这段配置，并且端口号改为上面指定的2223：</p><p><img src="img/QQ截图20191116202324.png" alt="QQ截图20191116202324.png"></p><p>然后执行<code>sh run_gitlab.sh</code>重启即可。</p><p>重启后，在虚拟机和windows里添加hosts解析：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">192.168.33.11 gitlab.mrbird.cc</span><br></pre></td></tr></table></figure><p></p><p>使用浏览器访问<a href="http://gitlab.mrbird.cc:8080/" target="_blank" rel="noopener">http://gitlab.mrbird.cc:8080/</a>：</p><p><img src="img/QQ截图20191116202636.png" alt="QQ截图20191116202636.png"></p><p>GitLab还是比较占内存的，在安装GitLab前请确保内存够用🌚：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">docker stats gitlab</span><br><span class="line"></span><br><span class="line">CONTAINER ID        NAME                CPU %               MEM USAGE / LIMIT     MEM %               NET I/O             BLOCK I/O           PIDS</span><br><span class="line">d8edbda28f9f        gitlab              6.80%               1.944GiB / 3.701GiB   52.54%              130kB / 2.29MB      118MB / 2.52MB      281</span><br></pre></td></tr></table></figure><p></p><h2 id="安装Jenkins"><a href="#安装Jenkins" class="headerlink" title="安装Jenkins"></a>安装Jenkins</h2><p>Jenkins的话，推荐用传统方式安装，这样宿主机上安装的maven、docker、kubectl等命令可以直接使用。</p><p>在安装Jenkins之前，需要有Java（我安装的是1.8版本）环境，在CentOS7上安装JDK的过程就不演示了，之前在<a href="https://mrbird.cc/FEBS-Vue-Document.html">https://mrbird.cc/FEBS-Vue-Document.html</a>中也有介绍过。安装好JDK后，下载Jenkins war包：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget http://mirrors.jenkins.io/war-stable/latest/jenkins.war</span><br></pre></td></tr></table></figure><p></p><p>编写一个启动脚本run_jenkins.sh：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim run_jenkins.sh</span><br></pre></td></tr></table></figure><p></p><p>内容如下所示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line"></span><br><span class="line">nohup java -jar jenkins.war --httpPort=8081 &amp;</span><br></pre></td></tr></table></figure><p></p><p>授权：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chmod u+x run_jenkins.sh</span><br></pre></td></tr></table></figure><p></p><p>启动Jenkins：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sh run_jenkins.sh</span><br></pre></td></tr></table></figure><p></p><p>当启动日志输出如下内容时，说明jenkins已成功启动：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">*************************************************************</span><br><span class="line">*************************************************************</span><br><span class="line">*************************************************************</span><br><span class="line"></span><br><span class="line">Jenkins initial setup is required. An admin user has been created and a password generated.</span><br><span class="line">Please use the following password to proceed to installation:</span><br><span class="line"></span><br><span class="line">6ddc10e56b574f27a360986f84da19fc</span><br><span class="line"></span><br><span class="line">This may also be found at: /root/.jenkins/secrets/initialAdminPassword</span><br><span class="line"></span><br><span class="line">*************************************************************</span><br><span class="line">*************************************************************</span><br><span class="line">*************************************************************</span><br></pre></td></tr></table></figure><p></p><p>其中<code>6ddc10e56b574f27a360986f84da19fc</code>为Jenkins的密码，该密码也可以在/root/.jenkins/secrets/initialAdminPassword文件找到。</p><p>使用浏览器访问<a href="http://192.168.33.11:8081/" target="_blank" rel="noopener">http://192.168.33.11:8081/</a>：</p><p><img src="img/QQ截图20191121085911.png" alt="QQ截图20191115145623.png"></p><p>输入上面的密码，进入：</p><p><img src="img/QQ截图20191115145856.png" alt="QQ截图20191115145856.png"></p><p>点击“选择插件安装”，然后<strong>Pipelines and Continuous Delivery</strong>一栏中的所有插件都勾选上：</p><p><img src="img/QQ截图20191115150023.png" alt="QQ截图20191115150023.png"></p><p>然后点击安装即可，安装结束后，接着创建用户：</p><p><img src="img/QQ截图20191115155632.png" alt="QQ截图20191115155632.png"></p><p>点击重启：</p><p><img src="img/QQ截图20191115160201.png" alt="QQ截图20191115160201.png"></p><p>用刚刚创建的用户登录即可：</p><p><img src="img/QQ截图20191115160710.png" alt="QQ截图20191115160710.png"></p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Tue Dec 17 2019 19:26:13 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;在CentOS下安装GitLab和Jenkins。
    
    </summary>
    
    
      <category term="GitLab" scheme="http://mrbird.cc/tags/GitLab/"/>
    
      <category term="Jenkins" scheme="http://mrbird.cc/tags/Jenkins/"/>
    
  </entry>
  
  <entry>
    <title>搭建Docker镜像仓库Harbor</title>
    <link href="http://mrbird.cc/Harbor.html"/>
    <id>http://mrbird.cc/Harbor.html</id>
    <published>2019-11-14T02:15:50.000Z</published>
    <updated>2019-11-16T10:13:18.196Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Tue Dec 17 2019 19:26:13 GMT+0800 (GMT+08:00) --><p>Harbor是一款开源的Docker镜像存储仓库，其扩展了Docker Distribution，在此基础上添加了我们常用的功能，比如安全认证，RBAC用户权限管理，可视化页面操作等功能。Harbor还支持多个Harbor仓库间的相互拷贝，以实现Docker镜像仓库的高可用。这节我们在CentOS虚拟机（192.168.33.11）上搭建个单机版的Harbor体验一下。<a id="more"></a></p><h2 id="安装Harbor"><a href="#安装Harbor" class="headerlink" title="安装Harbor"></a>安装Harbor</h2><p>在Harbor的GitHub仓库：<a href="https://github.com/goharbor/harbor/releases" target="_blank" rel="noopener">https://github.com/goharbor/harbor/releases</a>下载离线版本（offline），我选择的版本是1.8.4：</p><p><img src="img/QQ截图20191114145009.png" alt="QQ截图20191114145009.png"></p><p>下载后，将压缩包harbor-offline-installer-v1.8.4.tgz上传到192.168.33.11服务器上：</p><p><img src="img/QQ截图20191114164739.png" alt="QQ截图20191114164739.png"></p><p>解压压缩包：</p><p><img src="img/QQ截图20191114164856.png" alt="QQ截图20191114150144.png"></p><p>修改Harbor配置文件：</p><p><img src="img/QQ截图20191114164934.png" alt="QQ截图20191114150253.png"></p><p>将hostname修改为宿主机IP即可：</p><p><img src="img/QQ截图20191114165021.png" alt="QQ截图20191114150354.png"></p><p>然后执行当前目录下的install.sh脚本进行安装。</p><p>安装过程中出现如下错误：</p><p><img src="img/QQ截图20191114150640.png" alt="QQ截图20191114150640.png"></p><p>根据<a href="https://docs.docker.com/compose/install/" target="_blank" rel="noopener">https://docs.docker.com/compose/install/</a>安装docker compose后重新执行install.sh脚本。</p><p>出现如下信息时，安装成功:</p><p><img src="img/QQ截图20191114165532.png" alt="QQ截图20191114151457.png"></p><p>使用浏览器访问<a href="http://192.168.33.11/" target="_blank" rel="noopener">http://192.168.33.11/</a>地址，可以看到Harbor的管理界面：</p><p><img src="img/QQ截图20191114165616.png" alt="QQ截图20191114151916.png"></p><p>默认的用户名密码为：admin，Harbor12345，登录后：</p><p><img src="img/QQ截图20191114165700.png" alt="QQ截图20191114152147.png"></p><p>为了后续推送镜像方便，我们需要给192.168.33.11配置域名，添加hosts解析：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">192.168.33.11 docker.mrbird.cc</span><br></pre></td></tr></table></figure><p></p><h2 id="创建用户和项目"><a href="#创建用户和项目" class="headerlink" title="创建用户和项目"></a>创建用户和项目</h2><p>在<a href="http://192.168.33.11/" target="_blank" rel="noopener">http://192.168.33.11/</a>Harbor管理界面下新增一个用户：</p><p><img src="img/QQ截图20191114165828.png" alt="QQ截图20191114154608.png"></p><p><img src="img/QQ截图20191114165905.png" alt="QQ截图20191114154646.png"></p><p>然后新增一个项目：</p><p><img src="img/QQ截图20191114165952.png" alt="QQ截图20191114154755.png"></p><p><img src="img/QQ截图20191114170013.png" alt="QQ截图20191114154830.png"></p><p>在该项目下添加刚刚创建的mrbird用户：</p><p><img src="img/QQ截图20191114170054.png" alt="QQ截图20191114155249.png"></p><p><img src="img/QQ截图20191114170137.png" alt="QQ截图20191114155318.png"></p><p>接着在192.168.33.11上进行登录:</p><p><img src="img/QQ截图20191114170510.png" alt="QQ截图20191114170510.png"></p><p>用户名和密码就是刚刚在控制台创建的mrbird用户和密码。但是登录失败了，要登录到http docker仓库，需要添加一些配置：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/docker/daemon.json</span><br></pre></td></tr></table></figure><p></p><p>添加如下内容：</p><p><img src="img/QQ截图20191114170718.png" alt="QQ截图20191114170718.png"></p><p>重启docker：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo service docker restart</span><br></pre></td></tr></table></figure><p></p><p>然后重新登录即可：</p><p><img src="img/QQ截图20191114171254.png" alt="QQ截图20191114171254.png"></p><h2 id="测试镜像推拉"><a href="#测试镜像推拉" class="headerlink" title="测试镜像推拉"></a>测试镜像推拉</h2><p>拉取nginx:1.17.5镜像：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker pull nginx:1.17.5</span><br></pre></td></tr></table></figure><p></p><p>打标签:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker tag nginx:1.17.5 docker.mrbird.cc/febs/nginx:1.17.5</span><br></pre></td></tr></table></figure><p></p><p>标签格式为[docker仓库域名]:[项目名称]:[镜像]。</p><p>将docker.mrbird.cc/febs/nginx:1.17.5推送到Harbor：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker push docker.mrbird.cc/febs/nginx</span><br></pre></td></tr></table></figure><p></p><p>回到Harbor控制台，可以看到在febs项目下已经存在一个nginx镜像：</p><p><img src="img/QQ截图20191114171855.png" alt="QQ截图20191114171855.png"></p><p>在192.168.33.12服务器上添加docker.mrbird.cc的解析，然后拉取刚刚的镜像，看看是否成功：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker pull docker.mrbird.cc/febs/nginx:1.17.5</span><br></pre></td></tr></table></figure><p></p><p><img src="img/QQ截图20191114172154.png" alt="QQ截图20191114172154.png"></p><p>拉取成功。</p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Tue Dec 17 2019 19:26:13 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;Harbor是一款开源的Docker镜像存储仓库，其扩展了Docker Distribution，在此基础上添加了我们常用的功能，比如安全认证，RBAC用户权限管理，可视化页面操作等功能。Harbor还支持多个Harbor仓库间的相互拷贝，以实现Docker镜像仓库的高可用。这节我们在CentOS虚拟机（192.168.33.11）上搭建个单机版的Harbor体验一下。
    
    </summary>
    
    
      <category term="Harbor" scheme="http://mrbird.cc/tags/Harbor/"/>
    
      <category term="Docker" scheme="http://mrbird.cc/tags/Docker/"/>
    
  </entry>
  
  <entry>
    <title>Kubernetes资源管理</title>
    <link href="http://mrbird.cc/Kubernetes-Resource-Management.html"/>
    <id>http://mrbird.cc/Kubernetes-Resource-Management.html</id>
    <published>2019-11-09T04:52:56.000Z</published>
    <updated>2019-11-16T10:13:18.198Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Tue Dec 17 2019 19:26:13 GMT+0800 (GMT+08:00) --><p>通过前面的学习我们知道，我们可以通过requests和limits给Pod指定资源配置，但如果每个Pod都要指定的话略显繁琐，我们可以使用LimitRange指定一个全局的默认配置；此外通过ResourceQuota对象，我们可以定义资源配额，这个资源配额可以为每个命名空间都提供一个总体的资源使用的限制：它可以限制命名空间中某种类型的对象的总数目上限，也可以设置命名空间中Pod可以使用的计算资源的总上限。</p><a id="more"></a><h2 id="LimitRange"><a href="#LimitRange" class="headerlink" title="LimitRange"></a>LimitRange</h2><p>在使用LimitRange之前先创建一个命名空间：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Namespace</span><br><span class="line">metadata:</span><br><span class="line">  name: test-resource</span><br></pre></td></tr></table></figure><p></p><p>然后定义LimitRange配置（limit-range.yml）:</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">LimitRange</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">limit-range-example</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  limits:</span></span><br><span class="line"><span class="attr">    - max:</span></span><br><span class="line"><span class="attr">        cpu:</span> <span class="number">2</span></span><br><span class="line"><span class="attr">        memory:</span> <span class="number">2</span><span class="string">Gi</span></span><br><span class="line"><span class="attr">      min:</span></span><br><span class="line"><span class="attr">        cpu:</span> <span class="number">200</span><span class="string">m</span></span><br><span class="line"><span class="attr">        memory:</span> <span class="number">6</span><span class="string">Mi</span></span><br><span class="line"><span class="attr">      maxLimitRequestRatio:</span></span><br><span class="line"><span class="attr">        cpu:</span> <span class="number">3</span></span><br><span class="line"><span class="attr">        memory:</span> <span class="number">2</span></span><br><span class="line"><span class="attr">      type:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">    - default:</span></span><br><span class="line"><span class="attr">        cpu:</span> <span class="number">300</span><span class="string">m</span></span><br><span class="line"><span class="attr">        memory:</span> <span class="number">200</span><span class="string">Mi</span></span><br><span class="line"><span class="attr">      defaultRequest:</span></span><br><span class="line"><span class="attr">        cpu:</span> <span class="number">200</span><span class="string">m</span></span><br><span class="line"><span class="attr">        memory:</span> <span class="number">100</span><span class="string">Mi</span></span><br><span class="line"><span class="attr">      max:</span></span><br><span class="line"><span class="attr">        cpu:</span> <span class="number">2</span></span><br><span class="line"><span class="attr">        memory:</span> <span class="number">1</span><span class="string">Gi</span></span><br><span class="line"><span class="attr">      min:</span></span><br><span class="line"><span class="attr">        cpu:</span> <span class="number">100</span><span class="string">m</span></span><br><span class="line"><span class="attr">        memory:</span> <span class="number">3</span><span class="string">Mi</span></span><br><span class="line"><span class="attr">      maxLimitRequestRatio:</span></span><br><span class="line"><span class="attr">        cpu:</span> <span class="number">5</span></span><br><span class="line"><span class="attr">        memory:</span> <span class="number">4</span></span><br><span class="line"><span class="attr">      type:</span> <span class="string">Container</span></span><br></pre></td></tr></table></figure><p></p><p>创建该LimitRange：</p><p><img src="img/QQ截图20191112092850.png" alt="QQ截图20191112092850.png"></p><p>可以看到配置已经生效了。下面介绍下这些配置的含义：</p><p>上面配置分为Pod和Container配置，Container资源配置对应每个Docker容器的资源配置，Pod资源配置对应一个Pod中所有容器资源的总和。其中Pod和Container都可以指定<code>min</code>，<code>max</code>和<code>maxLimitRequestRatio</code>：</p><ol><li><p><code>min</code>：指定资源的下限，即最低资源配置不能低于这个值；</p></li><li><p><code>max</code>：指定资源的上限，即最高资源使用不能高于这个值；</p></li><li><p><code>maxLimitRequestRatio</code>：该值用于指定requests和limits值比例的上限。</p></li></ol><p>相较于Pod，Container还可以指定<code>defaultRequest</code>和<code>default</code>（实际上就是<code>defaultLimit</code>，不懂为什么Kubernetes不用这个名称😵）：</p><ol><li><p><code>defaultRequest</code>：全局容器的默认<code>requests</code>值；</p></li><li><p><code>default</code>：全局容器的默认<code>limits</code>值。</p></li></ol><p>下面我们举几个例子，看看我们创建的LimitRange是否生效。</p><p>定义一个Pod配置文件（test-default.yml）：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">test-default</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  containers:</span></span><br><span class="line"><span class="attr">    - name:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">      image:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">      ports:</span></span><br><span class="line"><span class="attr">        - containerPort:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure><p></p><p>创建该Pod：</p><p><img src="img/QQ截图20191112094923.png" alt="QQ截图20191112094923.png"></p><p><img src="img/QQ截图20191112094959.png" alt="QQ截图20191112094959.png"></p><p>可以看到我们在test-default.yml中并没有定义requests和limits配置，但是通过Pod实例的yaml可以看到它已经指定了这两个值，而这些正是上面我们在LimitRange中定义的默认值。</p><p>接着定义一个新的Pod配置（test-max.yml）:</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">test-max</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  containers:</span></span><br><span class="line"><span class="attr">    - name:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">      image:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">      ports:</span></span><br><span class="line"><span class="attr">        - containerPort:</span> <span class="number">80</span></span><br><span class="line"><span class="attr">      resources:</span></span><br><span class="line"><span class="attr">        limits:</span></span><br><span class="line"><span class="attr">          cpu:</span> <span class="number">3</span></span><br><span class="line"><span class="attr">          memory:</span> <span class="number">500</span><span class="string">Mi</span></span><br></pre></td></tr></table></figure><p></p><p>创建该Pod：</p><p><img src="img/QQ截图20191112095603.png" alt="QQ截图20191112095603.png"></p><p>可以看到在创建的时候就报错了，因为上面的cpu配置即超过了LimtRange中定义的Container的cpu最高配置，也超过了Pod的cpu的最高配置。</p><p>再创建一个Pod配置（test-ratio.yml）：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">test-ratio</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  containers:</span></span><br><span class="line"><span class="attr">    - name:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">      image:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">      ports:</span></span><br><span class="line"><span class="attr">        - containerPort:</span> <span class="number">80</span></span><br><span class="line"><span class="attr">      resources:</span></span><br><span class="line"><span class="attr">        limits:</span></span><br><span class="line"><span class="attr">          cpu:</span> <span class="number">2</span></span><br><span class="line"><span class="attr">          memory:</span> <span class="number">500</span><span class="string">Mi</span></span><br><span class="line"><span class="attr">        requests:</span></span><br><span class="line"><span class="attr">          cpu:</span> <span class="number">300</span><span class="string">m</span></span><br><span class="line"><span class="attr">          memory:</span> <span class="number">50</span><span class="string">Mi</span></span><br></pre></td></tr></table></figure><p></p><p>创建该Pod：</p><p><img src="img/QQ截图20191112100308.png" alt="QQ截图20191112100308.png"></p><p>可以看到也报错了，因为requests和limits的比例不符合LimitRange的maxLimitRequestRatio配置。</p><p>LimitRange的测试先到这里吧，通过上面三个例子大体也能感受到LimitRange的作用了。</p><h2 id="ResourceQuota"><a href="#ResourceQuota" class="headerlink" title="ResourceQuota"></a>ResourceQuota</h2><p>ResourceQuota用于管理资源配额，这个资源配额可以为每个命名空间都提供一个总体的资源使用的限制。资源配额主要分为以下几个类型：</p><h3 id="计算资源配额"><a href="#计算资源配额" class="headerlink" title="计算资源配额"></a>计算资源配额</h3><table align="center"><thead><tr><th scope="col">资源名称</th><th scope="col">说明</th></tr></thead><tbody><tr><td>Cpu</td><td>所有非终止状态的Pod，CPU Requests的总和不能超过该值</td></tr><tr><td>limits.cpu</td><td>所有非终止状态的Pod， CPU Limits的总和不能超过该值</td></tr><tr><td>limits.memory</td><td>所有非终止状态的Pod，内存 Limits的总和不能超过该值</td></tr><tr><td>Memory</td><td>所有非终止状态的Pod， 内存 Requests的总和不能超过该值</td></tr><tr><td>requests.cpu</td><td>所有非终止状态的Pod，CPU Requests的总和不能超过该值</td></tr><tr><td>requests.memory</td><td>所有非终止状态的Pod， 内存Requests的总和不能超过该值</td></tr></tbody></table><h3 id="存储资源配额"><a href="#存储资源配额" class="headerlink" title="存储资源配额"></a>存储资源配额</h3><table><thead><tr><th scope="col">资源名称</th><th scope="col">说明</th></tr></thead><tbody><tr><td>requests.storage</td><td>所有PVC，存储请求总量不能超过此值</td></tr><tr><td>PersistentVolumeclaims</td><td>在该命名空间中能存在的持久卷的总数上限</td></tr><tr><td>.storageclass.storage.k8s.io/requests.storage</td><td>和该存储类关联的所有PVC，存储请求总和不能超过此值</td></tr><tr><td>.storageclass.storage.k8s.io/persistentvolumeclaims</td><td>和该存储类关联的所有PVC的总和</td></tr></tbody></table><h3 id="对象数量配额"><a href="#对象数量配额" class="headerlink" title="对象数量配额"></a>对象数量配额</h3><table><thead><tr><th scope="col">资源名称</th><th scope="col">说明</th></tr></thead><tbody><tr><td>Configmaps</td><td>在该命名空间中能存在的ConfigMap的总数上限</td></tr><tr><td><p>Pods</p></td><td><p>在该命名空间中能存在的非终止状态Pod的总数上限，Pod终止状态等价于Pod的</p><p>status.phase in(Failed, Succeeded) = true</p></td></tr><tr><td>Replicationcontrollers</td><td>在该命名空间中能存在的RC的总数上限</td></tr><tr><td>Resourcequtas</td><td>在该命名空间中能存在的资源配额项的总数上限</td></tr><tr><td>Services</td><td>在该命名空间中能存在的Service的总数上限</td></tr><tr><td>service.loadbalancers</td><td>在该命名空间中能存在的负载均衡的总数上限</td></tr><tr><td>services.nodeports</td><td>在该命名空间中能存在的NodePort的总数上限</td></tr><tr><td>Secrets</td><td>在该命名空间中能存在的Secret的总数上限</td></tr></tbody></table><h3 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h3><p>在测试ResourceQuota之前我们也先创建一个命名空间：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Namespace</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">quota-ns</span></span><br></pre></td></tr></table></figure><p></p><p>创建个简单的ResourceQuota配置（test-quota.yml）：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: ResourceQuota</span><br><span class="line">metadata:</span><br><span class="line">  name: test-quota</span><br><span class="line">spec:</span><br><span class="line">  hard:</span><br><span class="line">    pods: &quot;4&quot;</span><br></pre></td></tr></table></figure><p></p><p>创建该ResourceQuota：</p><p><img src="img/QQ截图20191112104240.png" alt="QQ截图20191112104240.png"></p><p>接着定义一个RC配置（nginx-rc.yml）：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ReplicationController</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">nginx-rc</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  replicas:</span> <span class="number">3</span></span><br><span class="line"><span class="attr">  selector:</span></span><br><span class="line"><span class="attr">    name:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">  template:</span></span><br><span class="line"><span class="attr">    metadata:</span></span><br><span class="line"><span class="attr">      labels:</span></span><br><span class="line"><span class="attr">        name:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">    spec:</span></span><br><span class="line"><span class="attr">      containers:</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">          image:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">          imagePullPolicy:</span> <span class="string">IfNotPresent</span></span><br><span class="line"><span class="attr">          ports:</span></span><br><span class="line"><span class="attr">            - containerPort:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure><p></p><p>创建该RC:</p><p><img src="img/QQ截图20191112104507.png" alt="QQ截图20191112104507.png"></p><p>可以看到，已经有3个Pod实例了，如果将Pod数量扩大到5，看看会怎样：</p><p><img src="img/QQ截图20191112104655.png" alt="QQ截图20191112104655.png"></p><p>最终也只会有4个Pod实例，因为我们在上面ResourceQuota中指定的最大Pod数量为4。</p><blockquote><p>《Kubernetes权威指南(第4版)》读书笔记</p></blockquote><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Tue Dec 17 2019 19:26:13 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;通过前面的学习我们知道，我们可以通过requests和limits给Pod指定资源配置，但如果每个Pod都要指定的话略显繁琐，我们可以使用LimitRange指定一个全局的默认配置；此外通过ResourceQuota对象，我们可以定义资源配额，这个资源配额可以为每个命名空间都提供一个总体的资源使用的限制：它可以限制命名空间中某种类型的对象的总数目上限，也可以设置命名空间中Pod可以使用的计算资源的总上限。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Kubernetes" scheme="http://mrbird.cc/tags/Kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>Kubernetes Namespace&amp;Context</title>
    <link href="http://mrbird.cc/Kubernetes-Namespaces-Context.html"/>
    <id>http://mrbird.cc/Kubernetes-Namespaces-Context.html</id>
    <published>2019-11-08T04:53:11.000Z</published>
    <updated>2019-11-09T08:39:58.274Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Tue Dec 17 2019 19:26:13 GMT+0800 (GMT+08:00) --><p>在一个组织内部，不同的工作组可以在同一个Kubernetes集群中工作，Kubernetes通过命名空间和Context的设置对不同的工作组进行区分，使得它们既可以共享同一个Kubernetes集群的服务，也能够互不干扰。</p><a id="more"></a><h2 id="Namespace的创建"><a href="#Namespace的创建" class="headerlink" title="Namespace的创建"></a>Namespace的创建</h2><p>Kubernetes集群会帮我们创建一个名称为default的命名空间：</p><p><img src="img/QQ截图20191109160144.png" alt="QQ截图20191109160144.png"></p><p>默认情况下，我们的pod、rc、service等Kubernetes资源都是使用这个命名空间，此外我们也可以创建自己的命名空间。</p><p>定义一个命名空间配置dev-namesapce.yml：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Namespace</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">dev</span> <span class="comment"># dev命名空间</span></span><br></pre></td></tr></table></figure><p></p><p>创建该命名空间：</p><p><img src="img/QQ截图20191109160534.png" alt="QQ截图20191109160534.png"></p><h2 id="使用Namespace"><a href="#使用Namespace" class="headerlink" title="使用Namespace"></a>使用Namespace</h2><p>使用命名空间只需要在创建Kubernetes资源对象的时候指定即可，比如创建一个tomcat-rc.yml，并指定命名空间为dev：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ReplicationController</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">tomcat-rc</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">dev</span> <span class="comment"># 指定命名空间</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  replicas:</span> <span class="number">2</span></span><br><span class="line"><span class="attr">  selector:</span></span><br><span class="line"><span class="attr">    name:</span> <span class="string">tomcat</span></span><br><span class="line"><span class="attr">  template:</span></span><br><span class="line"><span class="attr">    metadata:</span></span><br><span class="line"><span class="attr">      name:</span> <span class="string">tomcat</span></span><br><span class="line"><span class="attr">      labels:</span></span><br><span class="line"><span class="attr">        name:</span> <span class="string">tomcat</span></span><br><span class="line"><span class="attr">    spec:</span></span><br><span class="line"><span class="attr">      containers:</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">tomcat</span></span><br><span class="line"><span class="attr">          image:</span> <span class="string">tomcat</span></span><br><span class="line"><span class="attr">          ports:</span></span><br><span class="line"><span class="attr">            - containerPort:</span> <span class="number">8080</span></span><br><span class="line"><span class="attr">              hostPort:</span> <span class="number">8081</span></span><br></pre></td></tr></table></figure><p></p><p>创建该rc：</p><p><img src="img/20191109161045.png" alt="20191109161045.png"></p><p>可以看到，defalut命名空间下并没有任何pod，而dev命名空间下则有两个tomcat pod实例。</p><div class="note danger"><p>命名空间只是名称上的隔离，不同命名空间下的pod，service等还是可以相互访问的。</p></div><h2 id="Context的创建和使用"><a href="#Context的创建和使用" class="headerlink" title="Context的创建和使用"></a>Context的创建和使用</h2><p>我们可以通过创建Context（上下文），指定使用的命名空间，然后使用该Context，来完成默认的命名空间切换。</p><p>在创建Context前，我们查看下Kubernetes默认的配置：</p><p><img src="img/QQ截图20191109162819.png" alt="QQ截图20191109162819.png"></p><p>可以看到，当前默认的Context名称为kubernetes-admin@kubernetes，由此可以推断，它和defalut这个命名空间挂钩。</p><p>创建一个新的Context，名称为ctx-dev，命名空间使用上面创建的dev：</p><p><img src="img/QQ截图20191109162659.png" alt="QQ截图20191109162659.png"></p><p>其中<code>/root/.kube/config</code>为Kubernetes配置。</p><p>创建成功后，我们使用ctx-dev这个Context：</p><p><img src="img/QQ截图20191109163224.png" alt="QQ截图20191109163224.png"></p><p>可以看到，现在不需要指定<code>-n dev</code>就可以获取到dev命名空间下的pod了，也证实了Context的切换是成功的。</p><p>如果想要恢复默认的Context，将Context指定为kubernetes-admin@kubernetes：</p><p><img src="img/QQ截图20191109163514.png" alt="QQ截图20191109163514.png"></p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Tue Dec 17 2019 19:26:13 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;在一个组织内部，不同的工作组可以在同一个Kubernetes集群中工作，Kubernetes通过命名空间和Context的设置对不同的工作组进行区分，使得它们既可以共享同一个Kubernetes集群的服务，也能够互不干扰。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Kubernetes" scheme="http://mrbird.cc/tags/Kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>Kubernetes Service基础</title>
    <link href="http://mrbird.cc/Kubernetes-Service-Basic.html"/>
    <id>http://mrbird.cc/Kubernetes-Service-Basic.html</id>
    <published>2019-11-07T06:30:59.000Z</published>
    <updated>2019-11-09T03:19:50.431Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Tue Dec 17 2019 19:26:13 GMT+0800 (GMT+08:00) --><p>Kubernetes可以为一组具有相同功能的Pod提供一个统一的入口地址，并且将请求均衡的转发到各个对应的Pod上。本节主要记录Service的一些基本用法。</p><a id="more"></a><h2 id="基本用法"><a href="#基本用法" class="headerlink" title="基本用法"></a>基本用法</h2><p>创建一个Tomcat RC（tomcat-rc.yml）:</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ReplicationController</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">tomcat-rc</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  replicas:</span> <span class="number">2</span></span><br><span class="line"><span class="attr">  selector:</span></span><br><span class="line"><span class="attr">    name:</span> <span class="string">tomcat</span></span><br><span class="line"><span class="attr">  template:</span></span><br><span class="line"><span class="attr">    metadata:</span></span><br><span class="line"><span class="attr">      name:</span> <span class="string">tomcat</span></span><br><span class="line"><span class="attr">      labels:</span></span><br><span class="line"><span class="attr">        name:</span> <span class="string">tomcat</span></span><br><span class="line"><span class="attr">    spec:</span></span><br><span class="line"><span class="attr">      containers:</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">tomcat</span></span><br><span class="line"><span class="attr">          image:</span> <span class="string">tomcat</span></span><br><span class="line"><span class="attr">          ports:</span></span><br><span class="line"><span class="attr">            - containerPort:</span> <span class="number">8080</span></span><br></pre></td></tr></table></figure><p></p><p>创建该RC：</p><p><img src="img/QQ截图20191109095409.png" alt="QQ截图20191109095409.png"></p><p>我们可以通过Node IP + Container Port在Kubernetes集群中访问Tomcat：</p><p><img src="img/QQ截图20191109095554.png" alt="QQ截图20191109095554.png"></p><p>由于Pod是Kubernetes集群范围内的虚拟概念，集群外的客户端无法通过Pod的IP和端口访问，我们可以将Pod的端口号映射到宿主机，以使客户端应用能够通过物理机访问容器应用，修改刚刚的tomcat-rc.yml，添加hostPort：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ReplicationController</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">tomcat-rc</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  replicas:</span> <span class="number">2</span></span><br><span class="line"><span class="attr">  selector:</span></span><br><span class="line"><span class="attr">    name:</span> <span class="string">tomcat</span></span><br><span class="line"><span class="attr">  template:</span></span><br><span class="line"><span class="attr">    metadata:</span></span><br><span class="line"><span class="attr">      name:</span> <span class="string">tomcat</span></span><br><span class="line"><span class="attr">      labels:</span></span><br><span class="line"><span class="attr">        name:</span> <span class="string">tomcat</span></span><br><span class="line"><span class="attr">    spec:</span></span><br><span class="line"><span class="attr">      containers:</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">tomcat</span></span><br><span class="line"><span class="attr">          image:</span> <span class="string">tomcat</span></span><br><span class="line"><span class="attr">          ports:</span></span><br><span class="line"><span class="attr">            - containerPort:</span> <span class="number">8080</span></span><br><span class="line"><span class="attr">              hostPort:</span> <span class="number">8081</span> <span class="comment"># 新增</span></span><br></pre></td></tr></table></figure><p>更新该RC：</p><p><img src="img/QQ截图20191109100036.png" alt="QQ截图20191109100036.png"></p><p>可以看到tomcat pod被分配到了node1和node2上，所以我们可以在宿主机外使用<a href=""></a>或者<a href=""></a>访问tomcat：</p><p><img src="img/QQ截图20191109100307.png" alt="QQ截图20191109100307.png"></p><p>但是我们知道，Pod的IP地址是不可靠的，例如当Pod所在的Node发生故障时，Pod将被Kubernetes重新调度到另一个Node，Pod的IP地址将发生变化。所以我们可以定义一个tomcat pod的统一访问入口，这就是Service的作用。</p><p>创建Service有两种方式：</p><p><strong>1.kubectl expose命令来创建Service</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl expose rc tomcat-rc</span><br></pre></td></tr></table></figure><p></p><p><img src="img/QQ截图20191109100642.png" alt="QQ截图20191109100642.png"></p><p>现在我们就可以通过Service的clusterIP + Port来访问了：</p><p><img src="img/QQ截图20191109100757.png" alt="QQ截图20191109100757.png"></p><p>Service地址10.1.187.222:8080均衡的负载到了两个tomcat pod上（10.244.1.19:8080和10.244.4.13:8080）</p><p><strong>2.通过配置文件创建</strong></p><p>定义一个tomcat-service.yml：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">tomcat-service</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  ports:</span></span><br><span class="line"><span class="attr">    - port:</span> <span class="number">8081</span> <span class="comment"># service端口</span></span><br><span class="line"><span class="attr">      targetPort:</span> <span class="number">8080</span> <span class="comment"># 目标端口</span></span><br><span class="line"><span class="attr">  selector:</span></span><br><span class="line"><span class="attr">    name:</span> <span class="string">tomcat</span> <span class="comment"># 选择器，选择name=tomcat的pod</span></span><br></pre></td></tr></table></figure><p></p><p>创建该Service：</p><p><img src="img/QQ截图20191109101415.png" alt="QQ截图20191109101415.png"></p><p>同样，Service默认是不能外部访问的，如果想让外部能够访问到tomcat service，我们也需要将Service的端口映射到物理机，修改上面的tomcat-service.yml：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">tomcat-service</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  type:</span> <span class="string">NodePort</span> <span class="comment"># 新增</span></span><br><span class="line"><span class="attr">  ports:</span></span><br><span class="line"><span class="attr">    - port:</span> <span class="number">8081</span></span><br><span class="line"><span class="attr">      targetPort:</span> <span class="number">8080</span></span><br><span class="line"><span class="attr">      nodePort:</span> <span class="number">30000</span> <span class="comment"># 新增</span></span><br><span class="line"><span class="attr">  selector:</span></span><br><span class="line"><span class="attr">    name:</span> <span class="string">tomcat</span></span><br></pre></td></tr></table></figure><p>上面配置通过设置nodePort（范围30000-32767）映射到物理机，同时设置Service的类型为NodePort，创建该Service：</p><p><img src="img/QQ截图20191109102138.png" alt="QQ截图20191109102138.png"></p><p>现在我们就可以通过宿主机的IP+30000访问tomcat了：</p><p><img src="img/QQ截图20191109102418.png" alt="QQ截图20191109102418.png"></p><h2 id="负载均衡策略"><a href="#负载均衡策略" class="headerlink" title="负载均衡策略"></a>负载均衡策略</h2><p>Kubernetes Service提供了两种负载分发策略：RoundRobin和SessionAffinity：</p><ol><li>RoundRobin：轮询模式（默认），即轮询将请求转发到后端的各个Pod上。</li><li>SessionAffinity：基于客户端IP地址进行会话保持的模式，即第1次将某个客户端发起的请求转发到后端的某个Pod上，之后从相同的客户端发起的请求都将被转发到后端相同的Pod上。可以通过设置service.spec.sessionAffinity=ClientIP来启用SessionAffinity策略：<figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">tomcat-service</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  type:</span> <span class="string">NodePort</span></span><br><span class="line"><span class="attr">  sessionAffinity:</span> <span class="string">ClientIP</span> <span class="comment"># 采用SessionAffinity策略</span></span><br><span class="line"><span class="attr">  ports:</span></span><br><span class="line"><span class="attr">    - port:</span> <span class="number">8081</span></span><br><span class="line"><span class="attr">      targetPort:</span> <span class="number">8080</span></span><br><span class="line"><span class="attr">      nodePort:</span> <span class="number">30000</span></span><br><span class="line"><span class="attr">  selector:</span></span><br><span class="line"><span class="attr">    name:</span> <span class="string">tomcat</span></span><br></pre></td></tr></table></figure></li></ol><h2 id="Headless-Service"><a href="#Headless-Service" class="headerlink" title="Headless Service"></a>Headless Service</h2><p>Headless Service不提供ClusterIP，仅通过Label Selector将后端的Pod列表返回给调用的客户端。</p><p>创建tomcat-headless-service.yml：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">tomcat-headless-service</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  ports:</span></span><br><span class="line"><span class="attr">    - port:</span> <span class="number">8080</span></span><br><span class="line"><span class="attr">  clusterIP:</span> <span class="string">None</span> <span class="comment"># 设置clusterIP为None，表示headless service</span></span><br><span class="line"><span class="attr">  selector:</span></span><br><span class="line"><span class="attr">    name:</span> <span class="string">tomcat</span></span><br></pre></td></tr></table></figure><p></p><p>创建该headless service：</p><p><img src="img/QQ截图20191109111632.png" alt="QQ截图20191109111632.png"></p><p><img src="img/QQ截图20191109111800.png" alt="QQ截图20191109111800.png"></p><blockquote><p>《Kubernetes权威指南(第4版)》读书笔记</p></blockquote><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Tue Dec 17 2019 19:26:13 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;Kubernetes可以为一组具有相同功能的Pod提供一个统一的入口地址，并且将请求均衡的转发到各个对应的Pod上。本节主要记录Service的一些基本用法。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Kubernetes" scheme="http://mrbird.cc/tags/Kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>Kubernetes Pod扩容与缩容</title>
    <link href="http://mrbird.cc/Kubernetes-Pod-Expansion-Contraction.html"/>
    <id>http://mrbird.cc/Kubernetes-Pod-Expansion-Contraction.html</id>
    <published>2019-11-07T06:19:48.000Z</published>
    <updated>2019-11-08T12:38:39.455Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Tue Dec 17 2019 19:26:13 GMT+0800 (GMT+08:00) --><p>针对不同时期流量的大小我们可以给Pod扩缩容，Kubernetes支持通过kubectl命令手动扩缩容，也支持通过HPA自动横向扩缩容。<a id="more"></a></p><h2 id="手动扩缩容"><a href="#手动扩缩容" class="headerlink" title="手动扩缩容"></a>手动扩缩容</h2><p>现有如下deployment配置（nginx-deployment.yml）：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">nginx-deployment</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  selector:</span></span><br><span class="line"><span class="attr">    matchLabels:</span></span><br><span class="line"><span class="attr">      name:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">  replicas:</span> <span class="number">3</span></span><br><span class="line"><span class="attr">  template:</span></span><br><span class="line"><span class="attr">    metadata:</span></span><br><span class="line"><span class="attr">      labels:</span></span><br><span class="line"><span class="attr">        name:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">    spec:</span></span><br><span class="line"><span class="attr">      containers:</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">          image:</span> <span class="attr">nginx:1.7.9</span></span><br><span class="line"><span class="attr">          imagePullPolicy:</span> <span class="string">IfNotPresent</span></span><br><span class="line"><span class="attr">          ports:</span></span><br><span class="line"><span class="attr">            - containerPort:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure><p></p><p>创建该Deployment：</p><p><img src="img/QQ截图20191108094938.png" alt="QQ截图20191108094938.png"></p><p>有3个nginx实例，现在用下面这条命令将nginx实例扩充到5个：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl scale deployment nginx-deployment --replicas 5</span><br></pre></td></tr></table></figure><p></p><p><img src="img/QQ截图20191108100513.png" alt="QQ截图20191108100513.png"></p><p>缩容：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl scale deployment nginx-deployment --replicas 1</span><br></pre></td></tr></table></figure><p></p><p><img src="img/QQ截图20191108100834.png" alt="QQ截图20191108100834.png"></p><h2 id="HPA"><a href="#HPA" class="headerlink" title="HPA"></a>HPA</h2><p>HPA能够根据特定指标完成目标Pod的自动扩缩容。创建一个与上面nginx-deployment相对应的HPA（nginx-deployment-hpa.yml）：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">autoscaling/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">HorizontalPodAutoscaler</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">nginx-deployment-hpa-v1</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  maxReplicas:</span> <span class="number">6</span></span><br><span class="line"><span class="attr">  minReplicas:</span> <span class="number">2</span></span><br><span class="line"><span class="attr">  scaleTargetRef:</span></span><br><span class="line"><span class="attr">    apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">    kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">    name:</span> <span class="string">nginx-deployment</span></span><br><span class="line"><span class="attr">  targetCPUUtilizationPercentage:</span> <span class="number">50</span></span><br></pre></td></tr></table></figure><p></p><p>主要参数如下：</p><ol><li><p>scaleTargetRef：目标作用对象，可以是Deployment、ReplicationController或ReplicaSet。</p></li><li><p>targetCPUUtilizationPercentage：期望每个Pod的CPU使用率都为50%，该使用率基于Pod设置的CPU Request值进行计算，例如该值为200m，那么系统将维持Pod的实际CPU使用值为100m。</p></li><li><p>minReplicas和maxReplicas：Pod副本数量的最小值和最大值，系统将在这个范围内进行自动扩缩容操作，并维持每个Pod的CPU使用率为50%。</p></li></ol><div class="note info"><p>使用HPA，需要预先安装Metrics Server，用于采集Pod的CPU使用率。</p></div><blockquote><p>《Kubernetes权威指南(第4版)》读书笔记</p></blockquote><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Tue Dec 17 2019 19:26:13 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;针对不同时期流量的大小我们可以给Pod扩缩容，Kubernetes支持通过kubectl命令手动扩缩容，也支持通过HPA自动横向扩缩容。
    
    </summary>
    
    
      <category term="Kubernetes" scheme="http://mrbird.cc/tags/Kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>Kubernetes Pod升级与回滚</title>
    <link href="http://mrbird.cc/Kubernetes-Pod-Upgrade-And-Rollback.html"/>
    <id>http://mrbird.cc/Kubernetes-Pod-Upgrade-And-Rollback.html</id>
    <published>2019-11-05T10:59:27.000Z</published>
    <updated>2019-11-08T09:57:27.638Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Tue Dec 17 2019 19:26:13 GMT+0800 (GMT+08:00) --><p>当集群中的某个服务需要升级时，我们需要停止目前与该服务相关的所有Pod，然后下载新版本镜像并创建新的Pod。如果集群规模比较大，则这个工作变成了一个挑战，而且先全部停止然后逐步升级的方式会导致较长时间的服务不可用。Kubernetes提供了滚动升级功能来解决上述问题。如果在更新过程中发生了错误，则还可以通过回滚操作恢复Pod的版本。<a id="more"></a></p><h2 id="Deployment升级"><a href="#Deployment升级" class="headerlink" title="Deployment升级"></a>Deployment升级</h2><p>现有如下deployment定义（nginx-deployment.yml）：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">nginx-deployment</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  selector:</span></span><br><span class="line"><span class="attr">    matchLabels:</span></span><br><span class="line"><span class="attr">      name:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">  replicas:</span> <span class="number">3</span></span><br><span class="line"><span class="attr">  template:</span></span><br><span class="line"><span class="attr">    metadata:</span></span><br><span class="line"><span class="attr">      labels:</span></span><br><span class="line"><span class="attr">        name:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">    spec:</span></span><br><span class="line"><span class="attr">      containers:</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">          image:</span> <span class="attr">nginx:1.7.9</span></span><br><span class="line"><span class="attr">          imagePullPolicy:</span> <span class="string">IfNotPresent</span></span><br><span class="line"><span class="attr">          ports:</span></span><br><span class="line"><span class="attr">            - containerPort:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure><p></p><p>创建该deployment：</p><p><img src="img/QQ截图20191106094755.png" alt="QQ截图20191106094755.png"></p><p>通过kubectl命令将nginx的版本更新到1.9.1：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl <span class="built_in">set</span> image deployment/nginx-deployment nginx=nginx:1.9.1</span><br></pre></td></tr></table></figure><p></p><p>查看滚动升级的过程：</p><p><img src="img/QQ截图20191106095447.png" alt="QQ截图20191106095447.png"></p><p>查看Pod，会发现名称已经改变了：</p><p><img src="img/QQ截图20191106095549.png" alt="QQ截图20191106095549.png"></p><p>上述滚动升级的过程可以用下图表示：</p><p><img src="img/QQ截图20191106101327.png" alt="QQ截图20191106101327.png"></p><p>查看Deployment nginx-deployment的详细事件信息可以证明这一点：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl describe deployments/nginx-deployment</span><br></pre></td></tr></table></figure><p></p><p><img src="img/QQ截图20191106100133.png" alt="QQ截图20191106100133.png"></p><p>查看rs：</p><p><img src="img/QQ截图20191106102115.png" alt="QQ截图20191106102115.png"></p><p>默认的升级策略为RollingUpdate（滚动更新），Kubernetes还支持Recreate（重建）策略：</p><ol><li><p>Recreate：先杀掉所有正在运行的Pod，然后创建新的Pod。</p></li><li><p>RollingUpdate：以滚动更新的方式来逐个更新Pod。同时，可以通过设置spec.strategy.rollingUpdate下的两个参数（maxUnavailable和maxSurge）来控制滚动更新的过程。</p></li></ol><p>RollingUpdate的两个参数含义如下：</p><ol><li><p>maxUnavailable：用于指定Deployment在更新过程中不可用状态的Pod数量的上限。该maxUnavailable的数值可以是绝对值（例如1）或Pod期望的副本数的百分比（例如10%）。</p></li><li><p>maxSurge：用于指定在Deployment更新Pod的过程中Pod总数超过Pod期望副本数部分的最大值。该maxSurge的数值可以是绝对值（例如5）或Pod期望副本数的百分比（例如10%）。</p></li></ol><div class="note info"><p>此外，除了使用kubectl命令升级外，我们也可以直接通过修改deployment.yml的方式来完成。</p></div><h2 id="Deployment回滚"><a href="#Deployment回滚" class="headerlink" title="Deployment回滚"></a>Deployment回滚</h2><p>如果升级后效果不满意的话，我们也可以将Deployment回滚到升级之前，使用下面这条命令查看滚动升级的历史：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl rollout history deployment/nginx-deployment</span><br></pre></td></tr></table></figure><p></p><p><img src="img/QQ截图20191106103606.png" alt="QQ截图20191106103606.png"></p><p>REVISION为升级的历史版本，我们只完成了nginx从1.7.9升级到1.9.1的过程，所以REVISION 1表示nginx为1.7.9的版本，REVISION 2表示nginx为1.9.1的版本。因为我们在创建deployment的时候没有加上<code>--record=true</code>参数，所以CHANGE-CACSE列是空的。</p><p>需要查看特定版本的详细信息，则可以加上–revision=<n>参数：</n></p><p><img src="img/QQ截图20191106104520.png" alt="QQ截图20191106104520.png"></p><p>要将nginx回退到1.7.9版本，我们可以将REVISION指定为1：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl rollout undo deployment/nginx-deployment --to-revision=1</span><br></pre></td></tr></table></figure><p></p><p><img src="img/QQ截图20191106105253.png" alt="QQ截图20191106105253.png"></p><p><img src="img/QQ截图20191106105638.png" alt="QQ截图20191106105638.png"></p><h2 id="暂停与恢复"><a href="#暂停与恢复" class="headerlink" title="暂停与恢复"></a>暂停与恢复</h2><p>因为Deployment配置一旦修改就会触发升级操作，所以当修改的地方较多的时候就会频繁触发升级。我们可以先暂停升级操作，当所有配置都修改好后再恢复升级。</p><p>暂停：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl rollout pause deployment/nginx-deployment</span><br></pre></td></tr></table></figure><p></p><p>暂停后，对nginx-deployment的修改不会触发升级。修改好后，恢复升级：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl rollout resume deployment/nginx-deployment</span><br></pre></td></tr></table></figure><p></p><h2 id="其他Pod管理对象升级策略"><a href="#其他Pod管理对象升级策略" class="headerlink" title="其他Pod管理对象升级策略"></a>其他Pod管理对象升级策略</h2><h3 id="DaemonSet"><a href="#DaemonSet" class="headerlink" title="DaemonSet"></a>DaemonSet</h3><p>DaemonSet的升级策略包括两种：OnDelete和RollingUpdate：</p><ol><li><p>OnDelete（默认）：在创建好新的DaemonSet配置之后，新的Pod并不会被自动创建，直到用户手动删除旧版本的Pod，才触发新建操作。</p></li><li><p>RollingUpdate：和前面介绍的一致，不过不支持rollout，只能通过将配置改回去来实现。</p></li></ol><h3 id="StatefulSet"><a href="#StatefulSet" class="headerlink" title="StatefulSet"></a>StatefulSet</h3><p>支持Recreate、OnDelete和RollingUpdate。</p><blockquote><p>《Kubernetes权威指南(第4版)》读书笔记</p></blockquote><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Tue Dec 17 2019 19:26:13 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;当集群中的某个服务需要升级时，我们需要停止目前与该服务相关的所有Pod，然后下载新版本镜像并创建新的Pod。如果集群规模比较大，则这个工作变成了一个挑战，而且先全部停止然后逐步升级的方式会导致较长时间的服务不可用。Kubernetes提供了滚动升级功能来解决上述问题。如果在更新过程中发生了错误，则还可以通过回滚操作恢复Pod的版本。
    
    </summary>
    
    
      <category term="Kubernetes" scheme="http://mrbird.cc/tags/Kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>Kubernetes Pod管理对象与调度策略</title>
    <link href="http://mrbird.cc/Kubernetes-Pod-Mananger.html"/>
    <id>http://mrbird.cc/Kubernetes-Pod-Mananger.html</id>
    <published>2019-11-04T01:14:06.000Z</published>
    <updated>2019-11-08T09:57:27.638Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Tue Dec 17 2019 19:26:13 GMT+0800 (GMT+08:00) --><p>在前面的学习中我们了解到，在Kubernetes中，Pod管理对象主要有RC(RS)、Deployment、StatefulSet、DaemonSet和Job（CronJob）等。其中RC(RS)和Deployment的用法已经大致了解，这里主要记录下StatefulSet、DaemonSet和Job（CronJob）的用法。默认情况下，Pod管理对象在创建Pod的时候是根据系统自动调度算法来完成部署的，我们可以设置调度策略来实现Pod的精准调度。</p><a id="more"></a><h2 id="Pod调度策略"><a href="#Pod调度策略" class="headerlink" title="Pod调度策略"></a>Pod调度策略</h2><h3 id="NodeSelector"><a href="#NodeSelector" class="headerlink" title="NodeSelector"></a>NodeSelector</h3><p>我们可以该某个节点Node设置标签，然后通过NodeSelector让Pod调度到该节点上。</p><p>前面搭建的Kubernetes集群有两个worker节点node1和node2，我们给node2打个标签：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl label nodes node2 tier=frontend</span><br></pre></td></tr></table></figure><p></p><p>接着定义一个RC配置（node-select-pod.yml）：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ReplicationController</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">test-rc</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  replicas:</span> <span class="number">1</span></span><br><span class="line"><span class="attr">  selector:</span></span><br><span class="line"><span class="attr">    name:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">  template:</span></span><br><span class="line"><span class="attr">    metadata:</span></span><br><span class="line"><span class="attr">      labels:</span></span><br><span class="line"><span class="attr">        name:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">    spec:</span></span><br><span class="line"><span class="attr">      containers:</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">          image:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">          ports:</span></span><br><span class="line"><span class="attr">            - containerPort:</span> <span class="number">80</span></span><br><span class="line"><span class="attr">      nodeSelector:</span></span><br><span class="line"><span class="attr">        tier:</span> <span class="string">frontend</span></span><br></pre></td></tr></table></figure><p></p><p>创建该RC，观察Pod最终调度的节点：</p><p><img src="img/QQ截图20191105202135.png" alt="图片"></p><p>可以看到nginx pod已经成功调度到了node2节点上。</p><p>Kubernetes会给每个node贴上一些默认的标签，通过<code>kubectl get node node1 -o yaml</code>可以看到这些默认的标签：</p><p><img src="img/QQ截图20191105152923.png" alt="QQ截图20191105152923.png"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">beta.kubernetes.io/arch: amd64</span><br><span class="line">beta.kubernetes.io/os: linux</span><br><span class="line">kubernetes.io/arch: amd64</span><br><span class="line">kubernetes.io/hostname: node1</span><br><span class="line">kubernetes.io/os: linux</span><br></pre></td></tr></table></figure><p>这些默认的标签在下面这些调度策略中也是蛮常用的。</p><h3 id="NodeAffinity"><a href="#NodeAffinity" class="headerlink" title="NodeAffinity"></a>NodeAffinity</h3><p>Affinity[əˈfɪnəti]：亲和力，喜好。NodeAffinity为Node亲和力调度，主要有两个规则（名称有点长，快18cm了吧）:</p><ol><li><p>RequiredDuringSchedulingIgnoredDuringExecution：必须满足指定的规则才可以调度Pod，硬规则。</p></li><li><p>PreferredDuringSchedulingIgnoredDuringExecution：软规则，最好满足所列出的条件才调度Pod。</p></li></ol><p>IgnoredDuringExecution的意思是，如果一个Pod已经调度到某个节点上了，然后这个节点的标签发生了改变，那么不影响已经调度好的Pod，ignore。</p><p>定义一个配置文件（node-affinity.yml），用于演示NodeAffinity：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ReplicationController</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">test-rc</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  replicas:</span> <span class="number">1</span></span><br><span class="line"><span class="attr">  selector:</span></span><br><span class="line"><span class="attr">    name:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">  template:</span></span><br><span class="line"><span class="attr">    metadata:</span></span><br><span class="line"><span class="attr">      labels:</span></span><br><span class="line"><span class="attr">        name:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">    spec:</span></span><br><span class="line"><span class="attr">      containers:</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">          image:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">          ports:</span></span><br><span class="line"><span class="attr">            - containerPort:</span> <span class="number">80</span></span><br><span class="line"><span class="attr">      affinity:</span></span><br><span class="line"><span class="attr">        nodeAffinity:</span></span><br><span class="line"><span class="attr">          requiredDuringSchedulingIgnoredDuringExecution:</span></span><br><span class="line"><span class="attr">            nodeSelectorTerms:</span></span><br><span class="line"><span class="attr">              - matchExpressions:</span></span><br><span class="line"><span class="attr">                  - key:</span> <span class="string">beta.kubernetes.io/arch</span></span><br><span class="line"><span class="attr">                    operator:</span> <span class="string">In</span></span><br><span class="line"><span class="attr">                    values:</span></span><br><span class="line"><span class="bullet">                      -</span> <span class="string">amd64</span></span><br><span class="line"><span class="attr">          preferredDuringSchedulingIgnoredDuringExecution:</span></span><br><span class="line"><span class="attr">            - weight:</span> <span class="number">1</span></span><br><span class="line"><span class="attr">              preference:</span></span><br><span class="line"><span class="attr">                matchExpressions:</span></span><br><span class="line"><span class="attr">                  - key:</span> <span class="string">disk-type</span></span><br><span class="line"><span class="attr">                    operator:</span> <span class="string">In</span></span><br><span class="line"><span class="attr">                    values:</span></span><br><span class="line"><span class="bullet">                      -</span> <span class="string">ssd</span></span><br></pre></td></tr></table></figure><p></p><p>上面配置使得RC在调度nginx pod的时候需要满足：节点具有beta.kubernetes.io/arch=amd64标签，如果具有disk-type=ssd标签就更好了，换句话说就是希望nginx pod调度在cpu架构为amd，磁盘为ssd的节点上。</p><p>上面配置中，操作符<code>operator</code>除了可以使用In外，还可以使用NotIn、Exists、DoesNotExist、Gt、Lt。</p><p>NodeAffinity规则设置需要注意的几个点：</p><ol><li><p>如果nodeAffinity指定了多个nodeSelectorTerms，那么其中一个能够匹配成功即可；</p></li><li><p>如果在nodeSelectorTerms中有多个matchExpressions，则一个节点必须满足所有matchExpressions才能运行该Pod。</p></li></ol><p>运行上面这个配置：</p><p><img src="img/QQ截图20191105202725.png" alt="QQ截图20191105202725.png"></p><p>可以看到，因为node1和node2都具有beta.kubernetes.io/arch=amd64标签，而没有disk-type=ssd标签，所以nginx pod有可能被调度到node1也有可能被调度到node2。</p><p>我们给node1添加disk-type=ssd标签，重新运行上面的配置文件：</p><p><img src="img/QQ截图20191105203033.png" alt="QQ截图20191105203033.png"></p><p>可以看到，nginx pod被调度到了node1上。</p><h3 id="PodAffinity"><a href="#PodAffinity" class="headerlink" title="PodAffinity"></a>PodAffinity</h3><p>PodAffinity指的是Pod亲和力调度股则，比如某些节点已经存在一些Pod了，新的Pod在调度的时候希望和指定Pod在一台节点上，亦或有意避开和指定Pod在一台节点上，这时候就可以用PodAffinity实现。</p><p>NodeAffinity规则设置也是通过<code>requiredDuringSchedulingIgnoredDuringExecution</code>和<code>PreferredDuringSchedulingIgnoredDuringExecution</code>实现的。此外，NodeAffinity还需要设置topology（拓扑规则），意为表达节点所属的topology范围：</p><ol><li><p>kubernetes.io/hostname（节点所处的服务器）</p></li><li><p>failure-domain.beta.kubernetes.io/zone（节点所处的服务器云盘分区）</p></li><li><p>failure-domain.beta.kubernetes.io/region（节点所处的服务器云盘所在的地区）</p></li></ol><p>要演示PodAffinity的使用，需要先创建一个参照Pod，创建一个参照Pod的配置文件（flag-pod.yml）:</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">flag-pod</span></span><br><span class="line"><span class="attr">  labels:</span></span><br><span class="line"><span class="attr">    tier:</span> <span class="string">frontend</span></span><br><span class="line"><span class="attr">    app:</span> <span class="string">flag-nginx</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  containers:</span></span><br><span class="line"><span class="attr">    - name:</span> <span class="string">flag-nginx</span></span><br><span class="line"><span class="attr">      image:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">      ports:</span></span><br><span class="line"><span class="attr">        - containerPort:</span> <span class="number">8081</span></span><br></pre></td></tr></table></figure><p></p><p>这个Pod具有<code>tier=frontend</code>和<code>app=flag-nginx</code>标签。</p><p>创建这个参照Pod：</p><p><img src="img/QQ截图20191105203331.png" alt="QQ截图20191105203331.png"></p><p>参照pod运行在了node1节点上。</p><p>创建好后，接着定义一个新的配置类（pod-affinity.yml）：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: pod-affinity</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">    - name: nginx</span><br><span class="line">      image: nginx</span><br><span class="line">      ports:</span><br><span class="line">        - containerPort: 80</span><br><span class="line">  affinity:</span><br><span class="line">    podAffinity:</span><br><span class="line">      requiredDuringSchedulingIgnoredDuringExecution:</span><br><span class="line">        - labelSelector:</span><br><span class="line">            matchExpressions:</span><br><span class="line">              - key: tier</span><br><span class="line">                operator: In</span><br><span class="line">                values:</span><br><span class="line">                  - frontend</span><br><span class="line">          topologyKey: kubernetes.io/hostname</span><br></pre></td></tr></table></figure><p></p><p>上述配置要求，nginx pod需要和标签包含tier=frontend的Pod分配在同一个Node上（topologyKey: kubernetes.io/hostname），创建该Pod，观察它被调度到哪个节点上了：</p><p><img src="img/QQ截图20191105203532.png" alt="QQ截图20191105203532.png"></p><p>podAntiAffinity和podAffinity刚好相反，举个例子，创建一个新的配置类（pod-affinity-two.yml）：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">pod-affinity-two</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  containers:</span></span><br><span class="line"><span class="attr">    - name:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">      image:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">      ports:</span></span><br><span class="line"><span class="attr">        - containerPort:</span> <span class="number">80</span></span><br><span class="line"><span class="attr">  affinity:</span></span><br><span class="line"><span class="attr">    podAntiAffinity:</span></span><br><span class="line"><span class="attr">      requiredDuringSchedulingIgnoredDuringExecution:</span></span><br><span class="line"><span class="attr">        - labelSelector:</span></span><br><span class="line"><span class="attr">            matchExpressions:</span></span><br><span class="line"><span class="attr">              - key:</span> <span class="string">app</span></span><br><span class="line"><span class="attr">                operator:</span> <span class="string">In</span></span><br><span class="line"><span class="attr">                values:</span></span><br><span class="line"><span class="bullet">                  -</span> <span class="string">flag-nginx</span></span><br><span class="line"><span class="attr">          topologyKey:</span> <span class="string">kubernetes.io/hostname</span></span><br></pre></td></tr></table></figure><p></p><p>上面配置希望nginx pod不和app=flag-nginx的Pod在同一个节点。</p><p>创建该Pod，观察它被调度到哪个节点上了：</p><p><img src="img/QQ截图20191105203938.png" alt="QQ截图20191105203938.png"></p><p>可以看到，它和flag-nginx处于不同的节点，位于node2。</p><h3 id="Taints-amp-Tolerations"><a href="#Taints-amp-Tolerations" class="headerlink" title="Taints &amp; Tolerations"></a>Taints &amp; Tolerations</h3><p>Taints用于给节点添加污点，而Tolerations用于定义Pod对节点污点的容忍度。在Node上设置一个或多个Taint之后，除非Pod明确声明能够容忍这些污点，否则无法在这些Node上运行。Toleration是Pod的属性，让Pod能够（注意，只是能够，而非必须）运行在标注了Taint的Node上。</p><p>给节点设置污点的语法为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl taint nodes [nodeName] key=value:rule</span><br></pre></td></tr></table></figure><p></p><p>其中rule的取值有：</p><ol><li><p>NoScheudle：不调度；</p></li><li><p>PreferNoSchedule：最好不要调度；</p></li><li><p>NoExecute：不运行；</p></li><li><p>PreferNoExecute：最好不运行。</p></li></ol><p>NoSchedule和NoExecute区别：</p><ul><li>NoSchedule不调度，如果是在调度后设置的污点，并且Pod没有容忍该污点，也能继续执行</li><li>NoExecute不执行，如果是在调度后设置的污点，并且Pod没有容忍该污点，则会被驱逐。可以设置驱逐时间<code>tolerationSeconds: xx</code>。</li></ul><p>我们给node1节点设置一个污点：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl taint nodes node1 aa=bb:NoSchedule</span><br></pre></td></tr></table></figure><p></p><p>然后新建一个Pod配置类（pod-taint-test.yml）：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">pod-taint</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  containers:</span></span><br><span class="line"><span class="attr">    - name:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">      image:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">      ports:</span></span><br><span class="line"><span class="attr">        - containerPort:</span> <span class="number">80</span></span><br><span class="line"><span class="attr">  tolerations:</span></span><br><span class="line"><span class="attr">    - key:</span> <span class="string">"aa"</span></span><br><span class="line"><span class="attr">      operator:</span> <span class="string">"Equal"</span></span><br><span class="line"><span class="attr">      value:</span> <span class="string">"bb"</span></span><br><span class="line"><span class="attr">      effect:</span> <span class="string">"NoSchedule"</span></span><br></pre></td></tr></table></figure><p></p><p>Pod的Toleration声明中的key和effect需要与Taint的设置保持一致，并且满足以下条件之一：</p><ol><li><p>operator的值是Exists（无须指定value），如：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">......</span></span><br><span class="line"><span class="attr">  tolerations:</span></span><br><span class="line"><span class="attr">    - key:</span> <span class="string">"aa"</span></span><br><span class="line"><span class="attr">      operator:</span> <span class="string">"Exists"</span></span><br><span class="line"><span class="attr">      effect:</span> <span class="string">"NoSchedule"</span></span><br></pre></td></tr></table></figure></li><li><p>operator的值是Equal并且value相等。如果不指定operator，则默认值为Equal。</p></li></ol><p>另外，有如下两个特例：</p><ol><li>空的key配合Exists操作符能够匹配所有的键和值；</li><li>空的effect匹配所有的effect。</li></ol><p>回到pod-taint-test.yml，该配置文件定义nginx pod可以容忍<code>aa=bb:NoSchedule</code>这个污点，所以它有可能会被调度到node1上。创建该Pod，观察：</p><p><img src="img/QQ截图20191105204219.png" alt="QQ截图20191105204219.png"></p><p>这时候在nginx pod所运行的节点node1上新增一个污点：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl taint nodes node1 cc=dd:NoExecute</span><br></pre></td></tr></table></figure><p></p><p>观察nginx pod情况：</p><p><img src="img/QQ截图20191105204303.png" alt="QQ截图20191105204303.png"></p><p>可以看到它被驱逐了，已经没有正在运行的pod了。</p><h3 id="Pod-Priority-Preemption"><a href="#Pod-Priority-Preemption" class="headerlink" title="Pod Priority Preemption"></a>Pod Priority Preemption</h3><p>我们可以给Pod指定优先级，优先级可以通过PriorityClass对象创建，比如创建一个优先级为10000的PriorityClass：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">scheduling.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">PriorityClass</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">hign-priority</span></span><br><span class="line"><span class="attr">value:</span> <span class="number">10000</span></span><br><span class="line"><span class="attr">globalDefault:</span> <span class="literal">false</span></span><br><span class="line"><span class="attr">description:</span> <span class="string">"10000优先级"</span></span><br></pre></td></tr></table></figure><p></p><p>上述文件定义了一个名为high-priority的优先级类别，优先级为10000，数字越大，优先越高。超过一亿的数字被系统保留，用于指派给系统组件。</p><p>优先级创建后，可以在Pod定义中引用该优先级：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">...</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  containers:</span></span><br><span class="line"><span class="attr">    - name:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">      image:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">      ports:</span></span><br><span class="line"><span class="attr">        - containerPort:</span> <span class="number">80</span></span><br><span class="line"><span class="attr">  priorityClassName:</span> <span class="string">hign-priority</span></span><br></pre></td></tr></table></figure><p></p><h2 id="Pod管理对象"><a href="#Pod管理对象" class="headerlink" title="Pod管理对象"></a>Pod管理对象</h2><h3 id="Job"><a href="#Job" class="headerlink" title="Job"></a>Job</h3><p>Job是一种特殊的Pod管理对象，是一种一次性Pod运行任务，任务结束后，Pod的生命周期也就结束了。</p><p>定义一个Job配置类（job.yml）：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">batch/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Job</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">job-ex</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  template:</span></span><br><span class="line"><span class="attr">    spec:</span></span><br><span class="line"><span class="attr">      containers:</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">job</span></span><br><span class="line"><span class="attr">          image:</span> <span class="string">busybox</span></span><br><span class="line"><span class="attr">          command:</span> <span class="string">["echo",</span> <span class="string">"hello job"</span><span class="string">]</span></span><br><span class="line"><span class="attr">      restartPolicy:</span> <span class="string">Never</span></span><br></pre></td></tr></table></figure><p></p><p>Job的重启策略<code>restartPolicy</code>只支持Never和OnFailure。</p><p>创建这个Job：</p><p><img src="img/QQ截图20191105140915.png" alt="QQ截图20191105140915.png"></p><p>查看Job状态：</p><p><img src="img/QQ截图20191105141330.png" alt="QQ截图20191105141330.png"></p><p>COMPLETIONS 1/1表示总共需要执行1个任务，共执行完1个任务。</p><p>查看对应Pod的状态：</p><p><img src="img/QQ截图20191105141452.png" alt="QQ截图20191105141452.png"></p><p>状态为Completed。</p><p>查看Job日志：</p><p><img src="img/QQ截图20191105141618.png" alt="QQ截图20191105141618.png"></p><p>Job还可以设置并发数量和总Job数，修改上面的job.yml：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">batch/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Job</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">job-ex</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  parallelism:</span> <span class="number">2</span> <span class="comment"># 并发数2</span></span><br><span class="line"><span class="attr">  completions:</span> <span class="number">6</span> <span class="comment"># 总的Job数量</span></span><br><span class="line"><span class="attr">  template:</span></span><br><span class="line"><span class="attr">    spec:</span></span><br><span class="line"><span class="attr">      containers:</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">job</span></span><br><span class="line"><span class="attr">          image:</span> <span class="string">busybox</span></span><br><span class="line"><span class="attr">          command:</span> <span class="string">["echo",</span> <span class="string">"hello job"</span><span class="string">]</span></span><br><span class="line"><span class="attr">      restartPolicy:</span> <span class="string">Never</span></span><br></pre></td></tr></table></figure><p></p><p>运行该Job： <img src="img/QQ截图20191105142838.png" alt="QQ截图20191105142838.png"></p><p>查看Pod：</p><p><img src="img/QQ截图20191105142918.png" alt="QQ截图20191105142918.png"></p><h3 id="CronJob"><a href="#CronJob" class="headerlink" title="CronJob"></a>CronJob</h3><p>CronJob顾名思义就是支持Cron表达式的Job，不过Kubernetes的Cron表达式和传统的Cron表达式不太一样，不支持到秒级。具体规则如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Minutes Hours DayofMonth Month DayofWeek Year</span><br></pre></td></tr></table></figure><p></p><ol><li><p>Minutes：可出现<code>,</code> <code>-</code> <code>*</code> <code>/</code> 这4个字符，有效范围为0～59的整数。</p></li><li><p>Hours：可出现<code>,</code> <code>-</code> <code>*</code> <code>/</code>这4个字符， 有效范围为0～23的整数。</p></li><li><p>DayofMonth：可出现<code>,</code> <code>-</code> <code>*</code> <code>/</code> <code>?</code> <code>L</code> <code>W</code> <code>C</code> 这8个字符，有效范围为0～31的整数。</p></li><li><p>Month：可出现<code>,</code> <code>-</code> <code>*</code> <code>/</code>这4个字符，有效范围为1～12的整数或JAN～DEC。</p></li><li><p>DayofWeek：可出现<code>,</code> <code>-</code> <code>*</code> <code>/</code> <code>?</code> <code>L</code> <code>C</code> <code>＃</code>这8个字符，有效范围为1～7的整数或SUN～SAT。1表示星期天，2表示星期一，以此类推。</p></li></ol><p>上面特殊字符的含义如下：</p><ol><li><p><code>*</code>：表示匹配该域的任意值，假如在Minutes域使用<code>*</code>，则表示每分钟都会触发事件。</p></li><li><p><code>/</code>：表示从起始时间开始触发，然后每隔固定时间触发一次，例如在Minutes域设置为5/20，则意味着第1次触发在第5min时，接下来每20min触发一次，将在第25min、第45min等时刻分别触发。</p></li></ol><p>定义一个CronJob的配置类（cron-job.yml）：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">batch/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">CronJob</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">cron-job-ex</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  schedule:</span> <span class="string">"*/1 * * * *"</span></span><br><span class="line"><span class="attr">  jobTemplate:</span></span><br><span class="line"><span class="attr">    spec:</span></span><br><span class="line"><span class="attr">      template:</span></span><br><span class="line"><span class="attr">        spec:</span></span><br><span class="line"><span class="attr">          containers:</span></span><br><span class="line"><span class="attr">            - name:</span> <span class="string">hello</span></span><br><span class="line"><span class="attr">              image:</span> <span class="string">busybox</span></span><br><span class="line"><span class="attr">              command:</span> <span class="string">["sh",</span> <span class="string">"-c"</span><span class="string">,</span> <span class="string">"date;echo hello cronJob"</span><span class="string">]</span></span><br><span class="line"><span class="attr">          restartPolicy:</span> <span class="string">Never</span></span><br></pre></td></tr></table></figure><p></p><p>上面的定时任务每分钟执行一次。</p><p>创建该CronJob：</p><p><img src="img/QQ截图20191105144308.png" alt="QQ截图20191105144308.png"></p><p>过个两三分钟查看运行情况：</p><p><img src="img/QQ截图20191105145147.png" alt="QQ截图20191105145147.png"></p><h3 id="DaemonSet"><a href="#DaemonSet" class="headerlink" title="DaemonSet"></a>DaemonSet</h3><p>DaemonSet适用于在每个Node都需要运行一个Pod的时候使用，比如：每一个Node上运行一个日志采集、性能监控的Pod。</p><p>比如我们现在需要在每个节点上都部署一个node-exporter来采集节点信息，可以通过DaemonSet来实现。</p><p>定义一个DaemonSet配置文件（daemonset.yml）：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">DaemonSet</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">node-exporter-d</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  selector:</span></span><br><span class="line"><span class="attr">    matchLabels:</span></span><br><span class="line"><span class="attr">      name:</span> <span class="string">node-exporter</span></span><br><span class="line"><span class="attr">  template:</span></span><br><span class="line"><span class="attr">    metadata:</span></span><br><span class="line"><span class="attr">      labels:</span></span><br><span class="line"><span class="attr">        name:</span> <span class="string">node-exporter</span></span><br><span class="line"><span class="attr">    spec:</span></span><br><span class="line"><span class="attr">      containers:</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">node-exporter</span></span><br><span class="line"><span class="attr">          image:</span> <span class="string">prom/node-exporter</span></span><br><span class="line"><span class="attr">          ports:</span></span><br><span class="line"><span class="attr">            - containerPort:</span> <span class="number">9100</span></span><br></pre></td></tr></table></figure><p></p><p>创建该DaemonSet之前先删除上面在node1节点上创建的污点：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubectl taint nodes node1 aa:NoSchedule-</span><br><span class="line">kubectl taint nodes node1 cc:NoExecute-</span><br></pre></td></tr></table></figure><p></p><p>创建该DaemonSet，然后观察Pod信息，看是否每个节点都部署了一个实例：</p><p><img src="img/QQ截图20191105205401.png" alt="QQ截图20191105205401.png"></p><h3 id="StatefulSet"><a href="#StatefulSet" class="headerlink" title="StatefulSet"></a>StatefulSet</h3><p>系统学习PV/PVC后再深入。</p><blockquote><p>《Kubernetes权威指南(第4版)》读书笔记</p></blockquote><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Tue Dec 17 2019 19:26:13 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;在前面的学习中我们了解到，在Kubernetes中，Pod管理对象主要有RC(RS)、Deployment、StatefulSet、DaemonSet和Job（CronJob）等。其中RC(RS)和Deployment的用法已经大致了解，这里主要记录下StatefulSet、DaemonSet和Job（CronJob）的用法。默认情况下，Pod管理对象在创建Pod的时候是根据系统自动调度算法来完成部署的，我们可以设置调度策略来实现Pod的精准调度。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Kubernetes" scheme="http://mrbird.cc/tags/Kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>Kubernetes Pod基础</title>
    <link href="http://mrbird.cc/Kubernetes-Pod-Basic.html"/>
    <id>http://mrbird.cc/Kubernetes-Pod-Basic.html</id>
    <published>2019-11-03T02:50:14.000Z</published>
    <updated>2019-11-03T09:32:24.908Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Tue Dec 17 2019 19:26:13 GMT+0800 (GMT+08:00) --><p>Pod是Kubernetes的最小调度单位，包含一个或者多个容器（比如Docker容器），容器间共享网络和存储。这节主要记录什么是静态Pod，Pod容器如何共享存储，如何使用ConfigMap管理Pod配置，如何使用Downward API获取Pod信息等。<a id="more"></a></p><h2 id="静态Pod"><a href="#静态Pod" class="headerlink" title="静态Pod"></a>静态Pod</h2><p>静态Pod是由kubelet创建并管理的特殊的Pod，无法和Pod管理对象关联，并且不能通过API Server关联。创建静态Pod有配置文件方式和HTTP方式：</p><h3 id="配置文件方式"><a href="#配置文件方式" class="headerlink" title="配置文件方式"></a>配置文件方式</h3><p>在搭建Kubernetes集群的时候，从启动Master节点的日志可以看出，静态Pod的目录位于<code>/etc/kubernetes/manifests</code>：</p><p>在该目录下创建静态Pod文件：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /etc/kubernetes/manifests</span><br><span class="line">vim static-pod.yaml</span><br></pre></td></tr></table></figure><p></p><p>内容如下所示：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">static-pod</span></span><br><span class="line"><span class="attr">  labels:</span></span><br><span class="line"><span class="attr">    name:</span> <span class="string">static-pod</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  containers:</span></span><br><span class="line"><span class="attr">    - name:</span> <span class="string">static-nginx</span></span><br><span class="line"><span class="attr">      image:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">      imagePullPolicy:</span> <span class="string">IfNotPresent</span></span><br><span class="line"><span class="attr">      ports:</span></span><br><span class="line"><span class="attr">        - containerPort:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure><p></p><p>过了一会查看Pod：</p><p><img src="img/QQ截图20191103124437.png" alt="QQ截图20191103124437.png"></p><p>于静态Pod无法通过API Server直接管理，所以在Master上尝试删除这个Pod时，会使其变成Pending状态，且不会被删除。</p><p><img src="img/QQ截图20191103124756.png" alt="QQ截图20191103124756.png"></p><p>删除该Pod的操作只能是到其所在Node上将其定义文件static-pod.yaml从/etc/kubernetes/manifests目录下删除：</p><p><img src="img/QQ截图20191103124916.png" alt="QQ截图20191103124916.png"></p><h3 id="HTTP方式"><a href="#HTTP方式" class="headerlink" title="HTTP方式"></a>HTTP方式</h3><p>过设置kubelet的启动参数<code>--manifest-url</code>，kubelet将会定期从该URL地址下载Pod的定义文件，并以.yaml或.json文件的格式进行解析，然后创建Pod。</p><h2 id="Pod容器共享Volume"><a href="#Pod容器共享Volume" class="headerlink" title="Pod容器共享Volume"></a>Pod容器共享Volume</h2><p>同一个Pod的多个容器间可以共享Pod级别的Volume，举个例子：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim pod-volume.yml</span><br></pre></td></tr></table></figure><p></p><p>内容如下所示：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">pod-volume</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  containers:</span></span><br><span class="line"><span class="attr">    - name:</span> <span class="string">tomcat</span></span><br><span class="line"><span class="attr">      image:</span> <span class="string">tomcat</span></span><br><span class="line"><span class="attr">      imagePullPolicy:</span> <span class="string">IfNotPresent</span></span><br><span class="line"><span class="attr">      ports:</span></span><br><span class="line"><span class="attr">        - containerPort:</span> <span class="number">8080</span></span><br><span class="line"><span class="attr">      volumeMounts:</span></span><br><span class="line"><span class="attr">        - mountPath:</span> <span class="string">/usr/local/tomcat/logs</span></span><br><span class="line"><span class="attr">          name:</span> <span class="string">logs</span></span><br><span class="line"><span class="attr">    - name:</span> <span class="string">busybox</span></span><br><span class="line"><span class="attr">      image:</span> <span class="string">busybox</span></span><br><span class="line"><span class="attr">      imagePullPolicy:</span> <span class="string">IfNotPresent</span></span><br><span class="line"><span class="attr">      command:</span> <span class="string">["sh",</span> <span class="string">"-c"</span><span class="string">,</span> <span class="string">"tail -f /logs/catalina*.log"</span><span class="string">]</span></span><br><span class="line"><span class="attr">      volumeMounts:</span></span><br><span class="line"><span class="attr">        - mountPath:</span> <span class="string">/logs</span></span><br><span class="line"><span class="attr">          name:</span> <span class="string">logs</span></span><br><span class="line"><span class="attr">  volumes:</span></span><br><span class="line"><span class="attr">    - name:</span> <span class="string">logs</span></span><br><span class="line"><span class="attr">      emptyDir:</span> <span class="string">&#123;&#125;</span></span><br></pre></td></tr></table></figure><p></p><p>上面Pod定义中，创建了一个Pod级别的Volume，名称为logs，类型为emptyDir。这个Volume同时挂载到了tomcat的/usr/local/tomcat/logs目录下，也挂载到了busybox的/logs目录下。</p><p>创建该Pod：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl create -f pod-volume.yml</span><br></pre></td></tr></table></figure><p></p><div class="note info"><p>这里的tomcat镜像比较大，大概有500MB左右，所以在创建之前，最好在Kubernetes集群的每个节点中配置Docker镜像加速地址。</p></div><p>当pod-volume状态为ready后，查看busybox的日志：</p><p><img src="img/QQ截图20191103143252.png" alt="QQ截图20191103143252.png"></p><p>该日志为tomcat的启动日志，说明上面挂载的Volume生效了，可以通过查看tomcat<code>/usr/local/tomcat/logs</code>目录下和busybox<code>/logs</code>目录下的内容来证明这一点：</p><p><img src="img/QQ截图20191103143458.png" alt="QQ截图20191103143458.png"></p><h2 id="ConfigMap"><a href="#ConfigMap" class="headerlink" title="ConfigMap"></a>ConfigMap</h2><p>ConfigMap以一个或多个key:value的形式保存在Kubernetes系统中供应用使用，既可以用于表示一个变量的值（例如version=v1），也可以用于表示一个完整配置文件的内容（例如<code>server.xml=&lt;?xml...&gt;...</code>）。</p><h3 id="创建ConfigMap"><a href="#创建ConfigMap" class="headerlink" title="创建ConfigMap"></a>创建ConfigMap</h3><p>创建ConfigMap主要有两种方式：</p><p><strong>1.通过yml文件创建</strong></p><p>创建<code>simple-cm.yml</code>文件，内容如下所示：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ConfigMap</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">simple-cm</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line"><span class="attr">  version:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">  release:</span> <span class="string">stable</span></span><br></pre></td></tr></table></figure><p></p><p>该ConfigMap仅包含两个简单的值version和releases。</p><p>创建该ConfigMap：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl create -f simple-cm.yml</span><br></pre></td></tr></table></figure><p></p><p>查看该ConfigMap：</p><p><img src="img/QQ截图20191103145002.png" alt="QQ截图20191103145002.png"></p><p>在定义ConfigMap的时候，value除了可以使用简单的值外，还可以是整个配置文件的内容。</p><p>创建<code>file-cm.yml</code>，内容如下所示：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ConfigMap</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">file-cm</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line"><span class="attr">  serverXml:</span> <span class="string">|</span></span><br><span class="line"><span class="string">    &lt;?xml version="1.0" encoding="UTF-8"?&gt;</span></span><br><span class="line"><span class="string">    &lt;Server port="8005" shutdown="SHUTDOWN"&gt;</span></span><br><span class="line"><span class="string">      &lt;Listener className="org.apache.catalina.startup.VersionLoggerListener"/&gt;</span></span><br><span class="line"><span class="string">      &lt;Listener SSLEngine="on" className="org.apache.catalina.core.AprLifecycleListener"/&gt;</span></span><br><span class="line"><span class="string">      &lt;!-- Prevent memory leaks due to use of particular java/javax APIs--&gt;</span></span><br><span class="line"><span class="string">      &lt;Listener className="org.apache.catalina.core.JreMemoryLeakPreventionListener"/&gt;</span></span><br><span class="line"><span class="string">      &lt;Listener className="org.apache.catalina.mbeans.GlobalResourcesLifecycleListener"/&gt;</span></span><br><span class="line"><span class="string">      &lt;Listener className="org.apache.catalina.core.ThreadLocalLeakPreventionListener"/&gt;</span></span><br><span class="line"><span class="string">      &lt;GlobalNamingResources&gt;</span></span><br><span class="line"><span class="string">        &lt;Resource auth="Container" description="User database that can be updated and saved" factory="org.apache.catalina.users.MemoryUserDatabaseFactory" name="UserDatabase" pathname="conf/tomcat-users.xml" type="org.apache.catalina.UserDatabase"/&gt;</span></span><br><span class="line"><span class="string">      &lt;/GlobalNamingResources&gt;</span></span><br><span class="line"><span class="string">      &lt;Service name="Catalina"&gt;</span></span><br><span class="line"><span class="string">        &lt;Connector connectionTimeout="20000" port="8080" protocol="HTTP/1.1" redirectPort="8443"/&gt;</span></span><br><span class="line"><span class="string">        &lt;Connector port="8009" protocol="AJP/1.3" redirectPort="8443"/&gt;</span></span><br><span class="line"><span class="string">        &lt;Engine defaultHost="localhost" name="Catalina"&gt;</span></span><br><span class="line"><span class="string">          &lt;Realm className="org.apache.catalina.realm.LockOutRealm"&gt;</span></span><br><span class="line"><span class="string">            &lt;Realm className="org.apache.catalina.realm.UserDatabaseRealm" resourceName="UserDatabase"/&gt;</span></span><br><span class="line"><span class="string">          &lt;/Realm&gt;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">          &lt;Host appBase="webapps" autoDeploy="true" name="localhost" unpackWARs="true"&gt;</span></span><br><span class="line"><span class="string">            &lt;Valve className="org.apache.catalina.valves.AccessLogValve" directory="logs" pattern="%h %l %u %t &amp;quot;%r&amp;quot; %s %b" prefix="localhost_access_log" suffix=".txt"/&gt;</span></span><br><span class="line"><span class="string">          &lt;Context docBase="D:\Code\apache-tomcat-8.5.32\webapps\tj_certification" path="/tj_certification" reloadable="true" source="org.eclipse.jst.jee.server:tj_certification"/&gt;&lt;/Host&gt;</span></span><br><span class="line"><span class="string">        &lt;/Engine&gt;</span></span><br><span class="line"><span class="string">      &lt;/Service&gt;</span></span><br><span class="line"><span class="string">    &lt;/Server&gt;</span></span><br><span class="line"><span class="string"></span><span class="attr">  serverProperties:</span> <span class="string">"1catalina.org.apache.juli.AsyncFileHandler.level = FINE</span></span><br><span class="line"><span class="string">                     1catalina.org.apache.juli.AsyncFileHandler.directory = $&#123;catalina.base&#125;/logs</span></span><br><span class="line"><span class="string">                     1catalina.org.apache.juli.AsyncFileHandler.prefix = catalina.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">                     2localhost.org.apache.juli.AsyncFileHandler.level = FINE</span></span><br><span class="line"><span class="string">                     2localhost.org.apache.juli.AsyncFileHandler.directory = $&#123;catalina.base&#125;/logs</span></span><br><span class="line"><span class="string">                     2localhost.org.apache.juli.AsyncFileHandler.prefix = localhost.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">                     3manager.org.apache.juli.AsyncFileHandler.level = FINE</span></span><br><span class="line"><span class="string">                     3manager.org.apache.juli.AsyncFileHandler.directory = $&#123;catalina.base&#125;/logs</span></span><br><span class="line"><span class="string">                     3manager.org.apache.juli.AsyncFileHandler.prefix = manager.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">                     4host-manager.org.apache.juli.AsyncFileHandler.level = FINE</span></span><br><span class="line"><span class="string">                     4host-manager.org.apache.juli.AsyncFileHandler.directory = $&#123;catalina.base&#125;/logs</span></span><br><span class="line"><span class="string">                     4host-manager.org.apache.juli.AsyncFileHandler.prefix = host-manager.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">                     java.util.logging.ConsoleHandler.level = FINE</span></span><br><span class="line"><span class="string">                     java.util.logging.ConsoleHandler.formatter = org.apache.juli.OneLineFormatter</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">                     org.apache.catalina.core.ContainerBase.[Catalina].[localhost].level = INFO</span></span><br><span class="line"><span class="string">                     org.apache.catalina.core.ContainerBase.[Catalina].[localhost].handlers = 2localhost.org.apache.juli.AsyncFileHandler</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">                     org.apache.catalina.core.ContainerBase.[Catalina].[localhost].[/manager].level = INFO</span></span><br><span class="line"><span class="string">                     org.apache.catalina.core.ContainerBase.[Catalina].[localhost].[/manager].handlers = 3manager.org.apache.juli.AsyncFileHandler</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">                     org.apache.catalina.core.ContainerBase.[Catalina].[localhost].[/host-manager].level = INFO</span></span><br><span class="line"><span class="string">                     org.apache.catalina.core.ContainerBase.[Catalina].[localhost].[/host-manager].handlers = 4host-manager.org.apache.juli.AsyncFileHandler"</span></span><br></pre></td></tr></table></figure><p></p><p>创建该ConfigMap：</p><p><img src="img/QQ截图20191103150049.png" alt="QQ截图20191103150049.png"></p><p><strong>2.直接通过Kubectl命令创建</strong></p><p>通过kubectl命令创建ConfigMap主要有以下三种用法：</p><ol><li><p>通过–from-file参数从文件中进行创建，可以指定key的名称，也可以在一个命令行中创建包含多个key的ConfigMap，语法为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl cerate configmap [NAME] --from-file=[key=]source --from-file=[key=]source</span><br></pre></td></tr></table></figure></li><li><p>通过–from-file参数从目录中进行创建，该目录下的每个配置文件名都被设置为key，文件的内容被设置为value，语法为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl cerate configmap [NAME] --from-file=config-file-dir</span><br></pre></td></tr></table></figure></li><li><p>使用–from-literal时会从文本中进行创建，直接将指定的key#=value#创建为ConfigMap的内容，语法为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl cerate configmap [NAME] --from-literal=key1=value1 --from-literal=key2=value2</span><br></pre></td></tr></table></figure></li></ol><p>比如使用kubectl命令创建一个和simple-cm效果一样的ConfigMap：</p><p><img src="img/QQ截图20191103150859.png" alt="QQ截图20191103150859.png"></p><p>使用kubectl命令创建一个和file-cm效果一样的ConfigMap：</p><p>首先在当前目录下准备好两个配置文件server.xml和server.properties：</p><p><img src="img/QQ截图20191103151524.png" alt="QQ截图20191103151524.png"></p><p>然后使用kubectl命令创建：</p><p><img src="img/QQ截图20191103151751.png" alt="QQ截图20191103151751.png"></p><h3 id="Pod容器使用ConfigMap"><a href="#Pod容器使用ConfigMap" class="headerlink" title="Pod容器使用ConfigMap"></a>Pod容器使用ConfigMap</h3><p>Pod的容器要使用ConfigMap主要有两种方式：</p><ol><li>通过环境变量获取ConfigMap中的内容;</li><li>通过Volume挂载的方式将ConfigMap中的内容挂载为容器内部的文件或目录。</li></ol><p><strong>通过环境变量的方式</strong></p><p>创建一个Pod配置（simple-cm-pod.yml）：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">simple-cm-pod</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  containers:</span></span><br><span class="line"><span class="attr">    - name:</span> <span class="string">busybox</span></span><br><span class="line"><span class="attr">      image:</span> <span class="string">busybox</span></span><br><span class="line"><span class="attr">      command:</span> <span class="string">["sh",</span> <span class="string">"-c"</span><span class="string">,</span> <span class="string">"env | grep ENV"</span><span class="string">]</span> <span class="comment"># 打印名称包含ENV的环境变量</span></span><br><span class="line"><span class="attr">      env:</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">ENVVERSION</span>     <span class="comment"># 定义环境变量名称</span></span><br><span class="line"><span class="attr">          valueFrom:</span>           <span class="comment"># 值来自...</span></span><br><span class="line"><span class="attr">            configMapKeyRef:</span>   <span class="comment"># ConfigMap键的引用</span></span><br><span class="line"><span class="attr">              key:</span> <span class="string">version</span>     <span class="comment"># ConfigMap的key</span></span><br><span class="line"><span class="attr">              name:</span> <span class="string">simple-cm</span>  <span class="comment"># ConfigMap的名称</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">ENVRELEASE</span></span><br><span class="line"><span class="attr">          valueFrom:</span></span><br><span class="line"><span class="attr">            configMapKeyRef:</span></span><br><span class="line"><span class="attr">              key:</span> <span class="string">release</span></span><br><span class="line"><span class="attr">              name:</span> <span class="string">simple-cm</span></span><br></pre></td></tr></table></figure><p></p><p>创建该Pod，并查看日志：</p><p><img src="img/QQ截图20191103153532.png" alt="QQ截图20191103153532.png"></p><p>可以看到，值已经成功从ConfigMap里去到了。</p><p>如果要引用某个ConfigMap的所有内容，可以使用下面这种方式。定义一个Pod配置（simple-cm-pod-all.uyml）：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">simple-cm-pod-all</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  containers:</span></span><br><span class="line"><span class="attr">    - name:</span> <span class="string">busybox</span></span><br><span class="line"><span class="attr">      image:</span> <span class="string">busybox</span></span><br><span class="line"><span class="attr">      command:</span> <span class="string">["sh",</span> <span class="string">"-c"</span><span class="string">,</span> <span class="string">"env"</span><span class="string">]</span></span><br><span class="line"><span class="attr">      envFrom:</span></span><br><span class="line"><span class="attr">        - configMapRef:</span></span><br><span class="line"><span class="attr">            name:</span> <span class="string">simple-cm</span></span><br></pre></td></tr></table></figure><p></p><p>创建该Pod，并查看日志：</p><p><img src="img/QQ截图20191103154213.png" alt="QQ截图20191103154213.png"></p><p><strong>通过Volume挂载的方式</strong></p><p>创建一个Pod配置（file-cm-pod.yml）：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">file-cm-pod</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  containers:</span></span><br><span class="line"><span class="attr">    - name:</span> <span class="string">tomcat</span></span><br><span class="line"><span class="attr">      image:</span> <span class="string">tomcat</span></span><br><span class="line"><span class="attr">      ports:</span></span><br><span class="line"><span class="attr">        - containerPort:</span> <span class="number">8080</span></span><br><span class="line"><span class="attr">      volumeMounts:</span></span><br><span class="line"><span class="attr">        - mountPath:</span> <span class="string">/configs</span> <span class="comment"># 容器挂载目录为/configs</span></span><br><span class="line"><span class="attr">          name:</span> <span class="string">config-vm</span> <span class="comment"># 引用下面定义的这个Volume</span></span><br><span class="line"><span class="attr">  volumes:</span></span><br><span class="line"><span class="attr">    - name:</span> <span class="string">config-vm</span>   <span class="comment"># volume名称为config-vm</span></span><br><span class="line"><span class="attr">      configMap:</span>        <span class="comment"># 通过ConfigMap获取</span></span><br><span class="line"><span class="attr">        name:</span> <span class="string">file-cm</span>   <span class="comment"># 引用名称为file-cm的ConfigMap</span></span><br><span class="line"><span class="attr">        items:</span></span><br><span class="line"><span class="attr">          - key:</span> <span class="string">serverXml</span> <span class="comment"># ConfigMap里配置的key</span></span><br><span class="line"><span class="attr">            path:</span> <span class="string">server.xml</span> <span class="comment"># 值使用server.xml文件进行挂载</span></span><br><span class="line"><span class="attr">          - key:</span> <span class="string">serverProperties</span></span><br><span class="line"><span class="attr">            path:</span> <span class="string">server.properties</span></span><br></pre></td></tr></table></figure><p></p><p>创建该Pod，并进入到容器内部观察/configs目录下文件内容：</p><p><img src="img/QQ截图20191103155731.png" alt="QQ截图20191103155731.png"></p><p>可以看到名称为file-cm的ConfigMap内容已经成功挂载到了tomcat容器内部。</p><p>如果在引用ConfigMap时不指定items，则使用volumeMount方式在容器内的目录下为每个item都生成一个文件名为key的文件。</p><div class="note danger"><p>在Pod对ConfigMap进行挂载（volumeMount）操作时，在容器内部只能挂载为“目录”，无法挂载为“文件”。在挂载到容器内部后，在目录下将包含ConfigMap定义的每个item，如果在该目录下原来还有其他文件，则容器内的该目录将被挂载的ConfigMap<strong>覆盖</strong>。</p></div><h2 id="Downward-API"><a href="#Downward-API" class="headerlink" title="Downward API"></a>Downward API</h2><p>Downward API用于将Pod相关信息注入到容器内部，主要有<strong>环境变量</strong>和<strong>Volume挂载</strong>两种方式。</p><p><strong>环境变量</strong></p><p>创建一个Pod配置（dapi-pod.yml）：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">dapi-pod</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  containers:</span></span><br><span class="line"><span class="attr">    - name:</span> <span class="string">busybox</span></span><br><span class="line"><span class="attr">      image:</span> <span class="string">busybox</span></span><br><span class="line"><span class="attr">      command:</span> <span class="string">["sh",</span> <span class="string">"-c"</span><span class="string">,</span> <span class="string">"env | grep MY_POD"</span><span class="string">]</span></span><br><span class="line"><span class="attr">      env:</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">MY_POD_NAME</span></span><br><span class="line"><span class="attr">          valueFrom:</span></span><br><span class="line"><span class="attr">            fieldRef:</span></span><br><span class="line"><span class="attr">              fieldPath:</span> <span class="string">metadata.name</span> <span class="comment"># 通过downward api获取当前pod名称</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">MY_POD_NAMESPACE</span></span><br><span class="line"><span class="attr">          valueFrom:</span></span><br><span class="line"><span class="attr">            fieldRef:</span></span><br><span class="line"><span class="attr">              fieldPath:</span> <span class="string">metadata.namespace</span>  <span class="comment"># 通过downward api获取当前pod namespace</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">MY_POD_IP</span></span><br><span class="line"><span class="attr">          valueFrom:</span></span><br><span class="line"><span class="attr">            fieldRef:</span></span><br><span class="line"><span class="attr">              fieldPath:</span> <span class="string">status.podIP</span>  <span class="comment"># 通过downward api获取当前pod IP</span></span><br></pre></td></tr></table></figure><p></p><p>创建该Pod，并查看日志：</p><p><img src="img/QQ截图20191103162045.png" alt="QQ截图20191103162045.png"></p><p>通过环境变量的方式还可以将容器的requests和limits信息注入到容器的环境变量中，创建一个Pod配置（dapi-pod-container-vars.yml）：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">dapi-pod-container-vars</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  containers:</span></span><br><span class="line"><span class="attr">    - name:</span> <span class="string">busybox</span></span><br><span class="line"><span class="attr">      image:</span> <span class="string">busybox</span></span><br><span class="line"><span class="attr">      command:</span> <span class="string">["sh",</span> <span class="string">"-c"</span><span class="string">]</span></span><br><span class="line"><span class="attr">      args:</span></span><br><span class="line"><span class="bullet">        -</span> <span class="string">while</span> <span class="literal">true</span><span class="string">;do</span></span><br><span class="line">            <span class="string">echo</span> <span class="bullet">-en</span> <span class="string">'\n'</span><span class="string">;</span></span><br><span class="line">            <span class="string">printenv</span> <span class="string">MY_CPU_REQUEST</span> <span class="string">MY_CPU_LIMIT;</span></span><br><span class="line">            <span class="string">printenv</span> <span class="string">MY_MEM_REQUEST</span> <span class="string">MY_MEM_LIMIT;</span></span><br><span class="line">            <span class="string">sleep</span> <span class="number">3600</span><span class="string">;</span></span><br><span class="line">          <span class="string">done;</span></span><br><span class="line"><span class="attr">      resources:</span></span><br><span class="line"><span class="attr">        requests:</span></span><br><span class="line"><span class="attr">          memory:</span> <span class="string">"32Mi"</span></span><br><span class="line"><span class="attr">          cpu:</span> <span class="string">"125m"</span></span><br><span class="line"><span class="attr">        limits:</span></span><br><span class="line"><span class="attr">          memory:</span> <span class="string">"64Mi"</span></span><br><span class="line"><span class="attr">          cpu:</span> <span class="string">"250m"</span></span><br><span class="line"><span class="attr">      env:</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">MY_CPU_REQUEST</span></span><br><span class="line"><span class="attr">          valueFrom:</span></span><br><span class="line"><span class="attr">            resourceFieldRef:</span></span><br><span class="line"><span class="attr">              resource:</span> <span class="string">requests.cpu</span></span><br><span class="line"><span class="attr">              containerName:</span> <span class="string">busybox</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">MY_CPU_LIMIT</span></span><br><span class="line"><span class="attr">          valueFrom:</span></span><br><span class="line"><span class="attr">            resourceFieldRef:</span></span><br><span class="line"><span class="attr">              resource:</span> <span class="string">limits.cpu</span></span><br><span class="line"><span class="attr">              containerName:</span> <span class="string">busybox</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">MY_MEM_REQUEST</span></span><br><span class="line"><span class="attr">          valueFrom:</span></span><br><span class="line"><span class="attr">            resourceFieldRef:</span></span><br><span class="line"><span class="attr">              resource:</span> <span class="string">request.memory</span></span><br><span class="line"><span class="attr">              containerName:</span> <span class="string">busybox</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">MY_MEM_LIMIT</span></span><br><span class="line"><span class="attr">          valueFrom:</span></span><br><span class="line"><span class="attr">            resourceFieldRef:</span></span><br><span class="line"><span class="attr">              resource:</span> <span class="string">limits.memory</span></span><br><span class="line"><span class="attr">              containerName:</span> <span class="string">busybox</span></span><br></pre></td></tr></table></figure><p></p><p>创建该Pod并观察日志：</p><p><img src="img/QQ截图20191103163059.png" alt="QQ截图20191103163059.png"></p><p><strong>通过Volume挂载</strong></p><p>我们可以通过Downward API将Pod的Label，Annotation等信息挂载到容器内部文件中，新建一个Pod配置（dapi-pod-volumes.yml）：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">dapi-pod-volume</span></span><br><span class="line"><span class="attr">  labels:</span></span><br><span class="line"><span class="attr">    tier:</span> <span class="string">frontend</span></span><br><span class="line"><span class="attr">    release:</span> <span class="string">canary</span></span><br><span class="line"><span class="attr">    environment:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">  annotations:</span></span><br><span class="line"><span class="attr">    builder:</span> <span class="string">mrbird</span></span><br><span class="line"><span class="attr">    blog:</span> <span class="attr">https://mrbird.cc</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  containers:</span></span><br><span class="line"><span class="attr">    - name:</span> <span class="string">busybox</span></span><br><span class="line"><span class="attr">      image:</span> <span class="string">busybox</span></span><br><span class="line"><span class="attr">      command:</span> <span class="string">["sh",</span> <span class="string">"-c"</span><span class="string">,</span> <span class="string">"sleep 36000"</span><span class="string">]</span></span><br><span class="line"><span class="attr">      volumeMounts:</span></span><br><span class="line"><span class="attr">        - mountPath:</span> <span class="string">/podinfo</span> <span class="comment"># 挂载路径</span></span><br><span class="line"><span class="attr">          name:</span> <span class="string">pod-info</span></span><br><span class="line"><span class="attr">  volumes:</span></span><br><span class="line"><span class="attr">    - name:</span> <span class="string">pod-info</span></span><br><span class="line"><span class="attr">      downwardAPI:</span> <span class="comment"># 通过downward api获取pod labels和annations信息</span></span><br><span class="line"><span class="attr">        items:</span></span><br><span class="line"><span class="attr">          - path:</span> <span class="string">"labels"</span> <span class="comment"># 挂载文件名称</span></span><br><span class="line"><span class="attr">            fieldRef:</span></span><br><span class="line"><span class="attr">              fieldPath:</span> <span class="string">metadata.labels</span> <span class="comment"># 挂载内容</span></span><br><span class="line"><span class="attr">          - path:</span> <span class="string">"annotation"</span></span><br><span class="line"><span class="attr">            fieldRef:</span></span><br><span class="line"><span class="attr">              fieldPath:</span> <span class="string">metadata.annotations</span></span><br></pre></td></tr></table></figure><p></p><p>创建该Pod，并进入到容器/podinfo目录观察结果：</p><p><img src="img/QQ截图20191103171025.png" alt="QQ截图20191103171025.png"></p><h2 id="Pod生命周期"><a href="#Pod生命周期" class="headerlink" title="Pod生命周期"></a>Pod生命周期</h2><table><thead><tr><th>阶段</th><th>描述</th></tr></thead><tbody><tr><td><strong>Pending</strong></td><td>Pod 已被 Kubernetes 接受，但尚未创建一个或多个容器镜像。这包括被调度之前的时间以及通过网络下载镜像所花费的时间，执行需要一段时间。</td></tr><tr><td><strong>Running</strong></td><td>Pod 已经被绑定到了一个节点，所有容器已被创建。至少一个容器正在运行，或者正在启动或重新启动。</td></tr><tr><td><strong>Succeeded</strong></td><td>所有容器成功终止，也不会重启。</td></tr><tr><td><strong>Failed</strong></td><td>所有容器终止，至少有一个容器以失败方式终止。也就是说，这个容器要么已非 0 状态退出，要么被系统终止。</td></tr><tr><td><strong>Unknown</strong></td><td>由于一些原因，Pod 的状态无法获取，通常是与 Pod 通信时出错导致的。</td></tr></tbody></table><p>三种重启策略：</p><ol><li>Always：当容器失效时，由kubelet自动重启该容器；</li><li>OnFailure：当容器终止运行且退出码不为0时，由kubelet自动重启该容器；</li><li>Never：不论容器运行状态如何，kubelet都不会重启该容器。</li></ol><p>结合Pod的状态和重启策略，以下为一些常见的状态转换场景：</p><table align="center" border="1" cellpadding="1" cellspacing="1"><tbody><tr><td colspan="1" rowspan="2" style="text-align:center;width:107px">Pod包含的容器数</td><td colspan="1" rowspan="2" style="text-align:center;width:108px">Pod当前的状态</td><td colspan="1" rowspan="2" style="text-align:center;width:139px">发生事件</td><td colspan="3" rowspan="1" style="text-align:center;width:486px">Pod的结果状态</td></tr><tr><td style="width:137px">RestarPolicy=Always</td><td style="width:162px">RestartPolicy=OnFailure</td><td style="width:180px">RestartPolicy=Never</td></tr><tr><td style="width:107px">包含1个容器</td><td style="width:108px">Running</td><td style="width:139px">容器成功退出</td><td style="width:137px">Running</td><td style="width:162px">Succeeded</td><td style="width:180px">Succeeded</td></tr><tr><td style="width:107px">包含1个容器</td><td style="width:108px">Running</td><td style="width:139px">容器失败退出</td><td style="width:137px">Running</td><td style="width:162px">Running</td><td style="width:180px">Failed</td></tr><tr><td style="width:107px">包含两个容器</td><td style="width:108px">Running</td><td style="width:139px">1个容器失败退出</td><td style="width:137px">Running</td><td style="width:162px">Running</td><td style="width:180px">Running</td></tr><tr><td style="width:107px">包含两个容器</td><td style="width:108px">Running</td><td style="width:139px">容器被OOM杀掉</td><td style="width:137px">Running</td><td style="width:162px">Running</td><td style="width:180px">Failed</td></tr></tbody></table><blockquote><p>《Kubernetes权威指南(第4版)》读书笔记</p></blockquote><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Tue Dec 17 2019 19:26:13 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;Pod是Kubernetes的最小调度单位，包含一个或者多个容器（比如Docker容器），容器间共享网络和存储。这节主要记录什么是静态Pod，Pod容器如何共享存储，如何使用ConfigMap管理Pod配置，如何使用Downward API获取Pod信息等。
    
    </summary>
    
    
      <category term="Kubernetes" scheme="http://mrbird.cc/tags/Kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>Kubernetes基础</title>
    <link href="http://mrbird.cc/Kubernetes-Basic.html"/>
    <id>http://mrbird.cc/Kubernetes-Basic.html</id>
    <published>2019-10-30T07:36:15.000Z</published>
    <updated>2019-11-16T10:13:18.197Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Tue Dec 17 2019 19:26:13 GMT+0800 (GMT+08:00) --><p>上一节我们已经成功搭建了Kubernetes集群，Kubernetes包含了大量的概念和术语，比如Master、Node、Pod、Replication Controller、Service等等，在深入学习Kubernetes之前，有必要捋清Kubernetes架构设计和这些术语的含义。</p><a id="more"></a><h2 id="Kubernetes架构"><a href="#Kubernetes架构" class="headerlink" title="Kubernetes架构"></a>Kubernetes架构</h2><p>Kubernetes基本架构如下图所示：</p><p><img src="img/QQ截图20191030093713.png" alt="QQ截图20191030093713.png"></p><p>由上图我们可以看出，Kubernetes集群节点可分为<strong>Master</strong>和<strong>Node</strong>：</p><ul><li>Master：指的是集群中的控制节点，负责管理和控制整个集群。基本上我们对Kubernetes集群的操作都是在Master节点上完成的；</li><li>Node：除了Master外，Kubernetes集群中其他节点称为Node。每个Node都将负责运行Master指派的Docker容器，当某个Node宕机后，这些工作会被Master转移到别的Node上。</li></ul><p>Master节点上主要包含了以下这些关接的进程:</p><ol><li><strong>API Server</strong>：提供了HTTP Rest接口的关键服务进程，是Kubernetes里所有资源的增、删、改、查等操作的唯一入口，也是集群控制的入口进程；</li><li><strong>Controller Manager</strong>：负责维护集群的状态，比如故障检测，扩缩容，滚动更新等等；</li><li><strong>Scheduler</strong>：负责资源的调度，按照预定的策略把pod调度到指定的node节点；</li><li><strong>etcd</strong>：存储Kubernetes集群信息。</li></ol><p>Node节点上主要包含了以下这些关接的进程:</p><ol><li><strong>kubelet</strong>：负责Pod对应的容器的创建、启停等任务；</li><li><strong>kube-proxy</strong>：实现Kubernetes Service的通信与负载均衡机制的重要组件；</li><li><strong>docker</strong>：Docker引擎，负责本机的容器创建和管理工作；</li><li><strong>pod</strong>：Pod是Kubernetes中能够创建和部署的最小单元，是Kubernetes集群中的一个应用实例。Pod包含了一个“根容器”Pause和多个Docker容器；</li></ol><p>Kubernetes节点间的网络通信通过网络插件实现，比如Flannel，Calico等。</p><h2 id="Pod管理对象"><a href="#Pod管理对象" class="headerlink" title="Pod管理对象"></a>Pod管理对象</h2><p>Pod管理对象指的是Kubernetes中可以用于创建和管理Pod的组件，比如RC(RS)，Deployment，StableSet等等。在了解这些组件前，先来看看Pod的组成：</p><p><img src="img/QQ截图20191030105535.png" alt="QQ截图20191030105535.png"></p><p>Pod包含一个<strong>Pause</strong>容器和多个Docker容器，Pause容器用于管理这些Docker容器。</p><p>Pod可以通过yaml文件来创建，下面举个简单的例子:</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span> <span class="comment"># kind为pod表明这是一个pod定义</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">nginx-pod</span> <span class="comment"># pod名称为nginx-pod</span></span><br><span class="line"><span class="attr">  labels:</span> <span class="comment"># 定义标签信息（label）</span></span><br><span class="line"><span class="attr">    name:</span> <span class="string">nginx</span> </span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  containers:</span></span><br><span class="line"><span class="attr">    - name:</span> <span class="string">nginx</span> <span class="comment"># 容器名称</span></span><br><span class="line"><span class="attr">      image:</span> <span class="string">nginx</span> <span class="comment"># 基于nginx镜像构建</span></span><br><span class="line"><span class="attr">      imagePullPolicy:</span> <span class="string">IfNotPresent</span> <span class="comment"># 镜像拉取规则，不存在则远程拉取</span></span><br><span class="line"><span class="attr">      ports:</span></span><br><span class="line"><span class="attr">        - containerPort:</span> <span class="number">80</span> <span class="comment"># 端口</span></span><br></pre></td></tr></table></figure><p></p><p>每个Pod都包含一个唯一的IP地址，称为<strong>Pod IP</strong>，Kubernetes集群内的任意两个Pod之间都能正常通信。Pod IP加上上面定义的80端口，组成了一个<strong>Endpoint</strong>，代表此Pod里的一个服务进程的对外通信地址。Pod的相关内容存储在<strong>Volume</strong>中，Pod的相关运行记录可以通过<strong>Event</strong>查看：</p><p><img src="img/QQ截图20191030113626.png" alt="QQ截图20191030113626.png"></p><p>在定义Pod的时候我们也可以指定资源资源限额，资源主要包括<strong>CPU</strong>和<strong>Memory</strong>：</p><ul><li><p>在Kubernetes中，1m表示千分之一CPU，即1000m表示一个CPU；</p></li><li><p>常用单位有KiB、MiB和GiB等，是二进制表示的字节单位，1 KiB（KibiByte）= 2^10 Bytes = 1024 Bytes = 8192 Bits。</p></li></ul><p>在Kubernetes里，一个计算资源进行配额限定时需要设定以下两个参数：</p><ol><li><strong>Requests</strong>：该资源的最小申请量，系统必须满足要求；</li><li><strong>Limits</strong>：该资源最大允许使用的量，不能被突破，当容器试图使用超过这个量的资源时，可能会被Kubernetes“杀掉”并重启。</li></ol><p>比如修改上面的Pod配置文件，定义资源配额：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span> </span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">nginx-pod</span> </span><br><span class="line"><span class="attr">  labels:</span> </span><br><span class="line"><span class="attr">    name:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  containers:</span></span><br><span class="line"><span class="attr">    - name:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">      image:</span> <span class="string">nginx</span> </span><br><span class="line"><span class="attr">      imagePullPolicy:</span> <span class="string">IfNotPresent</span> </span><br><span class="line"><span class="attr">      ports:</span></span><br><span class="line"><span class="attr">        - containerPort:</span> <span class="number">80</span> </span><br><span class="line"><span class="attr">      resources:</span></span><br><span class="line"><span class="attr">        requests:</span></span><br><span class="line"><span class="attr">          memory:</span> <span class="string">"64Mi"</span> <span class="comment"># 至少需要64MiB内存</span></span><br><span class="line"><span class="attr">          cpu:</span> <span class="string">"200m"</span> <span class="comment"># 至少需要0.2个CPU</span></span><br><span class="line"><span class="attr">        limits:</span></span><br><span class="line"><span class="attr">          memory:</span> <span class="string">"128Mi"</span> <span class="comment"># 内存消耗不能多于128MiB</span></span><br><span class="line"><span class="attr">          cpu:</span> <span class="string">"500m"</span> <span class="comment"># CPU消耗不能多于0.5</span></span><br></pre></td></tr></table></figure><p></p><p>除了直接使用Pod配置文件来创建Pod外，更为常用的是使用Pod管理对象RC(RS)、Deployment等创建和管理Pod。</p><h3 id="RC-RS"><a href="#RC-RS" class="headerlink" title="RC(RS)"></a>RC(RS)</h3><p>RC全称Replication Controller（副本控制器）,用于控制任意时刻指定Pod的数量都符合预期值。RC配置文件一般包含以下三个部分：</p><ol><li>期望的Pod副本数量；</li><li>用于筛选Pod的Label Selector；</li><li>创建Pod的模板（当数量少于预期的时候，用这个模板创建Pod）。</li></ol><p>举个RC yaml的例子：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: ReplicationController # 表示RC</span><br><span class="line">metadata:</span><br><span class="line">  name: nginx-rc # RC控制器名称为nginx-rc</span><br><span class="line">spec:</span><br><span class="line">  replicas: 3 # 期望Pod的副本数量为3</span><br><span class="line">  selector:</span><br><span class="line">    name: nginx # Label筛选器，筛选出Label包含（name=nginx）的Pod</span><br><span class="line">  template: # Pod创建模板，格式基本和我们上面定义的Pod yaml一致</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        name: nginx</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">        - name: nginx</span><br><span class="line">          image: nginx</span><br><span class="line">          imagePullPolicy: IfNotPresent</span><br><span class="line">          ports:</span><br><span class="line">            - containerPort: 80</span><br></pre></td></tr></table></figure><p></p><p>通过这个RC，我们可以实现：在Kubernetes集群中，任意时刻都存在3个运行着Nginx容器的Pod，即通过这个RC我们创建了一个Nginx数量为3的Nginx集群（其中一种可能性）：</p><p><img src="img/QQ截图20191030142008.png" alt="QQ截图20191030142008.png"></p><p>在Kubernetes的发展中，RC升级为了Replica Set，俗称RS，语法大致和RC一致。RS和RC最大的区别在于：RS拥有更为🐂🍺的Pod筛选器。比如：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ReplicaSet</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">frontend</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  replicas:</span> <span class="number">2</span></span><br><span class="line"><span class="attr">  selector:</span></span><br><span class="line"><span class="attr">    matchLabels:</span></span><br><span class="line"><span class="attr">      tier:</span> <span class="string">frontend</span></span><br><span class="line"><span class="attr">    matchExpressions:</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">&#123;key:</span> <span class="string">release,</span> <span class="attr">operator:</span> <span class="string">In,</span> <span class="attr">values:</span> <span class="string">[stable,</span> <span class="string">snapshot]&#125;</span></span><br><span class="line"><span class="attr">  template:</span></span><br><span class="line">    <span class="string">...</span></span><br></pre></td></tr></table></figure><p></p><p>上面的RS筛选Pod规则为：筛选标签包含tier为frontend，并且release的值为stable或者snapshot的Pod。</p><p>总之，RC(RS)的作用为:</p><ol><li>Pod的创建及数量控制；</li><li>通过改变RC里的Pod副本数量，可以实现Pod的扩容或缩容；</li><li>通过改变RC里Pod模板中的镜像版本，可以实现Pod的滚动升级。</li></ol><h3 id="Deployment"><a href="#Deployment" class="headerlink" title="Deployment"></a>Deployment</h3><p>Deployment可以看成是RS的升级版组件，内部使用RS管理Pod，和RS相比最大的不同在于Deployment可以随时查看Pod的部署状态。Deployment的yaml配置和RS差不多，举个Deployment yaml的例子(nginx-deployment.yml):</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: nginx-deployment</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      name: nginx</span><br><span class="line">  replicas: 3</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        name: nginx</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">        - name: nginx</span><br><span class="line">          image: nginx</span><br><span class="line">          imagePullPolicy: IfNotPresent</span><br><span class="line">          ports:</span><br><span class="line">            - containerPort: 80</span><br></pre></td></tr></table></figure><p></p><p>除了kind，其他都和RS差不多。在Kubernetes集群中创建该Deployment：</p><p><img src="img/QQ截图20191030152700.png" alt="QQ截图20191030152700.png"></p><ul><li>READY：集群中准备就绪的Pod数量；</li><li>UP-TO-DATE：最新版本的Pod的副本数量，用于指示在滚动升级的过程中，有多少个Pod副本已经成功升级；</li><li>AVAILABLE：当前集群中可用的Pod副本数量，即集群中当前存活的Pod数量。</li></ul><p>查看RS和Pod：</p><p><img src="img/QQ截图20191030153402.png" alt="QQ截图20191030153402.png"></p><p>可以看到它们的关系为deployment -&gt; rs -&gt; pods：</p><p><img src="img/QQ截图20191030154129.png" alt="QQ截图20191030154129.png"></p><h3 id="StatefulSet"><a href="#StatefulSet" class="headerlink" title="StatefulSet"></a>StatefulSet</h3><p>StatefulSet（有状态集合）可以看成是Deployment的一个变种，适合用于构建MySQL集群、MongoDB集群等有状态的集群，这些集群有以下这些共同特点：</p><ol><li>集群规模相对固定，不能随意变动；</li><li>集群中每个Pod都是有状态的，即数据会被持久化到存储中；</li><li>每个Pod都有固定的ID。</li></ol><p>StatefulSet创建的Pod集群符合上面的需求，具有如下特点:</p><ol><li>每个Pod的名称在创建前就可以确定下来了。比如StatefulSet的名称为mysql，那么第一个Pod叫mysql-0，第二个叫mysql-1，以此类推；</li><li>Pod的启停试是按照顺序来的；</li><li>Pod通过PV或者PVC来持久化存储。</li></ol><p>这里就先不深入研究StatefulSet了，后面再找机会研究。</p><h3 id="Job"><a href="#Job" class="headerlink" title="Job"></a>Job</h3><p>Job是一种特殊的Pod管理对象，是一种一次性Pod运行任务，任务结束后，Pod的生命周期也就结束了。Kubernetes中支持Cron表达式的任务称为CronJob，后面接触到了再仔细研究😪。</p><h2 id="Label"><a href="#Label" class="headerlink" title="Label"></a>Label</h2><p>就如上面所说，Label就是用于给Pod打标签用的，供Pod管理对象、Service等筛选使用。</p><h2 id="HPA"><a href="#HPA" class="headerlink" title="HPA"></a>HPA</h2><p>除了使用<code>kubectl scale</code>命令修改Pod数量实现扩容或者缩容外，我们可以借助HPA（Horizontal Pod Autoscaling，Pod横向自动扩展）来完成Pod的自动化扩缩容。举个HPA的例子：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">autoscaling/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">HorizontalPodAutoscaler</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">nginx-hpa</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">default</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  maxReplicas:</span> <span class="number">10</span></span><br><span class="line"><span class="attr">  minReplicas:</span> <span class="number">3</span></span><br><span class="line"><span class="attr">  scaleTargetRef:</span></span><br><span class="line"><span class="attr">    kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">    name:</span> <span class="string">nginx-deployment</span></span><br><span class="line"><span class="attr">  targetCPUUtilizationPercentage:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure><p></p><p>上面定义了一个名为nginx-hpa的HPA，监控名称为nginx-deployment的Deployment中的Pod，当其<code>targetCPUUtilizationPercentage</code>的值大于80%时，将发生动态扩容行为，并且Pod的数量必须再3~10之间。</p><p><code>targetCPUUtilizationPercentage</code>指的是Pod一分钟内CPU使用率的算数平均值。比如Pod的requests cpu为0.4，当前CPU使用量为0.3，则CPU使用率为75%。所以要使用HPA的功能，Pod必须指定了requests cpu值。</p><h2 id="Service"><a href="#Service" class="headerlink" title="Service"></a>Service</h2><p>Service、RC和Pod之间的关系如下图所示：</p><p><img src="img/QQ截图20191031100702.png" alt="QQ截图20191031100702.png"></p><p>从图中可以看出，Service是外界访问Pod的桥梁，Service通过Label Selector来筛选处符合的Pod，将请求均衡的转发到目标Pod上。前面例子中，我们通过Deployment创建了三个Nginx Pod，但现在外界并不能直接访问它们，我们可以创建一个Service来实现这个需求：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim nginx-service.yml</span><br></pre></td></tr></table></figure><p></p><p>内容如下所示：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">nginx-service</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  ports:</span></span><br><span class="line"><span class="attr">    - port:</span> <span class="number">8080</span></span><br><span class="line"><span class="attr">      targetPort:</span> <span class="number">80</span></span><br><span class="line"><span class="attr">      nodePort:</span> <span class="number">30001</span></span><br><span class="line"><span class="attr">  type:</span> <span class="string">NodePort</span></span><br><span class="line"><span class="attr">  selector:</span></span><br><span class="line"><span class="attr">    name:</span> <span class="string">nginx</span></span><br></pre></td></tr></table></figure><p></p><p>上面配置中<code>spec.ports</code>定义了三个端口，在了解这三个端口的含义之前，我们先了解下下面这三个IP的含义：</p><ol><li>Node IP：Node的IP地址，Node是部署在宿主机上的，所以实际上就是宿主机的IP地址，不会发生改变；</li><li>Pod IP：Pod的IP地址，由于动态扩缩容、宕机转移等原因，这个IP经常会发生改变；</li><li>Cluster IP：Service的IP地址，在一个完整的Service生命周期内是不会改变的。</li></ol><p>其中<code>Pod IP</code>和<code>Cluster IP</code>是属于Kubernetes集群范围内的，外界无法直接访问。</p><p>再回头看上面三个端口的含义：</p><ol><li>port：指定Service的端口号；</li><li>targetPort：目标Pod的端口，根据前面nginx-deployment的定义，这里应该指定为80；</li><li>nodePort：在Node上开启的监听端口，用于外界通过<code>Cluster IP:nodePort</code>来访问对应的Service。</li></ol><p>使用nodePort时，需要将Service的type指定为NodePort，并且nodePort有范围限制，必须在30000-32767之间。</p><p>使用<code>kubectl create -f nginx-service.yml</code>创建该Service：</p><p><img src="img/QQ截图20191031104422.png" alt="QQ截图20191031104422.png"></p><p>查看Service和endpoint：</p><p><img src="img/QQ截图20191031104556.png" alt="QQ截图20191031104556.png"></p><p>现在我们就可以通过<code>node1 Ip:nodePort</code>来访问Nginx Pod服务了：</p><p><img src="img/QQ截图20191031104735.png" alt="QQ截图20191031104735.png"></p><h2 id="Volume"><a href="#Volume" class="headerlink" title="Volume"></a>Volume</h2><p>Volume是Pod上能够被多个Docker容器访问的共享目录，Volume的生命周期和Pod相关，与Docker容器无关。可以在定义Pod的时候指定Volume：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">nginx-pod</span></span><br><span class="line"><span class="attr">  labels:</span></span><br><span class="line"><span class="attr">    name:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  volumes:</span></span><br><span class="line"><span class="attr">    - name:</span> <span class="string">nginx-data</span></span><br><span class="line"><span class="attr">      emptyDir:</span> <span class="string">&#123;&#125;</span></span><br><span class="line"><span class="attr">  containers:</span></span><br><span class="line"><span class="attr">    - name:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">      image:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">      imagePullPolicy:</span> <span class="string">IfNotPresent</span></span><br><span class="line"><span class="attr">      ports:</span></span><br><span class="line"><span class="attr">        - containerPort:</span> <span class="number">80</span></span><br><span class="line"><span class="attr">      volumeMounts:</span></span><br><span class="line"><span class="attr">        - mountPath:</span> <span class="string">/etc/nginx</span></span><br><span class="line"><span class="attr">          name:</span> <span class="string">nginx-data</span></span><br></pre></td></tr></table></figure><p></p><p>通常情况下，我们都是现在Pod里声明一个Volume，然后在容器里引用该Volume，并挂载到容器的某个目录上。</p><p>比较常用的Volume类型有：</p><ol><li><p>emptyDir：一个emptyDir Volume是在Pod分配到Node时创建的。从它的名称就可以看出，它的初始内容为空，并且无须指定宿主机上对应的目录文件，因为这是Kubernetes自动分配的一个目录，当Pod从Node上移除时，emptyDir中的数据也会被永久删除；</p></li><li><p>hostPath为在Pod上挂载宿主机上的文件或目录，比如：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  volumes:</span></span><br><span class="line"><span class="attr">    - name:</span> <span class="string">"persistend-storage"</span></span><br><span class="line"><span class="attr">      hostPath:</span></span><br><span class="line"><span class="attr">        path:</span> <span class="string">"/data"</span></span><br></pre></td></tr></table></figure></li></ol><h2 id="PV-PVC"><a href="#PV-PVC" class="headerlink" title="PV,PVC"></a>PV,PVC</h2><p>PV(Persistent Volume)是Kubernetes集群中的某个网络存储对应的一块存储，不属于任何Node，但可以在每个Node上访问；PVC(Persistent Volume Claim，PV声明)，某个Pod需要用到PV前，必须先定义PVC。</p><p>定一个NFS类型的PV，声明需要10Gi存储：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">PersistentVolume</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">pv01</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  capacity:</span></span><br><span class="line"><span class="attr">    storage:</span> <span class="number">10</span><span class="string">Gi</span></span><br><span class="line"><span class="attr">  accessModes:</span></span><br><span class="line"><span class="bullet">    -</span> <span class="string">ReadWriteOnce</span></span><br><span class="line"><span class="attr">  nfs:</span></span><br><span class="line"><span class="attr">    path:</span> <span class="string">/somepath</span></span><br><span class="line"><span class="attr">    server:</span> <span class="number">127.17</span><span class="number">.0</span><span class="number">.2</span></span><br></pre></td></tr></table></figure><p></p><p>该PV声明了127.17.0.2NFS系统下的/somepath目录作为网络存储，内存为10Gi，该PV名称为pv01。</p><p>accessModes有以下三种模式：</p><ol><li>ReadWriteOnce：读写权限，并且只能被单个Node挂载；</li><li>ReadOnlyMany：只读权限，允许被多个Node挂载；</li><li>ReadWriteMany：读写权限，允许被多个Node挂载。</li></ol><p>接着定义一个PVC：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">PersistentVolumeClaim</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">pvclaim</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  accessModes:</span></span><br><span class="line"><span class="bullet">    -</span> <span class="string">ReadWriteOnce</span></span><br><span class="line"><span class="attr">  resources:</span></span><br><span class="line"><span class="attr">    requests:</span></span><br><span class="line"><span class="attr">      storage:</span> <span class="number">8</span><span class="string">Gi</span></span><br></pre></td></tr></table></figure><p></p><p>该PVC声明了需要8Gi存储空间，刚刚定义的PV符合这个要求，所以会被绑定上。定义了PVC后，就可以在Pod里引用了：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  volumes:</span></span><br><span class="line"><span class="attr">    - name:</span> <span class="string">podpv</span></span><br><span class="line"><span class="attr">      persistentVolumeClaim:</span></span><br><span class="line"><span class="attr">        claimName:</span> <span class="string">pvclaim</span></span><br></pre></td></tr></table></figure><p></p><p>PV具有以下几种状态：</p><ol><li>Available：空闲状态；</li><li>Bound：已经绑定到某个PVC上；</li><li>Released：对应的PVC已经被删除，但资源还没有被集群收回；</li><li>Failed：PV自动回收失败。</li></ol><h2 id="Namespace"><a href="#Namespace" class="headerlink" title="Namespace"></a>Namespace</h2><p>Namespace顾名思义，命名空间，用于资源隔离。默认Kubernetes会创建default命名空间，并且Pod，RC等都是用该命名空间。</p><p>我们可以定义自己的命名空间：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Namespace</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">febs</span></span><br></pre></td></tr></table></figure><p></p><p>在创建Pod等资源的时候就可以指定该命名空间了：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">nginx-pod</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">febs</span></span><br><span class="line"><span class="attr">  labels:</span></span><br><span class="line"><span class="attr">    name:</span> <span class="string">nginx</span></span><br><span class="line"><span class="string">...</span></span><br></pre></td></tr></table></figure><p></p><h2 id="Annotation"><a href="#Annotation" class="headerlink" title="Annotation"></a>Annotation</h2><p>Annotation是用户任意定义的附加信息，便于外部工具查找，比如版本信息，build信息等。</p><h2 id="ConfigMap"><a href="#ConfigMap" class="headerlink" title="ConfigMap"></a>ConfigMap</h2><p>学过Docker的都知道，我们可以使用挂载目录的方式将宿主机中的配置文件映射到Docker容器内。但这在集群环境下，要挂载的配置文件过多，不仅麻烦而且容易出错，Kubernete的ConfigMap就是用于解决这个问题的。</p><p>ConfigMap存储了大量key-value配置，存储在etcd中，通过Volume的方式映射到目标Pod内，成为一份配置文件，ConfigMap实质上就是一个配置中心。</p><blockquote><p>《Kubernetes权威指南(第4版)》读书笔记</p></blockquote><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Tue Dec 17 2019 19:26:13 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;上一节我们已经成功搭建了Kubernetes集群，Kubernetes包含了大量的概念和术语，比如Master、Node、Pod、Replication Controller、Service等等，在深入学习Kubernetes之前，有必要捋清Kubernetes架构设计和这些术语的含义。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Kubernetes" scheme="http://mrbird.cc/tags/Kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>Kubernetes1.16.2安装Dashboard</title>
    <link href="http://mrbird.cc/Kubernetes1-16-2-install-Dashboard.html"/>
    <id>http://mrbird.cc/Kubernetes1-16-2-install-Dashboard.html</id>
    <published>2019-10-29T07:38:24.000Z</published>
    <updated>2019-11-08T12:06:08.417Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Tue Dec 17 2019 19:26:13 GMT+0800 (GMT+08:00) --><p>Kubernetes Dashboard是Kubernetes提供的Web用户界面，通过Dashboard我们可以将容器化的应用部署到Kubernetes集群中，对容器化的应用进行故障排除以及集群资源管理；可以通过Dashboard查看集群应用详情，创建或修改单个Kubernetes资源（例如Deployments，Jobs，DaemonSets等）。<a id="more"></a></p><h2 id="安装Dashboard"><a href="#安装Dashboard" class="headerlink" title="安装Dashboard"></a>安装Dashboard</h2><p>上节我们搭建的Kubernetes集群版本为1.16.2，截至目前为止，与该版本对应的Dashboard版本为v2.0.0-beta5，可以通过<a href="https://github.com/kubernetes/dashboard/releases" target="_blank" rel="noopener">https://github.com/kubernetes/dashboard/releases</a>查看：</p><p><img src="img/QQ截图20191029210946.png" alt="QQ截图20191029210946.png"></p><p>下载该版本的Dashboard yaml文件：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget https://raw.githubusercontent.com/kubernetes/dashboard/v2.0.0-beta5/aio/deploy/recommended.yaml</span><br></pre></td></tr></table></figure><p></p><p>修改该配置文件：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim recommended.yaml</span><br></pre></td></tr></table></figure><p></p><p>修改的内容如下图所示：</p><p><img src="img/QQ截图20191029211413.png" alt="QQ截图20191029211413.png"></p><p>接着创建证书：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">mkdir dashboard-certs</span><br><span class="line"></span><br><span class="line">cd dashboard-certs/</span><br><span class="line"></span><br><span class="line">#创建命名空间</span><br><span class="line">kubectl create namespace kubernetes-dashboard</span><br><span class="line"></span><br><span class="line">#创建key文件</span><br><span class="line">openssl genrsa -out dashboard.key 2048</span><br><span class="line"></span><br><span class="line">#证书请求</span><br><span class="line">openssl req -days 36000 -new -out dashboard.csr -key dashboard.key -subj &apos;/CN=dashboard-cert&apos;</span><br><span class="line"></span><br><span class="line">#自签证书</span><br><span class="line">openssl x509 -req -in dashboard.csr -signkey dashboard.key -out dashboard.crt</span><br><span class="line"></span><br><span class="line">#创建kubernetes-dashboard-certs对象</span><br><span class="line">kubectl create secret generic kubernetes-dashboard-certs --from-file=dashboard.key --from-file=dashboard.crt -n kubernetes-dashboard</span><br></pre></td></tr></table></figure><p></p><p>然后执行<code>kubectl create -f ../recommended.yaml</code>命令安装Dashboard。</p><p>使用<code>kubectl get service -n kubernetes-dashboard -o wide</code>命令查看是否部署成功：</p><p><img src="img/QQ截图20191029211919.png" alt="QQ截图20191029211919.png"></p><h2 id="创建账号与授权"><a href="#创建账号与授权" class="headerlink" title="创建账号与授权"></a>创建账号与授权</h2><p>Dashboard部署好后，接着创建账号：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim dashboard-admin.yaml</span><br></pre></td></tr></table></figure><p></p><p>内容如下所示：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ServiceAccount</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  labels:</span></span><br><span class="line"><span class="attr">    k8s-app:</span> <span class="string">kubernetes-dashboard</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">dashboard-admin</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">kubernetes-dashboard</span></span><br></pre></td></tr></table></figure><p></p><p>创建该账号：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl create -f dashboard-admin.yaml</span><br></pre></td></tr></table></figure><p></p><p>账号创建好后，接着为其授权：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim dashboard-admin-bind-cluster-role.yaml</span><br></pre></td></tr></table></figure><p></p><p>内容如下所示：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ClusterRoleBinding</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">dashboard-admin-bind-cluster-role</span></span><br><span class="line"><span class="attr">  labels:</span></span><br><span class="line"><span class="attr">    k8s-app:</span> <span class="string">kubernetes-dashboard</span></span><br><span class="line"><span class="attr">roleRef:</span></span><br><span class="line"><span class="attr">  apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></span><br><span class="line"><span class="attr">  kind:</span> <span class="string">ClusterRole</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">cluster-admin</span></span><br><span class="line"><span class="attr">subjects:</span></span><br><span class="line"><span class="attr">- kind:</span> <span class="string">ServiceAccount</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">dashboard-admin</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">kubernetes-dashboard</span></span><br></pre></td></tr></table></figure><p></p><p>授权：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl create -f dashboard-admin-bind-cluster-role.yaml</span><br></pre></td></tr></table></figure><p></p><h2 id="访问Dashboard"><a href="#访问Dashboard" class="headerlink" title="访问Dashboard"></a>访问Dashboard</h2><p>使用浏览器访问<a href="https://192.168.33.12:30008/#/login" target="_blank" rel="noopener">https://192.168.33.12:30008/#/login</a>：</p><p><img src="img/QQ截图20191029222406.png" alt="QQ截图20191029222406.png"></p><p>选择Token，Token的值可以用下面的命令获取：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl -n kubernetes-dashboard describe secret $(kubectl -n kubernetes-dashboard get secret | grep dashboard-admin | awk &apos;&#123;print $1&#125;&apos;)</span><br></pre></td></tr></table></figure><p></p><p><img src="img/QQ截图20191029222542.png" alt="QQ截图20191029222542.png"></p><p>复制该Token到Dashboard：</p><p><img src="img/QQ截图20191029222651.png" alt="QQ截图20191029222651.png"></p><p>点击Sign In：</p><p><img src="img/QQ截图20191029222743.png" alt="QQ截图20191029222743.png"></p><h2 id="安装Metrics-Service"><a href="#安装Metrics-Service" class="headerlink" title="安装Metrics Service"></a>安装Metrics Service</h2><p>上面Dashboard的CPU Usage (cores)和Memory Usage (bytes)列是空的，这是因为Kubernetes的早期版本依靠Heapster来实现完整的性能数据采集和监控功能，Kubernetes从1.8版本开始，性能数据开始以Metrics API的方式提供标准化接口，并且从1.10版本开始将Heapster替换为Metrics Server。</p><p>首先在master节点上安装git：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install git</span><br></pre></td></tr></table></figure><p></p><p>然后克隆Metrics Server GitHub仓库：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/kubernetes-sigs/metrics-server.git</span><br></pre></td></tr></table></figure><p></p><p>修改metrics-server-deployment.yaml：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim metrics-server/deploy/1.8+/metrics-server-deployment.yaml</span><br></pre></td></tr></table></figure><p></p><p>修改内容如下图所示：</p><p><img src="img/QQ截图20191108195559.png" alt="QQ截图20191108195559.png"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">......</span><br><span class="line">        imagePullPolicy: IfNotPresent</span><br><span class="line">        command:</span><br><span class="line">          - /metrics-server</span><br><span class="line">          - --kubelet-preferred-address-types=InternalIP</span><br><span class="line">          - --kubelet-insecure-tls</span><br><span class="line">......</span><br></pre></td></tr></table></figure><p>因为默认metrics service的镜像地址需要科学上网才能拉取，所以在创建之前，我们在node1和node2节点先执行以下操作准备镜像：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker pull bluersw/metrics-server-amd64:v0.3.6</span><br><span class="line">docker tag bluersw/metrics-server-amd64:v0.3.6 k8s.gcr.io/metrics-server-amd64:v0.3.6</span><br></pre></td></tr></table></figure><p></p><p>然后回到master节点，执行：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl create -f metrics-server/deploy/1.8+/</span><br></pre></td></tr></table></figure><p></p><p><img src="img/QQ截图20191108195421.png" alt="QQ截图20191108195421.png"></p><p>稍等片刻，然后执行<code>kubectl top nodes</code>便可以看到每个节点的CPU和内存使用率了：</p><p><img src="img/QQ截图20191108195522.png" alt="QQ截图20191108195522.png"></p><p>回到Dashboard：</p><p><img src="img/QQ截图20191108200314.png" alt="QQ截图20191108200314.png"></p><p><img src="img/QQ截图2019102ddd9202540.png" alt="QQ截图2019102ddd9202540.png"></p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Tue Dec 17 2019 19:26:13 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;Kubernetes Dashboard是Kubernetes提供的Web用户界面，通过Dashboard我们可以将容器化的应用部署到Kubernetes集群中，对容器化的应用进行故障排除以及集群资源管理；可以通过Dashboard查看集群应用详情，创建或修改单个Kubernetes资源（例如Deployments，Jobs，DaemonSets等）。
    
    </summary>
    
    
      <category term="Kubernetes" scheme="http://mrbird.cc/tags/Kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>Kubeadm安装Kubernetes1.16.2集群</title>
    <link href="http://mrbird.cc/Kubeadm-install-Kubernetes1-16-2-cluster.html"/>
    <id>http://mrbird.cc/Kubeadm-install-Kubernetes1-16-2-cluster.html</id>
    <published>2019-10-28T12:49:50.000Z</published>
    <updated>2019-11-08T09:57:27.638Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Tue Dec 17 2019 19:26:13 GMT+0800 (GMT+08:00) --><p>Kubernetes从1.4版本开始后就引入了kubeadm用于简化集群搭建的过程，在Kubernetes 1.13版本中，kubeadm工具进入GA阶段，可用于生产环境Kubernetes集群搭建。本节将使用Kubeadm搭建Kubernetes1.16.2集群，宿主机采用3台Vagrant构建的Centos7虚拟机，配置如下所示（Kubernetes推荐宿主机最低内存不能低于2G，CPU核心数最低不能低于2）：<a id="more"></a></p><table><thead><tr><th style="text-align:center">操作系统</th><th style="text-align:center">IP</th><th style="text-align:center">角色</th><th style="text-align:center">CPU核心数</th><th style="text-align:center">内存</th><th style="text-align:center">Hostname</th></tr></thead><tbody><tr><td style="text-align:center">centos7</td><td style="text-align:center">192.168.33.11</td><td style="text-align:center">master</td><td style="text-align:center">2</td><td style="text-align:center">4096M</td><td style="text-align:center">master</td></tr><tr><td style="text-align:center">centos7</td><td style="text-align:center">192.168.33.12</td><td style="text-align:center">worker</td><td style="text-align:center">2</td><td style="text-align:center">4096M</td><td style="text-align:center">node1</td></tr><tr><td style="text-align:center">centos7</td><td style="text-align:center">192.168.33.13</td><td style="text-align:center">worker</td><td style="text-align:center">2</td><td style="text-align:center">4096M</td><td style="text-align:center">node2</td></tr></tbody></table><p>分享下我的Vagrantfile配置：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">Vagrant.configure("2")</span> <span class="string">do</span> <span class="string">|config|</span></span><br><span class="line">  <span class="string">config.vm.box</span> <span class="string">=</span> <span class="string">"centos/7"</span></span><br><span class="line">  <span class="string">config.vm.define</span> <span class="string">"one"</span> <span class="string">do</span> <span class="string">|one|</span></span><br><span class="line">  	<span class="string">one.vm.network</span> <span class="string">"private_network"</span><span class="string">,</span> <span class="attr">ip:</span> <span class="string">"192.168.33.11"</span></span><br><span class="line">  	<span class="string">one.vm.hostname</span> <span class="string">=</span> <span class="string">"master"</span></span><br><span class="line">  	<span class="string">one.vm.provider</span> <span class="string">"virtualbox"</span> <span class="string">do</span> <span class="string">|v|</span></span><br><span class="line">	  <span class="string">v.memory</span> <span class="string">=</span> <span class="number">4096</span></span><br><span class="line">	  <span class="string">v.cpus</span> <span class="string">=</span> <span class="number">2</span></span><br><span class="line">	<span class="string">end</span></span><br><span class="line">  <span class="string">end</span></span><br><span class="line"></span><br><span class="line">  <span class="string">config.vm.define</span> <span class="string">"two"</span> <span class="string">do</span> <span class="string">|two|</span></span><br><span class="line">  	<span class="string">two.vm.network</span> <span class="string">"private_network"</span><span class="string">,</span> <span class="attr">ip:</span> <span class="string">"192.168.33.12"</span></span><br><span class="line">  	<span class="string">two.vm.hostname</span> <span class="string">=</span> <span class="string">"node1"</span></span><br><span class="line">  	<span class="string">two.vm.provider</span> <span class="string">"virtualbox"</span> <span class="string">do</span> <span class="string">|v|</span></span><br><span class="line">	  <span class="string">v.memory</span> <span class="string">=</span> <span class="number">4096</span></span><br><span class="line">	  <span class="string">v.cpus</span> <span class="string">=</span> <span class="number">2</span></span><br><span class="line">	<span class="string">end</span></span><br><span class="line">  <span class="string">end</span></span><br><span class="line"></span><br><span class="line">  <span class="string">config.vm.define</span> <span class="string">"three"</span> <span class="string">do</span> <span class="string">|three|</span></span><br><span class="line">  	<span class="string">three.vm.network</span> <span class="string">"private_network"</span><span class="string">,</span> <span class="attr">ip:</span> <span class="string">"192.168.33.13"</span></span><br><span class="line">  	<span class="string">three.vm.hostname</span> <span class="string">=</span> <span class="string">"node2"</span></span><br><span class="line">  	<span class="string">three.vm.provider</span> <span class="string">"virtualbox"</span> <span class="string">do</span> <span class="string">|v|</span></span><br><span class="line">	  <span class="string">v.memory</span> <span class="string">=</span> <span class="number">4096</span></span><br><span class="line">	  <span class="string">v.cpus</span> <span class="string">=</span> <span class="number">2</span></span><br><span class="line">	<span class="string">end</span></span><br><span class="line">  <span class="string">end</span></span><br><span class="line"><span class="string">end</span></span><br></pre></td></tr></table></figure><p></p><p>启动后如下所示：</p><p><img src="img/12341234.png" alt="QQ截图20191028210242.png"></p><h2 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h2><p><span style="color:red;font-weight:600">下面这些准备工作分别在3台机器上使用root账号操作：</span></p><p><strong>1.安装必要软件：</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install -y net-tools.x86_64 vim wget</span><br></pre></td></tr></table></figure><p></p><p><strong>2.配置hosts：</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/hosts</span><br></pre></td></tr></table></figure><p></p><p>内容如下所示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">192.168.33.11 master</span><br><span class="line">192.168.33.12 node1</span><br><span class="line">192.168.33.13 node2</span><br></pre></td></tr></table></figure><p></p><p><strong>3.关闭防火墙：</strong></p><p>为了避免kubernetes的Master节点和各个工作节点的Node节点间的通信出现问题，我们可以关闭本地搭建的Centos虚拟机的防火墙。生产环境推荐的做法是在防火墙上配置各个组件需要相互通信的端口。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">systemctl disable firewalld</span><br><span class="line">systemctl stop firewalld</span><br></pre></td></tr></table></figure><p></p><p><strong>4.禁用SELinux，让容器可以顺利地读取主机文件系统：</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">setenforce 0</span><br></pre></td></tr></table></figure><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sed -i &apos;s/^SELINUX=enforcing$/SELINUX=disabled/&apos; /etc/selinux/config</span><br></pre></td></tr></table></figure><p><strong>5.安装18.09版本的docker：</strong></p><p>因为本节需要安装的kubernetes集群版本为1.16.2，而该版本的kubernetes最高支持的docker版本为18.09。可以通过该地址查看kubernetes和docker的版本对应关系：<a href="https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG-1.16.md#downloads-for-v1160" target="_blank" rel="noopener">https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG-1.16.md#downloads-for-v1160</a>：</p><p><img src="img/QQ截图20191028211129.png" alt="QQ截图20191028211129.png"></p><p>安装必要依赖:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">yum install -y yum-utils \</span><br><span class="line">  device-mapper-persistent-data \</span><br><span class="line">  lvm2</span><br></pre></td></tr></table></figure><p></p><p>添加docker稳定版仓库：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">yum-config-manager \</span><br><span class="line">    --add-repo \</span><br><span class="line">    https://download.docker.com/linux/centos/docker-ce.repo</span><br></pre></td></tr></table></figure><p></p><p>安装18.09版本：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install docker-ce-18.09.0 docker-ce-cli-18.09.0 containerd.io</span><br></pre></td></tr></table></figure><p></p><p>启动docker，并设置开机自启：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl enable docker &amp;&amp; systemctl start docker</span><br></pre></td></tr></table></figure><p></p><p>修改/etc/docker/daemon.json文件:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/docker/daemon.json</span><br></pre></td></tr></table></figure><p></p><p>内容如下所示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;exec-opts&quot;: [&quot;native.cgroupdriver=systemd&quot;]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><p>重启docker：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl restart docker</span><br></pre></td></tr></table></figure><p></p><p><strong>6.将桥接的IPv4流量传递到iptables的链</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; /etc/sysctl.d/k8s.conf &lt;&lt; EOF</span><br><span class="line">   net.bridge.bridge-nf-call-ip6tables = 1</span><br><span class="line">   net.bridge.bridge-nf-call-iptables = 1</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sysctl --system</span><br></pre></td></tr></table></figure><p><strong>7.关闭swap</strong></p><p>Swap是操作系统在内存吃紧的情况申请的虚拟内存，按照Kubernetes官网的说法，Swap会对Kubernetes的性能造成影响，不推荐使用Swap。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">swapoff -a</span><br></pre></td></tr></table></figure><p></p><h2 id="安装Master"><a href="#安装Master" class="headerlink" title="安装Master"></a>安装Master</h2><p>准备工作完毕后，接着开始在192.168.33.11 Master虚拟机上安装Kubernetes Master。</p><p><strong>1.配置国内的kubernetes源：</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo</span><br><span class="line"></span><br><span class="line">[kubernetes]</span><br><span class="line">name=Kubernetes</span><br><span class="line">baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/</span><br><span class="line">enabled=1</span><br><span class="line">gpgcheck=1</span><br><span class="line">repo_gpgcheck=1</span><br><span class="line">gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg</span><br><span class="line"></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p></p><p><strong>2.安装kubelet、kubeadm和kubectl工具：</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install -y kubelet kubeadm kubectl --disableexcludes=kubernetes</span><br></pre></td></tr></table></figure><p></p><p><strong>3.启动kubelet并设置开机自启：</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl enable kubelet &amp;&amp; systemctl start kubelet</span><br></pre></td></tr></table></figure><p></p><p><strong>4.使用下面这条命令启动master：</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">kubeadm init --kubernetes-version=v1.16.2 \</span><br><span class="line">--pod-network-cidr=10.244.0.0/16 \</span><br><span class="line">--service-cidr=10.1.0.0/16 \</span><br><span class="line">--apiserver-advertise-address=192.168.33.11 \</span><br><span class="line">--image-repository registry.aliyuncs.com/google_containers</span><br></pre></td></tr></table></figure><p></p><p>配置含义如下：</p><ul><li>kubernetes-version: 用于指定k8s版本，这里指定为最新的1.16.2版本；</li><li>apiserver-advertise-address：用于指定kube-apiserver监听的ip地址，就是master本机IP地址。</li><li>pod-network-cidr：因为后面我们选择flannel作为Pod的网络插件，所以这里需要指定Pod的网络范围为10.244.0.0/16</li><li>service-cidr：用于指定SVC的网络范围；</li><li>image-repository: 其中默认的镜像仓库k8s.gcr.io没有科学上网的话无法访问，我们可以将它修改为国内的阿里镜像仓库registry.aliyuncs.com/google_containers</li></ul><p>启动时，需要拉取镜像，过程比较缓慢耐心等待即可。如果你想先拉好镜像再启动，你可以使用<code>kubeadm config images list</code>命令列出需要拉取的镜像。</p><p>启动成功后，你会看到类似如下提示:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">Your Kubernetes control-plane has initialized successfully!</span><br><span class="line"></span><br><span class="line">To start using your cluster, you need to run the following as a regular user:</span><br><span class="line"></span><br><span class="line">  mkdir -p $HOME/.kube</span><br><span class="line">  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span><br><span class="line">  sudo chown $(id -u):$(id -g) $HOME/.kube/config</span><br><span class="line"></span><br><span class="line">You should now deploy a pod network to the cluster.</span><br><span class="line">Run &quot;kubectl apply -f [podnetwork].yaml&quot; with one of the options listed at:</span><br><span class="line">  https://kubernetes.io/docs/concepts/cluster-administration/addons/</span><br><span class="line"></span><br><span class="line">Then you can join any number of worker nodes by running the following on each as root:</span><br><span class="line"></span><br><span class="line">kubeadm join 192.168.33.11:6443 --token yf7sct.o63ceq25gxdu71cd \</span><br><span class="line">    --discovery-token-ca-cert-hash sha256:bcd15ddd7432d393d3831c75ac7673f582d4e9895ff2c579c3f545d2a5d3026e</span><br></pre></td></tr></table></figure><p></p><p>意思是，如果你想要非root用户也能使用kubectl命令的话，需要执行下面这些操作：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p $HOME/.kube</span><br><span class="line">sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span><br><span class="line">sudo chown $(id -u):$(id -g) $HOME/.kube/config</span><br></pre></td></tr></table></figure><p></p><p>而如果你是root用户的话，直接运行下面这段命令即可：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export KUBECONFIG=/etc/kubernetes/admin.conf</span><br></pre></td></tr></table></figure><p></p><p>而下面这段则是用于工作节点Node加入Master集群用的，后面会使用到</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubeadm join 192.168.33.11:6443 --token yf7sct.o63ceq25gxdu71cd \</span><br><span class="line">    --discovery-token-ca-cert-hash sha256:bcd15ddd7432d393d3831c75ac7673f582d4e9895ff2c579c3f545d2a5d3026e</span><br></pre></td></tr></table></figure><p></p><h2 id="安装Node节点，加入集群"><a href="#安装Node节点，加入集群" class="headerlink" title="安装Node节点，加入集群"></a>安装Node节点，加入集群</h2><p>接着在192.168.33.12和192.168.33.13虚拟机上操作。</p><p>和安装Master步骤一样，先安装好kubeadm相关工具，然后执行下面这条命令将Node加入到集群：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubeadm join 192.168.33.11:6443 --token yf7sct.o63ceq25gxdu71cd \</span><br><span class="line">    --discovery-token-ca-cert-hash sha256:bcd15ddd7432d393d3831c75ac7673f582d4e9895ff2c579c3f545d2a5d3026e</span><br></pre></td></tr></table></figure><p></p><p>当输出如下内容是说明加入成功：</p><p><img src="img/QQ截图20191028215138.png" alt="QQ截图20191028215138.png"></p><h2 id="安装网络插件"><a href="#安装网络插件" class="headerlink" title="安装网络插件"></a>安装网络插件</h2><p>在Master上执行kubectl get nodes命令，会发现Kubernetes提示Master为NotReady状态，这是因为还没有安装CNI网络插件：</p><p><img src="img/QQ截图20191028215653.png" alt="QQ截图20191028215653.png"></p><p>对于CNI网络插件，可以有许多选择，请参考<a href="https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/#pod-network" target="_blank" rel="noopener">https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/#pod-network</a>的说明。这里我选择的flannel：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget https://raw.githubusercontent.com/coreos/flannel/2140ac876ef134e0ed5af15c65e414cf26827915/Documentation/kube-flannel.yml</span><br></pre></td></tr></table></figure><p></p><p>修改kube-flannel.yml：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim kube-flannel.yml</span><br></pre></td></tr></table></figure><p></p><p>修改的地方如下所示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">......</span><br><span class="line">containers:</span><br><span class="line">      - name: kube-flannel</span><br><span class="line">        image: quay.io/coreos/flannel:v0.11.0-amd64</span><br><span class="line">        command:</span><br><span class="line">        - /opt/bin/flanneld</span><br><span class="line">        args:</span><br><span class="line">        - --ip-masq</span><br><span class="line">        - --kube-subnet-mgr</span><br><span class="line">        - --iface=eth1 # 新增部分</span><br><span class="line">......</span><br></pre></td></tr></table></figure><p></p><p>Vagrant 在多主机模式下有多个网卡，eth0 网卡用于nat转发访问公网，而eth1网卡才是主机真正的IP，在这种情况下直接部署k8s flannel 插件会导致CoreDNS无法工作，所以我们需要添加上面这条配置强制flannel使用eth1。</p><p>安装flannel：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl create -f kube-flannel.yml</span><br></pre></td></tr></table></figure><p></p><p>输出如下所示时，表示安装成功：</p><p><img src="img/QQ截图20191028215831.png" alt="QQ截图20191028215831.png"></p><p>稍等片刻后，再次查看节点状态：</p><p><img src="img/QQ截图20191028215910.png" alt="QQ截图20191028215910.png"></p><p>可以看到所有节点都是Ready状态。</p><p>执行<code>kubectl get pods --all-namespaces</code>，验证Kubernetes集群的相关Pod是否都正常创建并运行：</p><p><img src="img/QQ截图20191028220122.png" alt="QQ截图20191028220122.png"></p><p>到这里通过Kubeadm安装Kubernetes 1.16.2集群已经成功了。如果安装失败，则可以执行<code>kubeadm reset</code>命令将主机恢复原状，重新执行<code>kubeadm init</code>命令，再次进行安装。</p><h2 id="小试牛刀"><a href="#小试牛刀" class="headerlink" title="小试牛刀"></a>小试牛刀</h2><p>为了快速地验证一下上面搭建集群是否可用，我们创建一个Nginx Deployment：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kubectl create deployment nginx --image=nginx</span><br><span class="line"> </span><br><span class="line">kubectl expose deployment nginx --port=80 --type=NodePort</span><br></pre></td></tr></table></figure><p></p><p>使用命令<code>kubectl get pod,svc</code>查看是否正常：</p><p><img src="img/QQ截图20191028221659.png" alt="QQ截图20191028221659.png"></p><p>使用命令<code>kubectl get pods,svc -o wide</code>查看该Pod具体位于哪一个节点：</p><p><img src="img/QQ截图20191028221805.png" alt="QQ截图20191028221805.png"></p><p>可以看到其位于Node2节点，该节点IP为192.168.33.13，端口为30935，使用浏览器访问该地址：</p><p><img src="img/QQ截图20191028221923.png" alt="QQ截图20191028221923.png"></p><p>使用<code>kubectl get pods</code>命令查看Pod的情况:</p><p><img src="img/QQ截图20191029202111.png" alt="QQ截图20191029202111.png"></p><p>使用<code>kubectl delete</code>命令删除这个Pod看看会怎样：</p><p><img src="img/QQ截图20191029202330.png" alt="QQ截图20191029202330.png"></p><p>可以看到，刚刚的名为xxx的Pod处于Terminating（结束中）的状态，而另一个新的名为xxx的Pod正处于ContainerCreating（创建中）状态，因为默认情况下，<code>replicas</code>的值为1，Kubernetes集群会始终保持Nginx的实例为1。</p><p>要删除Nginx可以通过删除deployment来完成，使用<code>kubectl get deployments</code>命令查看当前的deployment：</p><p><img src="img/QQ截图20191029202412.png" alt="QQ截图20191029202412.png"></p><p>使用命令<code>kubectl delete deployment nginx</code>：</p><p><img src="img/QQ截图20191029202439.png" alt="QQ截图20191029202439.png"></p><p>实际中我们一般通过yml或者json文件来创建应用，下面我们使用yml的方式创建一个3实例的Nginx集群：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim nginx-rc.yml</span><br></pre></td></tr></table></figure><p></p><p>内容如下所示：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ReplicationController</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">nginx-rc</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  replicas:</span> <span class="number">3</span></span><br><span class="line"><span class="attr">  selector:</span></span><br><span class="line"><span class="attr">    name:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">  template:</span></span><br><span class="line"><span class="attr">    metadata:</span></span><br><span class="line"><span class="attr">      labels:</span></span><br><span class="line"><span class="attr">        name:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">    spec:</span></span><br><span class="line"><span class="attr">      containers:</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">          image:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">          imagePullPolicy:</span> <span class="string">IfNotPresent</span></span><br><span class="line"><span class="attr">          ports:</span></span><br><span class="line"><span class="attr">            - containerPort:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim nginx-service.yml</span><br></pre></td></tr></table></figure><p>内容如下所示：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">nginx-service</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  ports:</span></span><br><span class="line"><span class="attr">    - port:</span> <span class="number">8080</span></span><br><span class="line"><span class="attr">      targetPort:</span> <span class="number">80</span></span><br><span class="line"><span class="attr">      protocol:</span> <span class="string">TCP</span></span><br><span class="line"><span class="attr">  type:</span> <span class="string">NodePort</span></span><br><span class="line"><span class="attr">  selector:</span></span><br><span class="line"><span class="attr">    name:</span> <span class="string">nginx</span></span><br></pre></td></tr></table></figure><p></p><p>接着执行下面这两条命令启动Nginx集群：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubectl create -f nginx-rc.yml</span><br><span class="line">kubectl create -f nginx-service.yml</span><br></pre></td></tr></table></figure><p></p><p>使用<code>kubectl get pods</code>命令查看Pod情况:</p><p><img src="img/QQ截图20191029202540.png" alt="QQ截图20191029202540.png"></p><p>使用<code>kubectl get services</code>命令查看Service情况：</p><p><img src="img/QQ截图20191029202644.png" alt="QQ截图20191029202644.png"></p><p>使用<code>kubectl describe svc nginx-service</code>命令查看Nginx Service详情：</p><p><img src="img/QQ截图20191029202719.png" alt="QQ截图20191029202719.png"></p><p>使用命令<code>kubectl get pods,svc -o wide</code>查看Nginx Pod具体位于哪一个节点：</p><p><img src="img/QQ截图20191029202746.png" alt="QQ截图20191029202746.png"></p><p>可以看到在node1和node2节点上都有Nginx的Pod，使用浏览器访问<a href="http://192.168.33.12:32631/" target="_blank" rel="noopener">http://192.168.33.12:32631/</a>或者<a href="http://192.168.33.13:32631/" target="_blank" rel="noopener">http://192.168.33.13:32631/</a>：</p><p><img src="img/QQ截图20191029202923.png" alt="QQ截图20191029202923.png"></p><p>删除的话执行下面这两条命令即可：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubectl delete -f nginx-service.yml</span><br><span class="line">kubectl delete -f nginx-rc.yml</span><br></pre></td></tr></table></figure><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Tue Dec 17 2019 19:26:13 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;Kubernetes从1.4版本开始后就引入了kubeadm用于简化集群搭建的过程，在Kubernetes 1.13版本中，kubeadm工具进入GA阶段，可用于生产环境Kubernetes集群搭建。本节将使用Kubeadm搭建Kubernetes1.16.2集群，宿主机采用3台Vagrant构建的Centos7虚拟机，配置如下所示（Kubernetes推荐宿主机最低内存不能低于2G，CPU核心数最低不能低于2）：
    
    </summary>
    
    
      <category term="Kubernetes" scheme="http://mrbird.cc/tags/Kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>Fork/Join使用学习</title>
    <link href="http://mrbird.cc/JDK7-Fork-Join.html"/>
    <id>http://mrbird.cc/JDK7-Fork-Join.html</id>
    <published>2019-03-21T03:20:14.000Z</published>
    <updated>2019-10-28T12:14:46.235Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Tue Dec 17 2019 19:26:13 GMT+0800 (GMT+08:00) --><p>JDK7提供了一个将任务“分而治之”的框架 — Fork/Join。它把一个大的任务分割成足够小的子任务，如果子任务比较大的话还要对子任务进行继续分割。分割的子任务分别放到双端队列里，然后启动线程分别从双端队列里获取任务执行。子任务执行完的结果都放在另外一个队列里，启动一个线程从队列里取数据，然后合并这些数据。<a id="more"></a></p><p>Fork/Join的思想如下所示： <img src="img/QQ截图20190702172347.png" alt="QQ截图20190702172347.png"></p><h2 id="RecursiveTask"><a href="#RecursiveTask" class="headerlink" title="RecursiveTask"></a>RecursiveTask</h2><p><img src="img/QQ截图20190703111904.png" alt="QQ截图20190703111904.png"></p><p>RecursiveTask适用于将任务分而治之，并且有返回值的情况，举个计算1到100和的例子：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">RecursiveTest</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 定义最小区间为10</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">static</span> <span class="keyword">int</span> MAX_THRESHOLD = <span class="number">10</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">final</span> ForkJoinPool forkJoinPool = <span class="keyword">new</span> ForkJoinPool();</span><br><span class="line">        ForkJoinTask&lt;Integer&gt; future = forkJoinPool.submit(<span class="keyword">new</span> CalculateRecursiveTask(<span class="number">1</span>, <span class="number">100</span>));</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            Integer result = future.get();</span><br><span class="line">            System.out.println(result);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (InterruptedException | ExecutionException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">CalculateRecursiveTask</span> <span class="keyword">extends</span> <span class="title">RecursiveTask</span>&lt;<span class="title">Integer</span>&gt; </span>&#123;</span><br><span class="line">        <span class="comment">// 起始</span></span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">int</span> start;</span><br><span class="line">        <span class="comment">// 结束</span></span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">int</span> end;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="title">CalculateRecursiveTask</span><span class="params">(<span class="keyword">int</span> start, <span class="keyword">int</span> end)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">this</span>.start = start;</span><br><span class="line">            <span class="keyword">this</span>.end = end;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">protected</span> Integer <span class="title">compute</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="comment">// 如果起始和结束范围小于我们定义的区间范围，则直接计算</span></span><br><span class="line">            <span class="keyword">if</span> ((end - start) &lt;= MAX_THRESHOLD) &#123;</span><br><span class="line">                <span class="keyword">return</span> IntStream.rangeClosed(start, end).sum();</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="comment">// 否则，将范围一分为二，分成两个子任务</span></span><br><span class="line">                <span class="keyword">int</span> middle = (start + end) / <span class="number">2</span>;</span><br><span class="line">                CalculateRecursiveTask leftTask = <span class="keyword">new</span> CalculateRecursiveTask(start, middle);</span><br><span class="line">                CalculateRecursiveTask rightTask = <span class="keyword">new</span> CalculateRecursiveTask(middle + <span class="number">1</span>, end);</span><br><span class="line">                <span class="comment">// 执行子任务</span></span><br><span class="line">                leftTask.fork();</span><br><span class="line">                rightTask.fork();</span><br><span class="line"></span><br><span class="line">                <span class="comment">// 汇总子任务</span></span><br><span class="line">                <span class="keyword">return</span> leftTask.join() + rightTask.join();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><p>ForkJoinPool使用submit或invoke提交的区别：invoke是同步执行，调用之后需要等待任务完成，才能执行后面的代码；submit是异步执行，只有在Future调用get的时候会阻塞。</p><p>启动程序输出如下：</p><p><img src="img/QQ截图20190703112347.png" alt="QQ截图20190703112347.png"></p><p>其实这里执行子任务调用fork方法并不是最佳的选择，最佳的选择是invokeAll方法：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 执行子任务</span></span><br><span class="line"><span class="comment">// leftTask.fork();</span></span><br><span class="line"><span class="comment">// rightTask.fork();</span></span><br><span class="line">invokeAll(leftTask,rightTask);</span><br><span class="line"><span class="comment">// 汇总子任务</span></span><br><span class="line"><span class="keyword">return</span> leftTask.join() + rightTask.join();</span><br></pre></td></tr></table></figure><p></p><h2 id="RecursiveAction"><a href="#RecursiveAction" class="headerlink" title="RecursiveAction"></a>RecursiveAction</h2><p><img src="img/QQ截图20190703114411.png" alt="QQ截图20190703114411.png"></p><p>使用方式和RecursiveTask类似，只不过没有返回值：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">RecursiveActionTest</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 定义最小区间为10</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">static</span> <span class="keyword">int</span> MAX_THRESHOLD = <span class="number">10</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">static</span> AtomicInteger SUM = <span class="keyword">new</span> AtomicInteger(<span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">        <span class="keyword">final</span> ForkJoinPool forkJoinPool = <span class="keyword">new</span> ForkJoinPool();</span><br><span class="line">        forkJoinPool.submit(<span class="keyword">new</span> CalculateRecursiveAction(<span class="number">0</span>, <span class="number">100</span>));</span><br><span class="line">        forkJoinPool.awaitTermination(<span class="number">2</span>, TimeUnit.SECONDS);</span><br><span class="line">        System.out.println(SUM);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">CalculateRecursiveAction</span> <span class="keyword">extends</span> <span class="title">RecursiveAction</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 起始</span></span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> start;</span><br><span class="line">        <span class="comment">// 结束</span></span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> end;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">private</span> <span class="title">CalculateRecursiveAction</span><span class="params">(<span class="keyword">int</span> start, <span class="keyword">int</span> end)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">this</span>.start = start;</span><br><span class="line">            <span class="keyword">this</span>.end = end;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">compute</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="comment">// 如果起始和结束范围小于我们定义的区间范围，则直接计算</span></span><br><span class="line">            <span class="keyword">if</span> ((end - start) &lt;= MAX_THRESHOLD) &#123;</span><br><span class="line">                SUM.addAndGet(IntStream.rangeClosed(start, end).sum());</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="comment">// 否则，将范围一分为二，分成两个子任务</span></span><br><span class="line">                <span class="keyword">int</span> middle = (end + start) / <span class="number">2</span>;</span><br><span class="line">                CalculateRecursiveAction leftAction = <span class="keyword">new</span> CalculateRecursiveAction(start, middle);</span><br><span class="line">                CalculateRecursiveAction rightAction = <span class="keyword">new</span> CalculateRecursiveAction(middle + <span class="number">1</span>, end);</span><br><span class="line">                <span class="comment">// 执行子任务</span></span><br><span class="line">                invokeAll(leftAction, rightAction);</span><br><span class="line">                <span class="comment">// 没有汇总子任务结果过程，因为没有返回值。</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><p>输出结果也是5050。</p><h2 id="什么时候用"><a href="#什么时候用" class="headerlink" title="什么时候用"></a>什么时候用</h2><p>上面只是为了演示Fork/Join的用法，实际是采用这种方式计算反而更加费时，因为切割任务，分配线程需要额外的开销。其实什么时候用不必太纠结，一个足够大的任务，如果采用Fork/Join来处理比传统处理方式快的话，那就毫不犹豫的选择它吧！</p><p>参考文章：<a href="https://www.imooc.com/article/24822" target="_blank" rel="noopener">https://www.imooc.com/article/24822</a></p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Tue Dec 17 2019 19:26:13 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;JDK7提供了一个将任务“分而治之”的框架 — Fork/Join。它把一个大的任务分割成足够小的子任务，如果子任务比较大的话还要对子任务进行继续分割。分割的子任务分别放到双端队列里，然后启动线程分别从双端队列里获取任务执行。子任务执行完的结果都放在另外一个队列里，启动一个线程从队列里取数据，然后合并这些数据。
    
    </summary>
    
    
      <category term="Java" scheme="http://mrbird.cc/tags/Java/"/>
    
  </entry>
  
</feed>
